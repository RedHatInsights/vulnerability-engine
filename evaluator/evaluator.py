#!/usr/bin/python3
"""
vulnerability-engine evaluator
"""

import os
import logging
import json
import requests
from psycopg2.extras import execute_values

from kafka import KafkaConsumer, KafkaProducer

from database.database_handler import DatabaseHandler, init_db

VMAAS_HOST = os.getenv('VMAAS_HOST', 'http://vmaas-webapp-1.vmaas-ci.svc:8080') # pylint: disable=invalid-name
vmaas_updates_endpoint = "%s/api/v1/updates" % VMAAS_HOST # pylint: disable=invalid-name
vmaas_errata_endpoint = "%s/api/v1/errata" % VMAAS_HOST # pylint: disable=invalid-name
vmaas_cves_endpoint = "%s/api/v1/cves" % VMAAS_HOST # pylint: disable=invalid-name
kafka_host = os.getenv('KAFKA_HOST', 'kafka-1.vmaas-ci.svc') # pylint: disable=invalid-name
kafka_port = os.getenv('KAFKA_PORT', '29092') # pylint: disable=invalid-name
kafka_evaluator_topic = os.getenv('EVALUATOR_TOPIC', 'vulnerability.evaluator.requests') # pylint: disable=invalid-name
kafka_rules_requests_topic = os.getenv('RULES_REQUESTS_TOPIC', 'vulnerability.rules-engine.requests') # pylint: disable=invalid-name
kafka_rules_results_topic = os.getenv('RULES_RESULTS_TOPIC', 'vulnerability.rules-engine.results') # pylint: disable=invalid-name
kafka_group_id = os.getenv('KAFKA_GROUP_ID', 'vulnerability') # pylint: disable=invalid-name

logging.basicConfig(
    format='%(asctime)s.%(msecs)s:%(name)s:%(thread)d:%(levelname)s:%(process)d:%(message)s',
    level=logging.INFO
)


class QueueEvaluator:
    """ This class contains logic for the processing new available
        updates from VMaaS.
    """
    def __init__(self, kafka_host_in, kafka_port_in, kafka_topics_in, kafka_group_in):
        # connect to the Messaging Service
        bootstrap_server = kafka_host_in + ':' + kafka_port_in
        self.consumer = KafkaConsumer(*kafka_topics_in,
                                      bootstrap_servers=bootstrap_server,
                                      group_id=kafka_group_in,
                                      auto_offset_reset='latest',)

        logging.info("Using BOOTSTRAP_SERVERS: %s", bootstrap_server)
        logging.info("Using GROUP_ID: %s", kafka_group_in)
        logging.info("Using TOPICS: %s", ", ".join(kafka_topics_in))

        self.producer = KafkaProducer(bootstrap_servers=bootstrap_server)

        # get DB connection
        init_db()
        self.conn = DatabaseHandler.get_connection()
        self.error_key_map = self._prepare_error_key_map()
        self.impact_id_map = self._prepare_impact_id_map()

    def _prepare_error_key_map(self):
        error_key_map = {}
        cur = self.conn.cursor()
        cur.execute("select name, id from prodsec_error_key")
        for error_key_name, error_key_id in cur.fetchall():
            error_key_map[error_key_name] = error_key_id
        cur.close()
        return error_key_map

    def _prepare_impact_id_map(self):
        impact_id_map = {}
        cur = self.conn.cursor()
        cur.execute("select name, id from cve_impact")
        for impact_name, impact_id in cur.fetchall():
            impact_id_map[impact_name] = impact_id
        cur.close()
        return impact_id_map

    def _store_cves(self, system_id, system_cves, source_name="VMAAS"):
        if not system_cves:
            return

        cur = self.conn.cursor()
        cur.execute("select cve from system_vulnerabilities where platform_id = %s and \
                        when_mitigated is NULL", (system_id,))

        current_cves = set()

        for row in cur.fetchall():
            current_cves.add(row[0])

        new_cves = system_cves.difference(current_cves)
        mitigated_cves = current_cves.difference(system_cves)

        cur.execute("select id from vulnerability_source where name = %s", (source_name,))
        source_id = cur.fetchall()[0][0]

        # if system has got new vulnerabilities with new CVEs
        if new_cves:
            # JSON to POST requests to vmaas CVEs endpoint
            cves_json = {'cve_list': list(new_cves)}
            cve_cvss_list = []
            cve_system_list = []

            response = requests.post(vmaas_cves_endpoint, json=cves_json)
            if response.status_code == 200:

                cves_response_json = json.loads(response.text)

                # FIXME: getting metadata from DB on every system update should be optimized
                cur.execute("select cve from cve_metadata")
                cves_in_db = []
                for cve_tuple in cur.fetchall():
                    cves_in_db.append(cve_tuple[0])

                for cve in cves_response_json['cve_list']:
                    if cve not in cves_in_db:
                        # need also add a new CVE metadata into DB
                        cvss3_score = float(cves_response_json['cve_list'][cve]['cvss3_score'])
                        if 'cvss2_score' in cves_response_json['cve_list'][cve]:
                            cvss2_score = float(cves_response_json['cve_list'][cve]['cvss2_score'])
                        else:
                            cvss2_score = ''
                        cve_cvss_list.append((cve, cvss3_score, cvss2_score))

                    cve_system_list.append((system_id, cve, source_id))

                # Insert new CVEs into db
                if cve_cvss_list:
                    execute_values(cur, "insert into cve_metadata (cve, cvss3_score, cvss2_score) values %s",
                                   cve_cvss_list, page_size=len(cve_cvss_list))

                execute_values(cur, "insert into system_vulnerabilities \
                               (platform_id, cve, vulnerability_source) values %s",
                               cve_system_list, page_size=len(cve_system_list))

            else:
                logging.error("Error during request to VMaaS endpoint %s", vmaas_cves_endpoint)
                logging.debug("Updates JSON: %s", str(cves_json))

        if mitigated_cves:
            cur.execute("update system_vulnerabilities set when_mitigated = now() \
            where platform_id = %s and vulnerability_source = %s and cve in %s", (system_id,
                                                                                  source_id,
                                                                                  tuple(mitigated_cves),))
        cur.close()
        self.conn.commit()

    def _sync_cve_md(self, page_size=5000, page=1, cves_in_db=None):
        cur = self.conn.cursor()
        if not cves_in_db:
            cur.execute('select cve from cve_metadata')
            cves_in_db = []
            for cve_tuple in cur.fetchall():
                cves_in_db.append(cve_tuple[0])
        while True:
            cve_list = {'cve_list' : [".*"], 'page_size' : page_size, 'page': page, 'rh_only' : True}
            response = requests.post(vmaas_cves_endpoint, json=cve_list)
            if response.status_code != 200:
                break
            r_json = response.json()
            logging.info('syncing cve_metadata from vmaas: page: %s, page_size: %s, pages: %s',
                         page, page_size, r_json['pages'])
            cves = r_json['cve_list']
            to_insert = []
            to_update = []
            for cve in cves:
                description = cves[cve]['description']
                impact_id = self.impact_id_map[cves[cve]['impact']]
                public_date = cves[cve]['public_date'] or None
                modified_date = cves[cve]['modified_date'] or None
                cvss3_score = float(cves[cve]['cvss3_score']) if cves[cve]['cvss3_score'] else None
                cvss3_metrics = cves[cve]['cvss3_metrics']
                cvss2_score = float(cves[cve]['cvss2_score']) if cves[cve]['cvss2_score'] else None
                cvss2_metrics = cves[cve]['cvss2_metrics']
                row = (cve, description, impact_id, public_date, modified_date, cvss3_score, cvss3_metrics,
                       cvss2_score, cvss2_metrics)
                if cve not in cves_in_db:
                    to_insert.append(row)
                else:
                    to_update.append(row)
            if to_insert:
                execute_values(cur, """insert into cve_metadata
                                    (cve, description, impact_id, public_date, modified_date,
                                    cvss3_score, cvss3_metrics, cvss2_score, cvss2_metrics)
                                    values %s""", to_insert, page_size=len(to_insert))
            if to_update:
                execute_values(cur, """update cve_metadata set description = data.description,
                               impact_id = data.impact_id,
                               public_date = cast(data.public_date as timestamp with time zone),
                               modified_date = cast(data.modified_date as timestamp with time zone),
                               cvss3_score = cast(data.cvss3_score as numeric),
                               cvss3_metrics = data.cvss3_metrics,
                               cvss2_score = cast(data.cvss2_score as numeric),
                               cvss2_metrics = data.cvss2_metrics
                               from (values %s) as data (cve, description, impact_id, public_date, modified_date,
                               cvss3_score, cvss3_metrics, cvss2_score, cvss2_metrics)
                               where cve_metadata.cve = data.cve""",
                               to_update, page_size=len(to_update))
            if page >= r_json['pages']:
                break
            page += 1
        cur.close()
        self.conn.commit()

    def _store_error_keys(self, system_id, system_error_keys):
        if system_error_keys:
            cur = self.conn.cursor()

            # Populate error keys not yet in DB
            new_error_keys = [(key,) for key in system_error_keys if key not in self.error_key_map]
            if new_error_keys:
                execute_values(cur, "insert into prodsec_error_key (name) values %s returning name, id",
                               new_error_keys, page_size=len(new_error_keys))
                self.conn.commit()

                for error_key_name, error_key_id in cur.fetchall():
                    self.error_key_map[error_key_name] = error_key_id

            # Get keys associated to system in DB
            db_system_error_key_ids = {}
            cur.execute("select error_key_id, when_mitigated from system_prodsec_error_key where platform_id = %s",
                        (system_id,))
            for error_key_id, when_mitigated in cur.fetchall():
                db_system_error_key_ids[error_key_id] = when_mitigated

            system_error_key_ids = {self.error_key_map[error_key] for error_key in system_error_keys}

            # Not in DB
            to_import = [(system_id, error_key_id) for error_key_id in system_error_key_ids
                         if error_key_id not in db_system_error_key_ids]
            if to_import:
                execute_values(cur, "insert into system_prodsec_error_key (platform_id, error_key_id) values %s",
                               to_import, page_size=len(to_import))

            # Not reported by rule but in DB
            to_mitigate = [error_key_id for error_key_id in db_system_error_key_ids
                           if error_key_id not in system_error_key_ids]
            if to_mitigate:
                cur.execute("""update system_prodsec_error_key set when_mitigated = now()
                               where platform_id = %s and error_key_id in %s""", (system_id, tuple(to_mitigate),))

            # Reported by rule but marked as mitigated in DB
            to_unmitigate = [error_key_id for error_key_id in system_error_key_ids
                             if db_system_error_key_ids.get(error_key_id, None)]
            if to_unmitigate:
                cur.execute("""update system_prodsec_error_key set when_mitigated = null
                               where platform_id = %s and error_key_id in %s""", (system_id, tuple(to_unmitigate),))

            cur.close()
            self.conn.commit()

    def evaluate_vmaas(self, system_platform):
        """Evaluates messages received from vmaas"""
        # JSON to POST requests to vmaas updates endpoint
        updates_json = json.loads(system_platform[1])
        # JSON to POST requests to vmaas errata endpoint
        errata_json = {'errata_list': []}

        system_errata = set()
        system_cves = set()

        response = requests.post(vmaas_updates_endpoint, json=updates_json)
        if response.status_code == 200:
            updates_response_json = json.loads(response.text)
            for pkg in updates_response_json['update_list']:
                for upd in updates_response_json['update_list'][pkg].get('available_updates', []):
                    system_errata.add(upd['erratum'])
        else:
            logging.error("Error during request to VMaaS endpoint %s", vmaas_updates_endpoint)
            logging.debug("Updates JSON: %s", str(updates_json))

        if system_errata:
            errata_json['errata_list'] = list(system_errata)
            response = requests.post(vmaas_errata_endpoint, json=errata_json)

            if response.status_code == 200:
                errata_response_json = json.loads(response.text)

                for erratum in errata_response_json['errata_list']:
                    for cve in errata_response_json['errata_list'][erratum]['cve_list']:
                        system_cves.add(cve)
            else:
                logging.error("Error during request to VMaaS endpoint %s", vmaas_errata_endpoint)
                logging.debug("Updates JSON: %s", str(errata_json))

        self._store_cves(system_platform[0], system_cves, source_name="VMAAS")

    def evaluate_rules(self, rules_engine_response):
        """Evaluates messages from rules engine"""
        system_cves = set()
        system_error_keys = set()

        for report in rules_engine_response["reports"]:
            # FIXME: get CVE IDs properly when they are available in rules results
            rule_id = report["rule_id"].upper()
            rule_id = rule_id.split("|")[0] # strip error key
            rule_id = rule_id.replace("_", "-")
            cve_id_parts = rule_id.split("-")
            if cve_id_parts[0] == "CVE" and cve_id_parts[1].isdigit() and cve_id_parts[2].isdigit():
                system_error_keys.add(report["rule_id"])
                system_cves.add("%s-%s-%s" % (cve_id_parts[0], cve_id_parts[1], cve_id_parts[2]))

        system_id = rules_engine_response["system"]["system_id"]
        self._store_error_keys(system_id, system_error_keys)
        self._store_cves(system_id, system_cves, source_name="RULES")

    def _prepare_rules_engine_request(self, listener_msg): # pylint: disable=no-self-use
        return {
            "plugins": ["vmaas"],
            "rh_account": listener_msg["rh_account"],
            "url": listener_msg["url"],
            "hash": listener_msg["hash"]
        }

    def run(self):
        """
        This method process messages with type 'vmaas_updates'
        :return:
        """

        cur = self.conn.cursor()
        cur.execute('select count(*) from cve_metadata')
        cve_md_count = int(cur.fetchone()[0])
        if cve_md_count == 0:
            logging.info('no cve_metadata found, attempting to pull them from vmaas')
            self._sync_cve_md()
        for message in self.consumer:
            if message.topic == kafka_evaluator_topic:
                msg_dict = json.loads(message.value.decode('utf-8'))
                if 'type' not in msg_dict:
                    logging.error("Received message is missing type field: %s", msg_dict)
                    continue
                if msg_dict['type'] == 'vmaas_updates':
                    logging.info("Received message type: %s", msg_dict['type'])
                    self._sync_cve_md()
                    cur.execute("select platform_id, vmaas_json from system_platform")
                    # reevaluate updates for every system in the DB
                    for system_platform in cur.fetchall():
                        self.evaluate_vmaas(system_platform)
                elif msg_dict['type'] == 'upload_new_file':
                    logging.info("Received message type: %s", msg_dict['type'])
                    cur.execute("select platform_id, vmaas_json from system_platform where platform_id = %s",
                                (msg_dict['system_id'],))
                    system_platform = cur.fetchone()
                    if system_platform is not None:
                        self.producer.send(kafka_rules_requests_topic,
                                           json.dumps(self._prepare_rules_engine_request(msg_dict)).encode("utf8"))
                        self.evaluate_vmaas(system_platform)
                    else:
                        logging.error("System with platform_id not found in DB: %s", msg_dict['system_id'])
                else:
                    logging.error("Received unknown message type: %s", msg_dict['type'])
            elif message.topic == kafka_rules_results_topic:
                logging.info("Received message on topic: %s", message.topic)
                msg_dict = json.loads(message.value.decode('utf-8'))
                self.evaluate_rules(msg_dict)
            else:
                logging.error("Received message on unsupported topic: %s", message.topic)

        self.consumer.close()
        cur.close()
        self.conn.commit()

def main():
    """Sets up and runs the evaluator"""
    evaluator = QueueEvaluator(kafka_host, kafka_port,
                               [kafka_evaluator_topic, kafka_rules_results_topic], kafka_group_id)
    evaluator.run()


if __name__ == "__main__":
    main()
