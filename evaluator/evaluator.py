#!/usr/bin/python3
import os
import logging
import json
import requests
from psycopg2.extras import execute_values

from kafka import KafkaConsumer, KafkaProducer

from database.database_handler import DatabaseHandler, init_db

VMAAS_HOST = os.getenv('VMAAS_HOST', 'webapp-vmaas-stable.1b13.insights.openshiftapps.com')
kafka_host = os.getenv('KAFKA_HOST', 'kafka-1.vmaas-ci.svc')
kafka_port = os.getenv('KAFKA_PORT', '29092')
kafka_evaluator_topic = os.getenv('EVALUATOR_TOPIC', 'vulnerability_evaluator_requests')
kafka_rules_requests_topic = os.getenv('RULES_REQUESTS_TOPIC', 'rules_engine_requests')
kafka_rules_results_topic = os.getenv('RULES_RESULTS_TOPIC', 'rules_engine_results')
kafka_group_id = os.getenv('KAFKA_GROUP_ID', 'vulnerability')

logging.basicConfig(
    format='%(asctime)s.%(msecs)s:%(name)s:%(thread)d:%(levelname)s:%(process)d:%(message)s',
    level=logging.INFO
)


class QueueEvaluator:
    """ This class contains logic for the processing new available
        updates from VMaaS.
    """
    def __init__(self, kafka_host, kafka_port, kafka_topics, kafka_group):
        # connect to the Messaging Service
        bootstrap_server = kafka_host + ':' + kafka_port
        self.consumer = KafkaConsumer(*kafka_topics,
                          bootstrap_servers=bootstrap_server,
                          group_id=kafka_group,
                          auto_offset_reset='latest',
                          )

        logging.info("Using BOOTSTRAP_SERVERS: %s" % bootstrap_server)
        logging.info("Using GROUP_ID: %s" % kafka_group)
        logging.info("Using TOPICS: %s" % ", ".join(kafka_topics))

        self.producer = KafkaProducer(bootstrap_servers=bootstrap_server)

        self.vmaas_updates_endpoint = 'https://' + VMAAS_HOST + '/api/v1/updates'
        self.vmaas_errata_endpoint = 'https://' + VMAAS_HOST + '/api/v1/errata'
        self.vmaas_cves_endpoint = 'https://' + VMAAS_HOST + '/api/v1/cves'

        # get DB connection
        init_db()
        self.conn = DatabaseHandler.get_connection()
    
    def _store_cves(self, system_id, system_cves, source_name="VMAAS"):
        if system_cves:
            cur = self.conn.cursor()
            cur.execute("select cve from system_vulnerabilities where platform_id = %s and \
                        when_mitigated is NULL",  (system_id,))

            current_cves = set()

            for row in cur.fetchall():
                current_cves.add(row[0])

            new_cves = system_cves.difference(current_cves)
            mitigated_cves = current_cves.difference(system_cves)

            cur.execute("select id from vulnerability_source where name = %s", (source_name,))
            source_id = cur.fetchall()[0][0]

            # if system has got new vulnerabilities with new CVEs
            if new_cves:
                # JSON to POST requests to vmaas CVEs endpoint
                cves_json = {'cve_list': list(new_cves)}
                cve_cvss3_list = []
                cve_system_list = []

                r = requests.post(self.vmaas_cves_endpoint, json=cves_json)
                if r.status_code == 200:

                    cves_response_json = json.loads(r.text)

                    # FIXME: getting metadata from DB on every system update should be optimized
                    cur.execute("select cve from cve_metadata")
                    cves_in_db = []
                    for cve_tuple in cur.fetchall():
                        cves_in_db.append(cve_tuple[0])

                    for cve in cves_response_json['cve_list']:
                        if cve not in cves_in_db:
                            # need also add a new CVE metadata into DB
                            cvss3_score = float(cves_response_json['cve_list'][cve]['cvss3_score'])
                            cve_cvss3_list.append((cve, cvss3_score))

                        cve_system_list.append((system_id, cve, source_id))

                    # Insert new CVEs into db
                    if cve_cvss3_list:
                        execute_values(cur, "insert into cve_metadata (cve, cvss3_score) values %s",
                                        cve_cvss3_list, page_size=len(cve_cvss3_list))

                    execute_values(cur, "insert into system_vulnerabilities \
                                    (platform_id, cve, vulnerability_source) values %s",
                                    cve_system_list, page_size=len(cve_system_list))

                else:
                    logging.error("Error during request to VMaaS endpoint " + self.vmaas_cves_endpoint)
                    logging.debug("Updates JSON: " + str(cves_json))

            if mitigated_cves:
                cur.execute("update system_vulnerabilities set when_mitigated = now() \
                where platform_id = %s and vulnerability_source = %s and cve in %s", (system_id,
                                                                                      source_id,
                                                                                      tuple(mitigated_cves),))
            cur.close()
            self.conn.commit()

    def _sync_cve_md(self, page_size=200, page=1, cves_in_db=None):
        cur = self.conn.cursor()
        if not cves_in_db:
            cur.execute('select cve from cve_metadata')
            cves_in_db = []
            for cve_tuple in cur.fetchall():
                cves_in_db.append(cve_tuple[0])
        while True:
            cve_list = {'cve_list' : [".*"], 'page_size' : page_size, 'page': page}
            response = requests.post(self.vmaas_cves_endpoint, json=cve_list)
            if response.status_code != 200:
                break
            r_json = response.json()
            logging.info('syncing cve_metadata from vmaas: page: %s, page_size: %s, pages: %s' % (page, page_size, r_json['pages']))
            cves = r_json['cve_list']
            to_insert = []
            to_update = []
            for cve in cves:
                description = cves[cve]['description']
                impact = cves[cve]['impact']
                public_date = cves[cve]['public_date'] or None
                modified_date = cves[cve]['modified_date'] or None
                cvss3_score = float(cves[cve]['cvss3_score']) if cves[cve]['cvss3_score'] else None
                cvss3_metrics = cves[cve]['cvss3_metrics']
                row = (cve, description, impact, public_date, modified_date, cvss3_score, cvss3_metrics)
                if cve not in cves_in_db:
                    to_insert.append(row)
                else:
                    to_update.append(row)
            if to_insert:
                execute_values(cur, """insert into cve_metadata
                                    (cve, description, impact, public_date, modified_date, cvss3_score, cvss3_metrics)
                                    values %s""", to_insert, page_size=len(to_insert))
            if to_update:
                execute_values(cur, """update cve_metadata set description = data.description, impact = data.impact,
                                    public_date = cast(data.public_date as timestamp with time zone),
                                    modified_date = cast(data.modified_date as timestamp with time zone),
                                    cvss3_score = data.cvss3_score, cvss3_metrics = data.cvss3_metrics
                                    from (values %s) as data (cve, description, impact, public_date, modified_date,
                                    cvss3_score, cvss3_metrics) where cve_metadata.cve = data.cve""",
                               to_update, page_size=len(to_update))
            if page >= r_json['pages']:
                break
            page += 1
        cur.close()
        self.conn.commit()
    
    def evaluate_vmaas(self, system_platform):
        # JSON to POST requests to vmaas updates endpoint
        updates_json = json.loads(system_platform[1])
        # JSON to POST requests to vmaas errata endpoint
        errata_json = {'errata_list': []}

        system_errata = set()
        system_cves = set()

        r = requests.post(self.vmaas_updates_endpoint, json=updates_json)
        if r.status_code == 200:
            updates_response_json = json.loads(r.text)
            for pkg in updates_response_json['update_list']:
                for upd in updates_response_json['update_list'][pkg].get('available_updates', []):
                    system_errata.add(upd['erratum'])
        else:
            logging.error("Error during request to VMaaS endpoint " + self.vmaas_updates_endpoint)
            logging.debug("Updates JSON: " + str(updates_json))

        if system_errata:
            errata_json['errata_list'] = list(system_errata)
            r = requests.post(self.vmaas_errata_endpoint, json=errata_json)

            if r.status_code == 200:
                errata_response_json = json.loads(r.text)

                for erratum in errata_response_json['errata_list']:
                    for cve in errata_response_json['errata_list'][erratum]['cve_list']:
                        system_cves.add(cve)
            else:
                logging.error("Error during request to VMaaS endpoint " + self.vmaas_errata_endpoint)
                logging.debug("Updates JSON: " + str(errata_json))

        self._store_cves(system_platform[0], system_cves, source_name="VMAAS")

    def evaluate_rules(self, rules_engine_response):
        system_cves = set()

        for report in rules_engine_response["reports"]:
            # FIXME: get CVE IDs properly when they are available in rules results
            rule_id = report["rule_id"].upper()
            rule_id = rule_id.split("|")[0] # strip error key
            rule_id = rule_id.replace("_", "-")
            cve_id_parts = rule_id.split("-")
            if cve_id_parts[0] == "CVE" and cve_id_parts[1].isdigit() and cve_id_parts[2].isdigit():
                system_cves.add("%s-%s-%s" % (cve_id_parts[0], cve_id_parts[1], cve_id_parts[2]))

        system_id = rules_engine_response["system"]["system_id"]
        self._store_cves(system_id, system_cves, source_name="RULES")

    def _prepare_rules_engine_request(self, listener_msg):
        return {
            "plugins": ["vmaas"],
            "rh_account": listener_msg["rh_account"],
            "url": listener_msg["url"],
            "hash": listener_msg["hash"]
        }

    def run(self):
        """
        This method process messages with type 'vmaas_updates'
        :return:
        """

        cur = self.conn.cursor()
        cur.execute('select count(*) from cve_metadata')
        cve_md_count = int(cur.fetchone()[0])
        if cve_md_count == 0:
            logging.info('no cve_metadata found, attempting to pull them from vmaas')
            self._sync_cve_md()
        for message in self.consumer:
            if message.topic == kafka_evaluator_topic:
                msg_dict = json.loads(message.value.decode('utf-8'))
                if 'type' not in msg_dict:
                    logging.error("Received message is missing type field: %s", msg_dict)
                    continue
                if msg_dict['type'] == 'vmaas_updates':
                    self._sync_cve_md()
                    logging.info("Received message type: %s", msg_dict['type'])
                    cur.execute("select platform_id, vmaas_json from system_platform")
                    # reevaluate updates for every system in the DB
                    for system_platform in cur.fetchall():
                        self.evaluate_vmaas(system_platform)
                elif msg_dict['type'] == 'upload_new_file':
                    logging.info("Received message type: %s", msg_dict['type'])
                    cur.execute("select platform_id, vmaas_json from system_platform where platform_id = %s", (msg_dict['system_id'],))
                    system_platform = cur.fetchone()
                    if system_platform is not None:
                        self.producer.send(kafka_rules_requests_topic,
                                           json.dumps(self._prepare_rules_engine_request(msg_dict)).encode("utf8"))
                        self.evaluate_vmaas(system_platform)
                    else:
                        logging.error("System with platform_id not found in DB: %s", msg_dict['system_id'])
                else:
                    logging.error("Received unknown message type: %s", msg_dict['type'])
            elif message.topic == kafka_rules_results_topic:
                logging.info("Received message on topic: %s", message.topic)
                msg_dict = json.loads(message.value.decode('utf-8'))
                self.evaluate_rules(msg_dict)
            else:
                logging.error("Received message on unsupported topic: %s", message.topic)

        self.consumer.close()
        cur.close()
        self.conn.commit()

def main():
    evaluator = QueueEvaluator(kafka_host, kafka_port, [kafka_evaluator_topic, kafka_rules_results_topic], kafka_group_id)
    evaluator.run()


if __name__ == "__main__":
    main()