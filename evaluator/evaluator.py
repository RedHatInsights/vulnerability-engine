#!/usr/bin/python3
"""
vulnerability-engine evaluator
"""

import os
import json
import requests
from prometheus_client import Histogram, start_http_server
from psycopg2.extras import execute_values

from common import mqueue
from common.database_handler import DatabaseHandler, init_db
from common.logging import init_logging, get_logger

LOGGER = get_logger(__name__)

VMAAS_HOST = os.getenv('VMAAS_HOST', 'http://vmaas-webapp-1.vmaas-ci.svc:8080') # pylint: disable=invalid-name
vmaas_updates_endpoint = "%s/api/v1/updates" % VMAAS_HOST # pylint: disable=invalid-name
vmaas_errata_endpoint = "%s/api/v1/errata" % VMAAS_HOST # pylint: disable=invalid-name
vmaas_cves_endpoint = "%s/api/v1/cves" % VMAAS_HOST # pylint: disable=invalid-name
kafka_host = os.getenv('KAFKA_HOST', 'kafka-1.vmaas-ci.svc') # pylint: disable=invalid-name
kafka_port = os.getenv('KAFKA_PORT', '29092') # pylint: disable=invalid-name
kafka_evaluator_topic = os.getenv('EVALUATOR_TOPIC', 'vulnerability.evaluator.requests') # pylint: disable=invalid-name
kafka_rules_requests_topic = os.getenv('RULES_REQUESTS_TOPIC', 'vulnerability.rules-engine.requests') # pylint: disable=invalid-name
kafka_rules_results_topic = os.getenv('RULES_RESULTS_TOPIC', 'vulnerability.rules-engine.results') # pylint: disable=invalid-name
kafka_group_id = os.getenv('KAFKA_GROUP_ID', 'vulnerability') # pylint: disable=invalid-name
prometheus_port = os.getenv('PROMETHEUS_PORT', '8085') # pylint: disable=invalid-name

VMAAS_EVAL_TIME = Histogram('evaluator_vmaas_evaluation_seconds', 'Time spent checking a system for vmaas hits')
RULES_EVAL_TIME = Histogram('evaluator_rules_evaluation_seconds', 'Time spent checking a system for rules-hits')


class QueueEvaluator:
    """ This class contains logic for the processing new available
        updates from VMaaS.
    """
    def __init__(self, kafka_host_in, kafka_port_in, kafka_topics_in, kafka_group_in):
        # connect to the Messaging Service
        bootstrap_server = kafka_host_in + ':' + kafka_port_in
        self.consumer = mqueue.MQReader(kafka_topics_in, # [kafka_evaluator_topic, kafka_rules_results_topic],
                                        group_id=kafka_group_in,
                                        bootstrap_servers=bootstrap_server)

        LOGGER.info("Using BOOTSTRAP_SERVERS: %s", bootstrap_server)
        LOGGER.info("Using GROUP_ID: %s", kafka_group_in)
        LOGGER.info("Using TOPICS: %s", ", ".join(kafka_topics_in))

        self.producer = mqueue.MQWriter(kafka_rules_requests_topic, bootstrap_servers=bootstrap_server)

        # get DB connection
        init_db()
        self.conn = DatabaseHandler.get_connection()
        self.rule_id_map = self._prepare_rule_id_map()
        self.impact_id_map = self._prepare_impact_id_map()
        self.source_id_map = self._prepare_source_id_map()

    def _prepare_rule_id_map(self):
        rule_id_map = {}
        cur = self.conn.cursor()
        cur.execute("select name, id from prodsec_rule")
        for rule_id_name, prodsec_rule_id in cur.fetchall():
            rule_id_map[rule_id_name] = prodsec_rule_id
        cur.close()
        return rule_id_map

    def _prepare_impact_id_map(self):
        impact_id_map = {}
        cur = self.conn.cursor()
        cur.execute("select name, id from cve_impact")
        for impact_name, impact_id in cur.fetchall():
            impact_id_map[impact_name] = impact_id
        cur.close()
        return impact_id_map

    def _prepare_source_id_map(self):
        source_id_map = {}
        cur = self.conn.cursor()
        cur.execute("select name, id from vulnerability_source")
        for source_name, source_id in cur.fetchall():
            source_id_map[source_name] = source_id
        cur.close()
        return source_id_map

    def _load_cves_for_inventory_id(self, inventory_id):
        system_cves_map = {}
        cur = self.conn.cursor()
        cur.execute("select id, cve, vulnerability_source, first_reported, when_mitigated \
                       from system_vulnerabilities where inventory_id = %s", (inventory_id,))
        for sys_vuln_id, cve, source_id, first_reported, when_mitigated in cur.fetchall():
            sys_vuln = {'id': sys_vuln_id,
                        'cve': cve,
                        'vulnerability_source': source_id,
                        'first_reported': first_reported,
                        'when_mitigated': when_mitigated}
            system_cves_map[cve] = sys_vuln
        cur.close()
        return system_cves_map

    def _load_cves_prodsec_rule_ids(self, inventory_id):
        system_cves_prodsec_rule_ids = {}
        cur = self.conn.cursor()
        cur.execute("select sv.id, sv.cve, svr.prodsec_rule_id \
                       from system_vulnerabilities sv \
                       join sys_vuln_rules_results svr \
                         on sv.id = svr.sys_vuln_id \
                      where sv.inventory_id = %s", (inventory_id,))
        for sys_vuln_id, cve, prodsec_rule_id in cur.fetchall():
            entry = system_cves_prodsec_rule_ids.setdefault(cve, {'id': sys_vuln_id, 'prodsec_rule_ids': set()})
            entry['prodsec_rule_ids'].add(prodsec_rule_id)
        cur.close()
        return system_cves_prodsec_rule_ids

    def _store_new_cves(self, inventory_id, new_cves, vulnerability_source):
        system_cves_id_map = {}
        if not new_cves:
            return system_cves_id_map

        # JSON to POST requests to vmaas CVEs endpoint
        cves_json = {'cve_list': list(new_cves)}
        cve_cvss_list = []
        cve_system_list = []

        response = requests.post(vmaas_cves_endpoint, json=cves_json)
        if response.status_code == 200:

            cves_response_json = json.loads(response.text)

            cur = self.conn.cursor()
            # FIXME: getting metadata from DB on every system update should be optimized
            cur.execute("select cve from cve_metadata where cve in %s", (tuple(new_cves),))
            cves_in_db = []
            for cve_tuple in cur.fetchall():
                cves_in_db.append(cve_tuple[0])

            for cve in cves_response_json['cve_list']:
                if cve not in cves_in_db:
                    # need also add a new CVE metadata into DB
                    cve_resp = cves_response_json['cve_list'][cve]
                    cvss3_score = float(cve_resp['cvss3_score']) if cve_resp.get('cvss3_score') else None
                    cvss2_score = float(cve_resp['cvss2_score']) if cve_resp.get('cvss2_score') else None
                    cve_cvss_list.append((cve, cvss3_score, cvss2_score))

                cve_system_list.append((inventory_id, cve, vulnerability_source))

            # Insert new CVEs into db
            if cve_cvss_list:
                execute_values(cur, "insert into cve_metadata (cve, cvss3_score, cvss2_score) values %s",
                               cve_cvss_list, page_size=len(cve_cvss_list))

            if cve_system_list:
                execute_values(cur, "insert into system_vulnerabilities \
                               (inventory_id, cve, vulnerability_source) values %s \
                               returning cve, id",
                               cve_system_list, page_size=len(cve_system_list))

                for cve, sys_vuln_id in cur.fetchall():
                    system_cves_id_map[cve] = sys_vuln_id
            cur.close()
            self.conn.commit()
        else:
            LOGGER.error("Error during request to VMaaS endpoint %s", vmaas_cves_endpoint)
            LOGGER.debug("Updates JSON: %s", str(cves_json))
        return system_cves_id_map

    def _update_mitigated_cves(self, inventory_id, mitigated_cves, vulnerability_source):
        if not mitigated_cves:
            return

        cur = self.conn.cursor()
        cur.execute("update system_vulnerabilities set when_mitigated = now() \
        where inventory_id = %s and vulnerability_source = %s and cve in %s", (inventory_id,
                                                                               vulnerability_source,
                                                                               tuple(mitigated_cves),))
        cur.close()
        self.conn.commit()

    def _update_unmitigated_cves(self, inventory_id, unmitigated_cves, vulnerability_source):
        if not unmitigated_cves:
            return

        cur = self.conn.cursor()
        cur.execute("update system_vulnerabilities set when_mitigated = null, \
                    first_reported = now() where inventory_id = %s and \
                    vulnerability_source = %s and cve in %s", (inventory_id,
                                                               vulnerability_source,
                                                               tuple(unmitigated_cves),))
        cur.close()
        self.conn.commit()

    def _change_cve_source(self, inventory_id, source_change_cves, vulnerability_source):
        if not source_change_cves:
            return

        cur = self.conn.cursor()
        cur.execute("update system_vulnerabilities set when_mitigated = null, \
                    first_reported = now(), vulnerability_source = %s \
                    where inventory_id = %s and cve in %s", (vulnerability_source,
                                                             inventory_id,
                                                             tuple(source_change_cves),))
        cur.close()
        self.conn.commit()

    def _update_rule_id_map(self, rule_ids):
        # Populate rule ids not yet in DB
        if not rule_ids:
            return

        new_rule_ids = [(key,) for key in rule_ids if key not in self.rule_id_map]
        if new_rule_ids:
            cur = self.conn.cursor()
            execute_values(cur, "insert into prodsec_rule (name) values %s returning name, id",
                           new_rule_ids, page_size=len(new_rule_ids))

            for rule_id_name, prodsec_rule_id in cur.fetchall():
                self.rule_id_map[rule_id_name] = prodsec_rule_id
            cur.close()
            self.conn.commit()

    def _rules_insert(self, rules_to_insert):
        if not rules_to_insert:
            return
        cur = self.conn.cursor()
        execute_values(cur, "insert into sys_vuln_rules_results \
                             (sys_vuln_id, prodsec_rule_id, details) \
                             values %s", rules_to_insert, page_size=len(rules_to_insert))
        cur.close()
        self.conn.commit()

    def _rules_update(self, rules_to_update):
        if not rules_to_update:
            return
        cur = self.conn.cursor()
        execute_values(cur, "update sys_vuln_rules_results set \
                                 details = data.details \
                             from (values %s) as data (sys_vuln_id, ek_id, details) \
                             where sys_vuln_rules_results.sys_vuln_id = data.sys_vuln_id \
                                 and sys_vuln_rules_results.prodsec_rule_id = data.ek_id",
                       rules_to_update, page_size=len(rules_to_update))
        cur.close()
        self.conn.commit()

    def _rules_delete(self, rules_to_delete):
        if not rules_to_delete:
            return
        cur = self.conn.cursor()
        for entry in rules_to_delete:
            execute_values(cur, "delete from sys_vuln_rules_results \
                                 where sys_vuln_id = %s and \
                                 prodsec_rule_id = %s", entry)
        cur.close()
        self.conn.commit()

    def _sync_cve_md(self, page_size=5000, page=1, cves_in_db=None):
        cur = self.conn.cursor()
        if not cves_in_db:
            cur.execute('select cve from cve_metadata')
            cves_in_db = []
            for cve_tuple in cur.fetchall():
                cves_in_db.append(cve_tuple[0])
        while True:
            cve_list = {'cve_list' : [".*"], 'page_size' : page_size, 'page': page, 'rh_only' : True}
            try:
                response = requests.post(vmaas_cves_endpoint, json=cve_list)
            except requests.exceptions.ConnectionError as exc:
                LOGGER.warning('Error calling VMAAS: %s', str(exc))
                break
            if response.status_code != 200:
                LOGGER.warning('Received %s from VMAAS, details: %s', response.status_code, response.text)
                break
            r_json = response.json()
            LOGGER.info('syncing cve_metadata from vmaas: page: %s, page_size: %s, pages: %s',
                        page, page_size, r_json['pages'])
            cves = r_json['cve_list']
            to_insert = []
            to_update = []
            for cve in cves:
                description = cves[cve]['description']
                impact_id = self.impact_id_map[cves[cve]['impact']]
                public_date = cves[cve]['public_date'] or None
                modified_date = cves[cve]['modified_date'] or None
                cvss3_score = float(cves[cve]['cvss3_score']) if cves[cve].get('cvss3_score') else None
                cvss3_metrics = cves[cve].get('cvss3_metrics')
                cvss2_score = float(cves[cve]['cvss2_score']) if cves[cve].get('cvss2_score') else None
                cvss2_metrics = cves[cve].get('cvss2_metrics')
                row = (cve, description, impact_id, public_date, modified_date, cvss3_score, cvss3_metrics,
                       cvss2_score, cvss2_metrics)
                if cve not in cves_in_db:
                    to_insert.append(row)
                else:
                    to_update.append(row)
            if to_insert:
                execute_values(cur, """insert into cve_metadata
                                    (cve, description, impact_id, public_date, modified_date,
                                    cvss3_score, cvss3_metrics, cvss2_score, cvss2_metrics)
                                    values %s""", to_insert, page_size=len(to_insert))
            if to_update:
                execute_values(cur, """update cve_metadata set description = data.description,
                               impact_id = data.impact_id,
                               public_date = cast(data.public_date as timestamp with time zone),
                               modified_date = cast(data.modified_date as timestamp with time zone),
                               cvss3_score = cast(data.cvss3_score as numeric),
                               cvss3_metrics = data.cvss3_metrics,
                               cvss2_score = cast(data.cvss2_score as numeric),
                               cvss2_metrics = data.cvss2_metrics
                               from (values %s) as data (cve, description, impact_id, public_date, modified_date,
                               cvss3_score, cvss3_metrics, cvss2_score, cvss2_metrics)
                               where cve_metadata.cve = data.cve""",
                               to_update, page_size=len(to_update))
            if page >= r_json['pages']:
                break
            page += 1
        cur.close()
        self.conn.commit()

    @staticmethod
    def _vmaas_request_cves(updates_json):
        """Make VMaaS request for updates, then cves returning them"""
        system_errata = set()
        system_cves = set()

        response = requests.post(vmaas_updates_endpoint, json=updates_json)
        if response.status_code == 200:
            updates_response_json = json.loads(response.text)
            for pkg in updates_response_json['update_list']:
                for upd in updates_response_json['update_list'][pkg].get('available_updates', []):
                    system_errata.add(upd['erratum'])
        else:
            LOGGER.error("Error during request to VMaaS endpoint %s", vmaas_updates_endpoint)
            LOGGER.debug("Updates JSON: %s", str(updates_json))

        if system_errata:
            # JSON to POST requests to vmaas errata endpoint
            errata_json = {'errata_list': list(system_errata)}
            response = requests.post(vmaas_errata_endpoint, json=errata_json)

            if response.status_code == 200:
                errata_response_json = json.loads(response.text)

                for erratum in errata_response_json['errata_list']:
                    for cve in errata_response_json['errata_list'][erratum]['cve_list']:
                        system_cves.add(cve)
            else:
                LOGGER.error("Error during request to VMaaS endpoint %s", vmaas_errata_endpoint)
                LOGGER.debug("Updates JSON: %s", str(errata_json))
        return system_cves

    @VMAAS_EVAL_TIME.time()
    def evaluate_vmaas(self, system_platform):
        """Evaluates messages received from vmaas"""
        inventory_id = system_platform[0]
        # JSON to POST requests to vmaas updates endpoint
        updates_json = json.loads(system_platform[1])

        system_cves = self._vmaas_request_cves(updates_json)

        if system_cves:
            system_cves_map = self._load_cves_for_inventory_id(inventory_id)
            unmitigated_cves = set()
            mitigated_cves = set()
            unprocessed_cves = set(system_cves_map.keys())
            new_cves = set()
            for cve in system_cves:
                if cve in system_cves_map:
                    unprocessed_cves.discard(cve)
                    if system_cves_map[cve]['vulnerability_source'] != self.source_id_map['VMAAS']:
                        # skip this one, it's a RULES vulnerability and
                        # takes precedence over VMAAS
                        continue
                    if system_cves_map[cve]['when_mitigated']:
                        # it was mitigated, now its not
                        unmitigated_cves.add(cve)
                else:
                    new_cves.add(cve)
            for cve in unprocessed_cves:
                if system_cves_map[cve]['vulnerability_source'] == self.source_id_map['VMAAS']:
                    mitigated_cves.add(cve)
            self._store_new_cves(inventory_id, new_cves, self.source_id_map['VMAAS'])
            self._update_mitigated_cves(inventory_id, mitigated_cves, self.source_id_map['VMAAS'])
            self._update_unmitigated_cves(inventory_id, unmitigated_cves, self.source_id_map['VMAAS'])

    def _process_rules_results(self, rules_engine_reports):
        """Process the list of reports in the rules engine response.
           This returns a dict, keyed on cve, whose value is a list
           of dict's containing 'rule_id' and the string decoded from
           json of the 'details' we will need to provide to
           Remediations.  As a side effect, any rule ids not already
           in the rule_id_map are added."""
        results_cves = {}
        results_rule_ids = set()

        for report in rules_engine_reports:
            LOGGER.info("REPORT------------------------")
            LOGGER.info(report)
            result_details = report.get('details', {})
            failed_cves = result_details.get("cves_fail", [])
            if failed_cves:
                results_rule_ids.add(report["rule_id"])
                for cve in failed_cves:
                    entry = results_cves.setdefault(cve, [])
                    entry.append({'rule_id': report['rule_id'], 'details': json.dumps(result_details)})

        if results_cves:
            self._update_rule_id_map(results_rule_ids)
        return results_cves

    @RULES_EVAL_TIME.time()
    def evaluate_rules(self, rules_engine_response):
        """Evaluates messages from rules engine"""
        # pylint: disable=too-many-branches
        inventory_id = rules_engine_response["system"]["system_id"]

        results_cves = self._process_rules_results(rules_engine_response["reports"])
        if not results_cves:
            return

        system_cves_map = self._load_cves_for_inventory_id(inventory_id)
        system_cves_prodsec_rule_ids = self._load_cves_prodsec_rule_ids(inventory_id)
        change_to_rules_cves = set()
        unmitigated_cves = set()
        mitigated_cves = set(system_cves_map.keys())
        new_cves = set()
        rule_results_insert = [] # (sys_vuln_id, prodsec_rule_id, details)
        rule_results_update = [] # (sys_vuln_id, prodsec_rule_id, details)
        rule_results_delete = [] # (sys_vuln_id, prodsec_rule_id)
        for cve in results_cves:
            if cve in system_cves_map:
                mitigated_cves.discard(cve)
                if system_cves_map[cve]['vulnerability_source'] != self.source_id_map['RULES']:
                    change_to_rules_cves.add(cve)
                if system_cves_map[cve]['when_mitigated']:
                    # it was mitigated, now its not
                    unmitigated_cves.add(cve)
                for entry in results_cves[cve]:
                    prodsec_rule_id = self.rule_id_map[entry['rule_id']]
                    need_insert = True
                    if cve in system_cves_prodsec_rule_ids:
                        if prodsec_rule_id in system_cves_prodsec_rule_ids[cve]['prodsec_rule_ids']:
                            need_insert = False
                            row = (system_cves_map[cve]['id'], prodsec_rule_id, entry['details'])
                            rule_results_update.append(row)
                            system_cves_prodsec_rule_ids[cve]['prodsec_rule_ids'].discard(prodsec_rule_id)
                    if need_insert:
                        row = (system_cves_map[cve]['id'], prodsec_rule_id, entry['details'])
                        rule_results_insert.append(row)
                if cve in system_cves_prodsec_rule_ids:
                    for prodsec_rule_id in system_cves_prodsec_rule_ids[cve]['prodsec_rule_ids']:
                        row = (system_cves_map[cve]['id'], prodsec_rule_id)
                        rule_results_delete.append(row)
            else:
                new_cves.add(cve)
        cves_id_map = self._store_new_cves(inventory_id, new_cves, self.source_id_map['RULES'])
        for cve in new_cves:
            for entry in results_cves[cve]:
                prodsec_rule_id = self.rule_id_map[entry['rule_id']]
                row = (cves_id_map[cve], prodsec_rule_id, entry['details'])
                rule_results_insert.append(row)
        self._change_cve_source(inventory_id, change_to_rules_cves, self.source_id_map['RULES'])
        self._update_mitigated_cves(inventory_id, mitigated_cves, self.source_id_map['RULES'])
        self._update_unmitigated_cves(inventory_id, unmitigated_cves, self.source_id_map['RULES'])
        self._rules_delete(rule_results_delete)
        self._rules_insert(rule_results_insert)
        self._rules_update(rule_results_update)

    def _prepare_rules_engine_request(self, listener_msg): # pylint: disable=no-self-use
        return {
            "plugins": ["vmaas"],
            "rh_account": listener_msg["rh_account"],
            "url": listener_msg["url"],
            # FIXME: remove this field as soon as we remove this from rules-engine
            # (it's used for upload validation and this code shouldn't be here anymore)
            "hash": listener_msg["payload_id"]
        }

    def run(self):
        """
        This method process messages with type 'vmaas_updates'
        :return:
        """

        # pylint: disable=too-many-branches
        cur = self.conn.cursor()
        cur.execute('select count(*) from cve_metadata')
        cve_md_count = int(cur.fetchone()[0])
        if cve_md_count == 0:
            LOGGER.info('no cve_metadata found, attempting to pull them from vmaas')
            self._sync_cve_md()

        def process_message(message):
            """Message procession logic"""
            if message.topic == kafka_evaluator_topic:
                msg_dict = json.loads(message.value.decode('utf-8'))
                if 'type' not in msg_dict:
                    LOGGER.error("Received message is missing type field: %s", msg_dict)
                    return
                if msg_dict['type'] == 'vmaas_updates':
                    LOGGER.info("Received message type: %s", msg_dict['type'])
                    self._sync_cve_md()
                    cur.execute("select inventory_id, vmaas_json from system_platform")
                    # reevaluate updates for every system in the DB
                    for system_platform in cur.fetchall():
                        self.evaluate_vmaas(system_platform)
                elif msg_dict['type'] == 'upload_new_file':
                    LOGGER.info("Received message type: %s", msg_dict['type'])
                    cur.execute("select inventory_id, vmaas_json from system_platform where inventory_id = %s",
                                (msg_dict['system_id'],))
                    system_platform = cur.fetchone()
                    if system_platform is not None:
                        # stop kicking off rules-engine processing to avoid
                        # log messages about failure to find inventory_id
                        # in db.  Rule-engine is sending back system_id, not
                        # inventory_id.
                        # self.producer.send(self._prepare_rules_engine_request(msg_dict))
                        self.evaluate_vmaas(system_platform)
                    else:
                        LOGGER.error("System with inventory_id not found in DB: %s", msg_dict['system_id'])
                else:
                    LOGGER.error("Received unknown message type: %s", msg_dict['type'])
            elif message.topic == kafka_rules_results_topic:
                LOGGER.info("Received message on topic: %s", message.topic)
                msg_dict = json.loads(message.value.decode('utf-8'))
                cur.execute("select inventory_id from system_platform where inventory_id = %s",
                            (msg_dict["system"]["system_id"],))
                system_platform = cur.fetchone()
                if system_platform is not None:
                    self.evaluate_rules(msg_dict)
                else:
                    LOGGER.error("System with inventory_id not found in DB: %s", msg_dict["system"]["system_id"])
            else:
                LOGGER.error("Received message on unsupported topic: %s", message.topic)

        self.consumer.listen(process_message)
        cur.close()
        self.conn.commit()

def main():
    """Sets up and runs the evaluator"""
    evaluator = QueueEvaluator(kafka_host, kafka_port,
                               [kafka_evaluator_topic, kafka_rules_results_topic], kafka_group_id)
    evaluator.run()


if __name__ == "__main__":
    # Set up endpoint for prometheus monitoring
    init_logging()
    LOGGER.info("Opening port [%s] for prometheus", prometheus_port)
    start_http_server(int(prometheus_port))
    main()
