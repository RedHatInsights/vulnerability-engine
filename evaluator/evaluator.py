#!/usr/bin/env python3
"""
vulnerability-engine evaluator
"""
from collections import namedtuple

import json
import asyncio
import ssl
import asyncpg
from prometheus_client import Counter, Histogram

from common import mqueue
from common.config import Config
from common.logging import init_logging, get_logger
from common.utils import send_msg_to_payload_tracker, send_remediations_update, a_ensure_minimal_schema_version, get_available_remediation_type, \
    release_semaphore, send_notifications
from common.vmaas_client import vmaas_request
from common.status_app import create_status_app, create_status_runner

LOGGER = get_logger(__name__)
CFG = Config()

PROMETHEUS_PORT = CFG.prometheus_port or str(CFG.evaluator_prometheus_port)

# database pool instance
DB_POOL = None

# prometheus probes
# times
VMAAS_EVAL_TIME = Histogram('ve_evaluator_vmaas_evaluation_seconds', 'Time spent checking a system for vmaas hits',
                            buckets=[0.1, 0.25, 0.5, 0.75, 1.0, 1.5, 2, 5])
# counts
VMAAS_COUNT = Counter('ve_evaluator_vmaas_calls', 'Number of VMaaS-evaluations attempted')
INV_ID_NOT_FOUND = Counter('ve_evaluator_inventory_not_found', 'Number of times inventory-id not in SystemPlatform')
UNKNOWN_MSG = Counter('ve_evaluator_unknown_msg', 'Number of unrecognized messages delivered from queue')
UNKNOWN_TOPIC = Counter('ve_evaluator_unknown_topic', 'Number of times message delivered from unsupported topic')
MESSAGE_PARSE_ERROR = Counter('ve_evaluator_message_parse_error', '# of message parse errors')
VMAAS_ERRORS_SKIP = Counter('ve_evaluator_vmaas_errors_skip', '# of evaluations skipped due to VMaaS errors')
STORE_FAILED = Counter('ve_evaluator_store_failed', '# of failed evaluations')

CONSUMER_QUEUE = mqueue.MQReader(CFG.evaluator_topics)
PAYLOAD_TRACKER_PRODUCER = mqueue.MQWriter(CFG.payload_tracker_topic)
REMEDIATIONS_PRODUCER = mqueue.MQWriter(CFG.remediation_updates_topic)
EVALUATOR_RESULTS = mqueue.MQWriter(CFG.evaluator_results_topic)

MAIN_LOOP = asyncio.get_event_loop()
MAX_MESSAGES_SEMAPHORE = asyncio.BoundedSemaphore(CFG.max_loaded_evaluator_msgs)

Cve = namedtuple("Cve", ["name", "errata"])
ErrataHasPlaybook = namedtuple("ErrataHasPlaybook", ["errata", "has_playbook"])
CveIdErrata = namedtuple("CveIdErrata", ["id", "errata"])


async def _load_cves_for_inventory_id(rh_account_id, system_id, conn):
    system_cves_map = {}
    for record in await conn.fetch("""select cm.id, cm.cve, sv.id as sv_id, sv.when_mitigated, sv.mitigation_reason, sv.advisories,
                                             ir.active, ir.playbook_count, ir.rule_only
                                        from system_vulnerabilities sv
                                        join cve_metadata cm on sv.cve_id = cm.id
                                        left outer join insights_rule ir on sv.rule_id = ir.id
                                       where sv.system_id = $1 and sv.rh_account_id = $2""", system_id, rh_account_id):
        system_cves_map[record["cve"]] = {"sv_id": record["sv_id"],
                                          "cve_id": record["id"],
                                          "when_mitigated": record["when_mitigated"],
                                          "mitigation_reason": record["mitigation_reason"],
                                          "advisories": record["advisories"],
                                          "active_rule": record["active"],
                                          "playbook_count": record["playbook_count"],
                                          "rule_only": record["rule_only"]}
    return system_cves_map


async def _register_missing_cves(missing_cves, conn):
    new_cves = set()
    for cve in sorted(missing_cves):
        # do nothing if row exists - other evaluator or vmaas-sync just inserted it
        record = await conn.fetchrow("""INSERT INTO cve_metadata (cve, description, impact_id)
                                        VALUES ($1, $2, $3)
                                   ON CONFLICT (cve) DO UPDATE set cve = $1
                                     returning id, cve""", cve, 'unknown', 0)
        new_cves.add((record[0], record[1]))
    return new_cves


async def _store_new_cves(rh_account_id, system_id, new_cves, conn):
    new_sys_vulns = []
    new_cves_id_errata = set()
    if not new_cves:
        return new_sys_vulns

    cves_in_db = set()

    # FIXME: getting metadata from DB on every system update should be optimized
    cve_id_has_playbook = {}

    for record in await conn.fetch("""select id, cve
                                      from cve_metadata
                                      where cve = any($1::text[])""", list(new_cves.keys())):
        cve_name = record['cve']
        new_cves_id_errata.add(CveIdErrata(record['id'], new_cves[cve_name].errata))
        cves_in_db.add(cve_name)
        cve_id_has_playbook[record['id']] = new_cves[cve_name].has_playbook

    cve_metadata_missing = [new_cve for new_cve in new_cves if new_cve not in cves_in_db]

    # Insert new CVEs into db
    if cve_metadata_missing:
        missing_cves = await _register_missing_cves(cve_metadata_missing, conn)
        for new_cve in missing_cves:
            new_cves_id_errata.add(CveIdErrata(new_cve[0], new_cves[new_cve[1]].errata))
            cve_id_has_playbook[new_cve[0]] = new_cves[new_cve[1]].has_playbook

    # prepare each member in row separately as array, so asyncpg can insert it in bulk and return ids
    rh_acc_ids = []
    system_ids = []
    cve_ids = []
    adv_avails = []
    remed_ids = []
    advisories = []
    for cve_id_errata in new_cves_id_errata:
        remediation_type_id = get_available_remediation_type(cve_id_has_playbook[cve_id_errata.id], None, None, 0)
        rh_acc_ids.append(rh_account_id)
        system_ids.append(system_id)
        cve_ids.append(cve_id_errata.id)
        adv_avails.append(cve_id_has_playbook[cve_id_errata.id])
        remed_ids.append(remediation_type_id)
        advisories.append(cve_id_errata.errata)

    for row in await conn.fetch("""insert into system_vulnerabilities (rh_account_id, system_id, cve_id, advisory_available, remediation_type_id, advisories)
                                   (select * from unnest($1::int[], $2::int[], $3::int[], $4::boolean[], $5::int[], $6::text[]))
                                   returning id, cve_id""", rh_acc_ids, system_ids, cve_ids, adv_avails, remed_ids, advisories):
        new_sys_vulns.append((row[0], row[1]))
    return new_sys_vulns


async def _update_cves_advisories(rh_account_id, system_id, cves_need_udpate, conn, system_cves_map):
    if not cves_need_udpate:
        return

    cve_system_list = []
    for cve in cves_need_udpate:
        cve_system_list.append((system_id, system_cves_map[cve.name]["cve_id"], cve.errata))

    await conn.executemany(f"""update system_vulnerabilities as sv
                               set advisories = v.advisories
                               from (values ($1::int, $2::int, $3::text))
                                 as v(system_id, cve_id, advisories)
                               where sv.rh_account_id = {rh_account_id}
                                 and sv.system_id = v.system_id
                                 and sv.cve_id = v.cve_id""", cve_system_list)


async def _update_mitigated_cves(rh_account_id, system_id, mitigated_cves, conn, system_cves_map):
    if not mitigated_cves:
        return

    cve_system_list = []
    for cve in mitigated_cves:
        advisory_available = False  # No advisory available when CVE is mitigated from VMaaS side
        remediation_type_id = get_available_remediation_type(advisory_available, "now()",
                                                             system_cves_map[cve]["mitigation_reason"],
                                                             system_cves_map[cve]["playbook_count"])
        cve_system_list.append((system_id, system_cves_map[cve]["cve_id"], advisory_available, remediation_type_id))

    await conn.executemany(f"""update system_vulnerabilities as sv
                               set when_mitigated = now(),
                                   advisory_available = v.advisory_available,
                                   remediation_type_id = v.remediation_type_id
                               from (values ($1::int, $2::int, $3::boolean, $4::int))
                                 as v(system_id, cve_id, advisory_available, remediation_type_id)
                               where sv.rh_account_id = {rh_account_id}
                                 and sv.system_id = v.system_id
                                 and sv.cve_id = v.cve_id""", cve_system_list)


async def _update_unmitigated_cves(rh_account_id, system_id, unmitigated_cves, conn, system_cves_map):
    if not unmitigated_cves:
        return

    cve_system_list = []
    for cve, errata_has_playbook in unmitigated_cves.items():
        remediation_type_id = get_available_remediation_type(errata_has_playbook.has_playbook, None,
                                                             system_cves_map[cve]["mitigation_reason"],
                                                             system_cves_map[cve]["playbook_count"])
        cve_system_list.append((system_id, system_cves_map[cve]["cve_id"], errata_has_playbook.has_playbook, remediation_type_id, errata_has_playbook.errata))

    await conn.executemany(f"""update system_vulnerabilities as sv
                           set when_mitigated = null,
                               advisory_available = v.advisory_available,
                               remediation_type_id = v.remediation_type_id,
                               advisories = v.advisories
                           from (values ($1::int, $2::int, $3::boolean, $4::int, $5::text))
                             as v(system_id, cve_id, advisory_available, remediation_type_id, advisories)
                           where sv.rh_account_id = {rh_account_id}
                             and sv.system_id = v.system_id
                             and sv.cve_id = v.cve_id""", cve_system_list)


async def _update_system(system_id, cve_count, conn):
    await conn.execute("""update system_platform
                             set last_evaluation = now(), cve_count_cache = $1
                           where id = $2""", cve_count, system_id)


async def _vmaas_request_cves(vmaas_request_json):
    """Make VMaaS request for cves"""
    playbook_cves = list()
    manually_fixable_cves = list()

    if len(vmaas_request_json.get("package_list", [])) == 0 or len(vmaas_request_json.get("repository_list", [])) == 0:
        # no need to evaluate system without packages or repositories by vmaas
        return playbook_cves, manually_fixable_cves

    vulnerabilities_response_json = await vmaas_request(CFG.vmaas_vulnerabilities_endpoint,
                                                        vmaas_request_json)
    if vulnerabilities_response_json is not None:
        for cve in vulnerabilities_response_json['cve_list']:
            playbook_cves.append(Cve(cve["cve"], ",".join(sorted(cve["errata"] or [])) or None))
        for cve in vulnerabilities_response_json['manually_fixable_cve_list']:
            # manually fixable CVE never has any errata
            manually_fixable_cves.append(Cve(cve["cve"], None))
    else:
        return None, None
    return playbook_cves, manually_fixable_cves


# pylint: disable=too-many-branches,too-many-statements
async def evaluate_vmaas(system_platform, acc_num, org_id, conn):
    """Evaluates messages received from vmaas"""
    VMAAS_COUNT.inc()
    system_id = system_platform[0]
    inventory_id = system_platform[1]
    # JSON to POST requests to vmaas vulnerabilities endpoint
    vmaas_request_json = json.loads(system_platform[2])
    rh_account_id = system_platform[3]

    reported_playbook_cves, reported_manually_fixable_cves = await _vmaas_request_cves(vmaas_request_json)
    if reported_playbook_cves is None or reported_manually_fixable_cves is None:
        LOGGER.warning('Skipping evaluation of %s due to VMaaS errors.', inventory_id)
        VMAAS_ERRORS_SKIP.inc()
        return

    LOGGER.info("Evaluated vulnerabilities for inventory_id: %s (%s playbook, %s manual)", inventory_id,
                len(reported_playbook_cves), len(reported_manually_fixable_cves))
    system_cves_map = await _load_cves_for_inventory_id(rh_account_id, system_id, conn)
    unprocessed_cves = dict.fromkeys(system_cves_map.keys(), ErrataHasPlaybook(None, False))
    new_cves = dict()
    mitigated_cves = set()
    unmitigated_cves = dict()
    system_cves = []
    mit_sys_vulns = []
    unmit_sys_vulns = []
    cves_needed_update = []

    for cve in reported_playbook_cves:
        system_cves.append(cve.name)
        if cve.name in system_cves_map:
            unprocessed_cves.pop(cve.name)
            if system_cves_map[cve.name]["when_mitigated"]:
                # it was mitigated, now its not
                unmitigated_cves[cve.name] = ErrataHasPlaybook(cve.errata, True)
                unmit_sys_vulns.append((system_cves_map[cve.name]["sv_id"], system_cves_map[cve.name]["cve_id"]))
            elif cve.errata != system_cves_map[cve.name]["advisories"]:
                cves_needed_update.append(cve)
        else:
            # update errata in unprocessed list
            if cve.name in unprocessed_cves:
                unprocessed_cves[cve.name] = ErrataHasPlaybook(cve.errata, True)
            new_cves[cve.name] = ErrataHasPlaybook(cve.errata, True)

    if CFG.evaluator_manual_cves:
        for cve in reported_manually_fixable_cves:
            system_cves.append(cve.name)
            if cve.name in system_cves_map:
                unprocessed_cves.pop(cve.name)
                if system_cves_map[cve.name]['when_mitigated']:
                    # it was mitigated, now its not
                    unmitigated_cves[cve.name] = ErrataHasPlaybook(cve.errata, False)
                    unmit_sys_vulns.append((system_cves_map[cve.name]["sv_id"], system_cves_map[cve.name]["cve_id"]))
            else:
                # update errata in unprocessed list
                if cve.name in unprocessed_cves:
                    unprocessed_cves[cve.name] = ErrataHasPlaybook(cve.errata, False)
                new_cves[cve.name] = ErrataHasPlaybook(cve.errata, False)

    for cve in unprocessed_cves:  # unprocessed_cves is rest of the system_vulnerabilities which has not been reported by VMaaS
        if not system_cves_map[cve]["when_mitigated"]:
            mitigated_cves.add(cve)
            mit_sys_vulns.append((system_cves_map[cve]["sv_id"], system_cves_map[cve]["cve_id"]))
        if not system_cves_map[cve]["when_mitigated"] or (system_cves_map[cve]["active_rule"] is True
                                                          and system_cves_map[cve]["rule_only"] is False
                                                          and system_cves_map[cve]["mitigation_reason"] is None):
            system_cves.append(cve)

    new_sys_vulns = await _store_new_cves(rh_account_id, system_id, new_cves, conn)
    await _update_cves_advisories(rh_account_id, system_id, cves_needed_update, conn, system_cves_map)
    await _update_mitigated_cves(rh_account_id, system_id, mitigated_cves, conn, system_cves_map)
    await _update_unmitigated_cves(rh_account_id, system_id, unmitigated_cves, conn, system_cves_map)
    await _update_system(system_id, len(system_cves), conn)

    send_remediations_update(REMEDIATIONS_PRODUCER, str(inventory_id), system_cves)
    send_notifications(EVALUATOR_RESULTS, new_sys_vulns, list(mit_sys_vulns), list(unmit_sys_vulns), rh_account_id, acc_num, org_id)

    LOGGER.debug("Finished storing vulnerabilities for inventory_id: %s", inventory_id)


async def process_upload_or_re_evaluate(msg_dict: dict):
    """
    Process function to upload new file or re-evaluate system
    """
    async with DB_POOL.acquire() as conn:
        try:
            async with conn.transaction():
                LOGGER.info("Received message type: %s", msg_dict['type'])
                # Lock the system for processing
                system_platform = await conn.fetchrow("""SELECT id,
                                                                inventory_id,
                                                                vmaas_json,
                                                                rh_account_id
                                                           FROM system_platform
                                                          WHERE inventory_id = $1
                                                            AND when_deleted IS NULL
                                                     FOR UPDATE""", msg_dict['host']['id'])
                if system_platform is not None and system_platform[2] is not None:
                    host = msg_dict.get("host", {})
                    acc_num = host.get("account")
                    org_id = host.get("org_id")
                    with VMAAS_EVAL_TIME.time():
                        await evaluate_vmaas(system_platform, acc_num, org_id, conn)
                    if msg_dict['type'] == 'upload_new_file':
                        send_msg_to_payload_tracker(PAYLOAD_TRACKER_PRODUCER, msg_dict, 'success', loop=MAIN_LOOP)

                else:
                    INV_ID_NOT_FOUND.inc()
                    LOGGER.error("System with inventory_id not found in DB: %s", msg_dict['host']['id'])
                    if msg_dict['type'] == 'upload_new_file':
                        send_msg_to_payload_tracker(PAYLOAD_TRACKER_PRODUCER, msg_dict, 'error',
                                                    status_msg='System with inventory_id not found in DB: %s' % msg_dict['host']['id'],
                                                    loop=MAIN_LOOP)

        # pylint: disable=broad-except
        except Exception:
            STORE_FAILED.inc()
            LOGGER.exception("Unable to store data: ")


# pylint: disable=too-many-branches
@release_semaphore(MAX_MESSAGES_SEMAPHORE)
async def process_message(message):
    """Message procession logic"""
    try:
        msg_dict = json.loads(message.value.decode('utf-8'))
    except json.decoder.JSONDecodeError:
        MESSAGE_PARSE_ERROR.inc()
        LOGGER.exception("Unable to parse message: ")
        return
    if message.topic in CFG.evaluator_topics:
        if 'type' not in msg_dict:
            LOGGER.error("Received message is missing type field: %s", msg_dict)
            return
        if msg_dict['type'] in ['upload_new_file', 're-evaluate_system']:
            await process_upload_or_re_evaluate(msg_dict)
            if msg_dict['type'] == 'upload_new_file':
                send_msg_to_payload_tracker(PAYLOAD_TRACKER_PRODUCER, msg_dict, 'processing',
                                            status_msg='Scheduled for evaluation', loop=MAIN_LOOP)
        else:
            UNKNOWN_MSG.inc()
            LOGGER.error("Received unknown message type: %s", msg_dict['type'])
    else:
        UNKNOWN_TOPIC.inc()
        LOGGER.error("Received message on unsupported topic: %s", message.topic)


async def run() -> None:
    """
    Start everything and begin processing messages
    """
    await CONSUMER_QUEUE.start()
    await PAYLOAD_TRACKER_PRODUCER.start()
    await REMEDIATIONS_PRODUCER.start()

    dsn = f"postgres://{CFG.db_user}:{CFG.db_pass}@{CFG.db_host}:{CFG.db_port}/{CFG.db_name}?sslmode={CFG.db_ssl_mode}"
    # Validate the CA certificate before sending to asyncpg
    try:
        ssl.create_default_context(cafile=CFG.db_ssl_root_cert_path)
        dsn = f"{dsn}&sslrootcert={CFG.db_ssl_root_cert_path}"
    except (FileNotFoundError, ssl.SSLError):
        pass

    # pylint: disable=global-statement
    global DB_POOL
    DB_POOL = await asyncpg.create_pool(
        dsn=dsn,
        loop=MAIN_LOOP,
        min_size=CFG.db_min_pool_size,
        max_size=CFG.db_max_pool_size
    )
    try:
        async for msg in CONSUMER_QUEUE.client:
            await MAX_MESSAGES_SEMAPHORE.acquire()
            MAIN_LOOP.create_task(process_message(msg))
    finally:
        LOGGER.info("Shutting down.")
        await CONSUMER_QUEUE.stop()
        await DB_POOL.close()
        await PAYLOAD_TRACKER_PRODUCER.stop()
        await REMEDIATIONS_PRODUCER.stop()


def main():
    """Sets up and run whole application"""
    # Set up endpoint for prometheus monitoring
    LOGGER.info("Opening port [%s] for prometheus", PROMETHEUS_PORT)
    init_logging()

    status_app = create_status_app(LOGGER)
    _, status_site = create_status_runner(status_app, int(PROMETHEUS_PORT), LOGGER, MAIN_LOOP)
    MAIN_LOOP.run_until_complete(status_site.start())

    MAIN_LOOP.run_until_complete(a_ensure_minimal_schema_version())

    LOGGER.info("Using BOOTSTRAP_SERVERS: %s", CFG.bootstrap_servers)
    LOGGER.info("Using GROUP_ID: %s", CFG.group_id)
    LOGGER.info("Using TOPICS: %s", ", ".join(CFG.evaluator_topics))
    MAIN_LOOP.run_until_complete(run())


if __name__ == "__main__":
    main()
