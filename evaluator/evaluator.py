#!/usr/bin/env python3
"""
vulnerability-engine evaluator
"""
from datetime import datetime
import asyncio
import os
import json
import signal
from prometheus_client import Counter, Histogram, start_http_server
from psycopg2 import DatabaseError
from psycopg2.extras import execute_values

from common import mqueue
from common.bounded_executor import BoundedExecutor
from common.database_handler import DatabasePool, DatabasePoolConnection
from common.logging import init_logging, get_logger
from common.utils import vmaas_post_request, on_thread_done

LOGGER = get_logger(__name__)

VMAAS_HOST = os.getenv('VMAAS_HOST', 'http://vmaas-webapp-1.vmaas-ci.svc:8080')
VMAAS_VULNERABILITIES_API = os.getenv("VMAAS_VULNERABILITIES_API", "/api/v1/vulnerabilities")
vmaas_vulnerabilities_endpoint = "%s%s" % (VMAAS_HOST, VMAAS_VULNERABILITIES_API)  # pylint: disable=invalid-name

kafka_evaluator_topic = os.getenv('EVALUATOR_TOPIC',  # pylint: disable=invalid-name
                                  'vulnerability.evaluator.upload,vulnerability.evaluator.recalc').split(",")
prometheus_port = os.getenv('PROMETHEUS_PORT', '8085')  # pylint: disable=invalid-name
# number of worker threads
WORKER_THREADS = int(os.getenv('WORKER_THREADS', '30'))
MAX_QUEUE_SIZE = int(os.getenv('MAX_QUEUE_SIZE', '30'))

# prometheus probes
# times
VMAAS_EVAL_TIME = Histogram('ve_evaluator_vmaas_evaluation_seconds', 'Time spent checking a system for vmaas hits')
# counts
VMAAS_COUNT = Counter('ve_evaluator_vmaas_calls', 'Number of VMaaS-evaluations attempted')
INV_ID_NOT_FOUND = Counter('ve_evaluator_inventory_not_found', 'Number of times inventory-id not in SystemPlatform')
UNKNOWN_MSG = Counter('ve_evaluator_unknown_msg', 'Number of unrecognized messages delivered from queue')
UNKNOWN_TOPIC = Counter('ve_evaluator_unknown_topic', 'Number of times message delivered from unsupported topic')

CONSUMER_QUEUE = mqueue.MQReader(kafka_evaluator_topic)
WEBHOOKS_QUEUE = mqueue.MQWriter(mqueue.WEBHOOKS_TOPIC)


async def terminate(_, loop):
    """Trigger shutdown."""
    LOGGER.info("Signal received, stopping kafka consumers.")
    await CONSUMER_QUEUE.stop()
    await WEBHOOKS_QUEUE.stop()
    loop.stop()


class QueueEvaluator:
    """ This class contains logic for the processing vulnerabilities using VMaaS.
    """

    def __init__(self):
        LOGGER.info("Using BOOTSTRAP_SERVERS: %s", mqueue.BOOTSTRAP_SERVERS)
        LOGGER.info("Using GROUP_ID: %s", mqueue.GROUP_ID)
        LOGGER.info("Using TOPICS: %s", ", ".join(kafka_evaluator_topic))

    @staticmethod
    def _load_cves_for_inventory_id(system_id, cur):
        system_cves_map = {}
        cur.execute("""select cm.id, cm.cve, sv.when_mitigated
                       from system_vulnerabilities sv
                       join cve_metadata cm on sv.cve_id = cm.id where sv.system_id = %s""", (system_id,))
        for cve_id, cve, when_mitigated in cur.fetchall():
            sys_vuln = {'cve_id': cve_id,
                        'when_mitigated': when_mitigated}
            system_cves_map[cve] = sys_vuln
        return system_cves_map

    @staticmethod
    def _register_missing_cves(missing_cves, cur):
        new_cves = set()
        for cve in missing_cves:
            to_insert = ((cve, 'unknown', 0,), cve,)
            # do nothing if row exists - other evaluator or vmaas-sync just inserted it
            cur.execute("""INSERT INTO cve_metadata
                           (cve, description, impact_id)
                           VALUES %s ON CONFLICT (cve) DO UPDATE set cve = %s
                           returning id""", to_insert)
            cve_id = cur.fetchone()[0]
            new_cves.add(cve_id)
        return new_cves

    def _store_new_cves(self, system_id, inventory_id, new_cves, rh_account_id, cur, loop=None):
        new_cves_ids = set()
        if not new_cves:
            return new_cves_ids
        cvss_buckets = {'0to3': 0, '3to7': 0, '7to10': 0}

        # FIXME: getting metadata from DB on every system update should be optimized
        cur.execute("select id, cve, coalesce(cvss3_score, cvss2_score) from cve_metadata where cve in %s",
                    (tuple(new_cves),))
        cves_in_db = set()
        for cve_id, cve, cvss_score in cur.fetchall():
            new_cves_ids.add(cve_id)
            cves_in_db.add(cve)
            if cvss_score is None:
                pass
            elif cvss_score < 3:
                cvss_buckets['0to3'] += 1
            elif 3 <= cvss_score < 7:
                cvss_buckets['3to7'] += 1
            elif 7 <= cvss_score <= 10:
                cvss_buckets['7to10'] += 1

        cve_metadata_missing = [cve for cve in new_cves if cve not in cves_in_db]

        # Insert new CVEs into db
        if cve_metadata_missing:
            new_cves_ids.update(self._register_missing_cves(cve_metadata_missing, cur))

        cve_system_list = [(system_id, cve_id) for cve_id in new_cves_ids]
        execute_values(cur, "insert into system_vulnerabilities \
                       (system_id, cve_id) values %s",
                       cve_system_list, page_size=len(cve_system_list))

        cur.execute("""SELECT name FROM rh_account WHERE id = %s""", (rh_account_id,))
        rh_account = cur.fetchone()[0]

        for level in cvss_buckets:
            if cvss_buckets[level]:
                msg = {
                    'application': 'vulnerability',
                    'event_type': 'new-host-cve',
                    'timestamp': datetime.utcnow().isoformat(),
                    'account_id': rh_account,
                    'level': level,
                    'message': 'Discovered %s new CVEs with cvss score within %s radius for host id: %s' % (
                        cvss_buckets[level], level, inventory_id),
                }
                WEBHOOKS_QUEUE.send(msg, loop=loop)
        return new_cves_ids

    @staticmethod
    def _update_mitigated_cves(system_id, mitigated_cves_ids, cve_status_map, cur):
        if not mitigated_cves_ids:
            return

        cur.execute("""update system_vulnerabilities set when_mitigated = now()
                    where system_id = %s and cve_id in %s
                    returning cve_id, status_id""",
                    (system_id, tuple(mitigated_cves_ids),))
        for cve_id, status_id in cur.fetchall():
            cve_status_map[cve_id] = status_id

    @staticmethod
    def _update_unmitigated_cves(system_id, unmitigated_cves_ids, cve_status_map, cur):
        if not unmitigated_cves_ids:
            return

        cur.execute("update system_vulnerabilities set when_mitigated = null, \
                    first_reported = now() where system_id = %s and \
                    cve_id in %s \
                    returning cve_id, status_id",
                    (system_id, tuple(unmitigated_cves_ids),))
        for cve_id, status_id in cur.fetchall():
            cve_status_map[cve_id] = status_id

    @staticmethod
    def _update_system(system_id, cve_count, cur):
        cur.execute("""update system_platform set last_evaluation = now(),
                                                  cve_count_cache = %s
                       where id = %s""",
                    (cve_count, system_id,))

    @staticmethod
    def _update_cve_affected_systems_cache(new_cves_ids, unmitigated_cves_ids, mitigated_cves_ids,
                                           rh_account_id, cve_status_map, cur):
        # pylint: disable=too-many-branches
        if not new_cves_ids and not unmitigated_cves_ids and not mitigated_cves_ids:
            return
        all_cves_ids = new_cves_ids.copy()
        all_cves_ids.update(unmitigated_cves_ids)
        all_cves_ids.update(mitigated_cves_ids)
        inc_cves = []
        inc_cves_divergent_status = []
        dec_cves = []
        dec_cves_divergent_status = []
        delete_cves = []
        cur.execute("""select cve_id, systems_affected, status_id from cve_account_data
                       where rh_account_id = %s and cve_id in %s
                       order by cve_id for update""",
                    (rh_account_id, tuple(all_cves_ids),))
        cve_global_status_map = {}
        for cve_id, systems_affected, status_id in cur.fetchall():
            if cve_id in new_cves_ids or cve_id in unmitigated_cves_ids:
                if status_id == 0:
                    inc_cves.append(cve_id)
                else:
                    inc_cves_divergent_status.append(cve_id)
            elif cve_id in mitigated_cves_ids and systems_affected > 1:
                if status_id == cve_status_map.get(cve_id, 0):
                    dec_cves.append(cve_id)
                else:
                    dec_cves_divergent_status.append(cve_id)
            elif cve_id in mitigated_cves_ids:
                delete_cves.append(cve_id)
            cve_global_status_map[cve_id] = status_id
            # cves not in DB cache
            all_cves_ids.remove(cve_id)
        # filter out rest of cves and insert cache for new and unmitigated
        insert_cves = [(cve_id, rh_account_id, 1,
                        0 if cve_global_status_map.get(cve_id, 0) == cve_status_map.get(cve_id, 0) else 1)
                       for cve_id in all_cves_ids if cve_id in new_cves_ids or cve_id in unmitigated_cves_ids]
        if inc_cves:
            cur.execute("""update cve_account_data set systems_affected = systems_affected + 1
                            where rh_account_id = %s and cve_id in %s""", (rh_account_id, tuple(inc_cves)))
        if inc_cves_divergent_status:
            cur.execute("""update cve_account_data set systems_affected = systems_affected + 1,
                                                       systems_status_divergent = systems_status_divergent + 1
                            where rh_account_id = %s and cve_id in %s""", (rh_account_id,
                                                                           tuple(inc_cves_divergent_status)))
        if dec_cves:
            cur.execute("""update cve_account_data set systems_affected = systems_affected - 1
                            where rh_account_id = %s and cve_id in %s""", (rh_account_id, tuple(dec_cves)))
        if dec_cves_divergent_status:
            cur.execute("""update cve_account_data set systems_affected = systems_affected - 1,
                                                       systems_status_divergent = systems_status_divergent - 1
                            where rh_account_id = %s and cve_id in %s""", (rh_account_id,
                                                                           tuple(dec_cves_divergent_status)))
        if delete_cves:
            cur.execute("""delete from cve_account_data
                           where rh_account_id = %s and cve_id in %s""", (rh_account_id, tuple(delete_cves)))
        if insert_cves:
            execute_values(cur, """insert into cve_account_data
                                   (cve_id, rh_account_id, systems_affected, systems_status_divergent) values %s
                                   on conflict (cve_id, rh_account_id) do update set
                                     systems_affected = cve_account_data.systems_affected
                                                      + excluded.systems_affected,
                                     systems_status_divergent = cve_account_data.systems_status_divergent
                                                              + excluded.systems_status_divergent""",
                           insert_cves, page_size=len(insert_cves))

    @staticmethod
    def _vmaas_request_cves(vmaas_request_json):
        """Make VMaaS request for cves"""
        system_cves = set()
        vulnerabilities_response_json = vmaas_post_request(vmaas_vulnerabilities_endpoint,
                                                           vmaas_request_json)
        if vulnerabilities_response_json is not None:
            for cve in vulnerabilities_response_json['cve_list']:
                system_cves.add(cve)
        return system_cves

    @VMAAS_EVAL_TIME.time()
    def evaluate_vmaas(self, system_platform, cur, loop=None):
        """Evaluates messages received from vmaas"""
        VMAAS_COUNT.inc()
        system_id = system_platform[0]
        inventory_id = system_platform[1]
        LOGGER.info("Evaluating vulnerabilities for inventory_id: %s", inventory_id)
        # JSON to POST requests to vmaas vulnerabilities endpoint
        vmaas_request_json = json.loads(system_platform[2])
        rh_account_id = system_platform[3]
        opt_out = system_platform[4]

        reported_cves = self._vmaas_request_cves(vmaas_request_json)

        system_cves_map = self._load_cves_for_inventory_id(system_id, cur)
        unprocessed_cves = set(system_cves_map.keys())
        new_cves = set()
        mitigated_cves_ids = set()
        unmitigated_cves_ids = set()

        for cve in reported_cves:
            if cve in system_cves_map:
                unprocessed_cves.discard(cve)
                if system_cves_map[cve]['when_mitigated']:
                    # it was mitigated, now its not
                    unmitigated_cves_ids.add(system_cves_map[cve]['cve_id'])
            else:
                new_cves.add(cve)

        for cve in unprocessed_cves:
            if not system_cves_map[cve]['when_mitigated']:
                mitigated_cves_ids.add(system_cves_map[cve]['cve_id'])

        new_cves_ids = self._store_new_cves(system_id, inventory_id, new_cves, rh_account_id, cur, loop=loop)
        cve_status_map = {}
        self._update_mitigated_cves(system_id, mitigated_cves_ids, cve_status_map, cur)
        self._update_unmitigated_cves(system_id, unmitigated_cves_ids, cve_status_map, cur)
        self._update_system(system_id, len(reported_cves), cur)
        # don't update cve cache for opted out system
        if not opt_out:
            # pylint: disable=too-many-function-args
            self._update_cve_affected_systems_cache(new_cves_ids, unmitigated_cves_ids,
                                                    mitigated_cves_ids, rh_account_id, cve_status_map,
                                                    cur)

        LOGGER.debug("Finished evaluating vulnerabilities for inventory_id: %s", inventory_id)

    def process_upload_or_re_evaluate(self, msg_dict: dict, loop=None):
        """
        Process function to upload new file or re-evaluate system
        """
        with DatabasePoolConnection() as conn:
            with conn.cursor() as cur:
                try:
                    LOGGER.info("Received message type: %s", msg_dict['type'])
                    # Lock the system for processing
                    cur.execute("""SELECT id, inventory_id, vmaas_json, rh_account_id,
                                        opt_out FROM system_platform
                                WHERE inventory_id = %s
                                FOR UPDATE""", (msg_dict['inventory_id'],))
                    system_platform = cur.fetchone()
                    if system_platform is not None:
                        self.evaluate_vmaas(system_platform, cur, loop=loop)
                        conn.commit()
                    else:
                        INV_ID_NOT_FOUND.inc()
                        LOGGER.error("System with inventory_id not found in DB: %s", msg_dict['inventory_id'])
                except DatabaseError:
                    LOGGER.exception("Unable to store data: ")
                    conn.rollback()

    def run(self):
        """
        This method evaluates incoming system package profiles using VMaaS
        :return:
        """

        loop = asyncio.get_event_loop()
        signals = (signal.SIGHUP, signal.SIGTERM, signal.SIGINT)
        for sig in signals:
            loop.add_signal_handler(
                sig, lambda sig=sig: loop.create_task(terminate(sig, loop)))
        executor = BoundedExecutor(MAX_QUEUE_SIZE, max_workers=WORKER_THREADS)

        # pylint: disable=too-many-branches
        def process_message(message):
            """Message procession logic"""
            if message.topic in kafka_evaluator_topic:
                msg_dict = json.loads(message.value.decode('utf-8'))
                if 'type' not in msg_dict:
                    LOGGER.error("Received message is missing type field: %s", msg_dict)
                    return
                if msg_dict['type'] in ['upload_new_file', 're-evaluate_system']:
                    process_func = self.process_upload_or_re_evaluate
                else:
                    UNKNOWN_MSG.inc()
                    LOGGER.error("Received unknown message type: %s", msg_dict['type'])
                    return

                future = executor.submit(process_func, msg_dict, loop=loop)
                future.add_done_callback(on_thread_done)
            else:
                UNKNOWN_TOPIC.inc()
                LOGGER.error("Received message on unsupported topic: %s", message.topic)

        with DatabasePool(WORKER_THREADS):
            CONSUMER_QUEUE.listen(process_message)

            # wait until loop is stopped from terminate callback
            loop.run_forever()

            LOGGER.info("Shutting down.")
            executor.shutdown()


def run_evaluator():
    """Sets up and runs the evaluator"""
    evaluator = QueueEvaluator()
    evaluator.run()


def main():
    """Sets up and run whole application"""
    # Set up endpoint for prometheus monitoring
    init_logging()
    LOGGER.info("Opening port [%s] for prometheus", prometheus_port)
    start_http_server(int(prometheus_port))
    run_evaluator()


if __name__ == "__main__":
    main()
