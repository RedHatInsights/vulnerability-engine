#!/usr/bin/python3
import os
import logging
import json
import requests
from psycopg2.extras import execute_values

from kafka import KafkaConsumer, KafkaProducer

from database.database_handler import DatabaseHandler, init_db

VMAAS_HOST = os.getenv('VMAAS_HOST', 'webapp-vmaas-stable.1b13.insights.openshiftapps.com')
kafka_host = os.getenv('KAFKA_HOST', 'kafka-1.vmaas-ci.svc')
kafka_port = os.getenv('KAFKA_PORT', '29092')
kafka_evaluator_topic = os.getenv('EVALUATOR_TOPIC', 'vulnerability_evaluator_requests')
kafka_rules_requests_topic = os.getenv('RULES_REQUESTS_TOPIC', 'rules_engine_requests')
kafka_rules_results_topic = os.getenv('RULES_RESULTS_TOPIC', 'rules_engine_results')
kafka_group_id = os.getenv('KAFKA_GROUP_ID', 'vulnerability')

logging.basicConfig(
    format='%(asctime)s.%(msecs)s:%(name)s:%(thread)d:%(levelname)s:%(process)d:%(message)s',
    level=logging.INFO
)


class QueueEvaluator:
    """ This class contains logic for the processing new available
        updates from VMaaS.
    """
    def __init__(self, kafka_host, kafka_port, kafka_topics, kafka_group):
        # connect to the Messaging Service
        bootstrap_server = kafka_host + ':' + kafka_port
        self.consumer = KafkaConsumer(*kafka_topics,
                          bootstrap_servers=bootstrap_server,
                          group_id=kafka_group,
                          auto_offset_reset='latest',
                          )

        logging.info("Using BOOTSTRAP_SERVERS: %s" % bootstrap_server)
        logging.info("Using GROUP_ID: %s" % kafka_group)
        logging.info("Using TOPICS: %s" % ", ".join(kafka_topics))

        self.producer = KafkaProducer(bootstrap_servers=bootstrap_server)

        self.vmaas_updates_endpoint = 'https://' + VMAAS_HOST + '/api/v1/updates'
        self.vmaas_errata_endpoint = 'https://' + VMAAS_HOST + '/api/v1/errata'
        self.vmaas_cves_endpoint = 'https://' + VMAAS_HOST + '/api/v1/cves'

        # get DB connection
        init_db()
        self.conn = DatabaseHandler.get_connection()
        self.error_key_map = self._prepare_error_key_map()
    
    def _prepare_error_key_map(self):
        error_key_map = {}
        cur = self.conn.cursor()
        cur.execute("select name, id from prodsec_error_key")
        for error_key_name, error_key_id in cur.fetchall():
            error_key_map[error_key_name] = error_key_id
        cur.close()
        self.conn.commit()
        return error_key_map
    
    def _store_cves(self, system_id, system_cves, source_name="VMAAS"):
        if system_cves:
            cur = self.conn.cursor()
            cur.execute("select cve from system_vulnerabilities where platform_id = %s and \
                        when_mitigated is NULL",  (system_id,))

            current_cves = set()

            for row in cur.fetchall():
                current_cves.add(row[0])

            new_cves = system_cves.difference(current_cves)
            mitigated_cves = current_cves.difference(system_cves)

            cur.execute("select id from vulnerability_source where name = %s", (source_name,))
            source_id = cur.fetchall()[0][0]

            # if system has got new vulnerabilities with new CVEs
            if new_cves:
                # JSON to POST requests to vmaas CVEs endpoint
                cves_json = {'cve_list': list(new_cves)}
                cve_cvss3_list = []
                cve_system_list = []

                r = requests.post(self.vmaas_cves_endpoint, json=cves_json)
                if r.status_code == 200:

                    cves_response_json = json.loads(r.text)

                    # FIXME: getting metadata from DB on every system update should be optimized
                    cur.execute("select cve from cve_metadata")
                    cves_in_db = []
                    for cve_tuple in cur.fetchall():
                        cves_in_db.append(cve_tuple[0])

                    for cve in cves_response_json['cve_list']:
                        if cve not in cves_in_db:
                            # need also add a new CVE metadata into DB
                            cvss3_score = float(cves_response_json['cve_list'][cve]['cvss3_score'])
                            cve_cvss3_list.append((cve, cvss3_score))

                        cve_system_list.append((system_id, cve, source_id))

                    # Insert new CVEs into db
                    if cve_cvss3_list:
                        execute_values(cur, "insert into cve_metadata (cve, cvss3_score) values %s",
                                        cve_cvss3_list, page_size=len(cve_cvss3_list))

                    execute_values(cur, "insert into system_vulnerabilities \
                                    (platform_id, cve, vulnerability_source) values %s",
                                    cve_system_list, page_size=len(cve_system_list))

                else:
                    logging.error("Error during request to VMaaS endpoint " + self.vmaas_cves_endpoint)
                    logging.debug("Updates JSON: " + str(cves_json))

            if mitigated_cves:
                cur.execute("update system_vulnerabilities set when_mitigated = now() \
                where platform_id = %s and vulnerability_source = %s and cve in %s", (system_id,
                                                                                      source_id,
                                                                                      tuple(mitigated_cves),))
            cur.close()
            self.conn.commit()
    
    def _store_error_keys(self, system_id, system_error_keys):
        if system_error_keys:
            cur = self.conn.cursor()

            # Populate error keys not yet in DB
            new_error_keys = [(key,) for key in system_error_keys if key not in self.error_key_map]
            if new_error_keys:
                execute_values(cur, "insert into prodsec_error_key (name) values %s returning name, id",
                               new_error_keys, page_size=len(new_error_keys))
                self.conn.commit()

                for error_key_name, error_key_id in cur.fetchall():
                    self.error_key_map[error_key_name] = error_key_id

            # Get keys associated to system in DB
            db_system_error_key_ids = {}
            cur.execute("select error_key_id, when_mitigated from system_prodsec_error_key where platform_id = %s",
                        (system_id,))
            for error_key_id, when_mitigated in cur.fetchall():
                db_system_error_key_ids[error_key_id] = when_mitigated

            system_error_key_ids = {self.error_key_map[error_key] for error_key in system_error_keys}

            # Not in DB
            to_import = [(system_id, error_key_id) for error_key_id in system_error_key_ids
                         if error_key_id not in db_system_error_key_ids]
            if to_import:
                execute_values(cur, "insert into system_prodsec_error_key (platform_id, error_key_id) values %s",
                               to_import, page_size=len(to_import))

            # Not reported by rule but in DB
            to_mitigate = [error_key_id for error_key_id in db_system_error_key_ids
                           if error_key_id not in system_error_key_ids]
            if to_mitigate:
                cur.execute("""update system_prodsec_error_key set when_mitigated = now()
                               where platform_id = %s and error_key_id in %s""", (system_id, tuple(to_mitigate),))

            # Reported by rule but marked as mitigated in DB
            to_unmitigate = [error_key_id for error_key_id in system_error_key_ids
                             if db_system_error_key_ids.get(error_key_id, None)]
            if to_unmitigate:
                cur.execute("""update system_prodsec_error_key set when_mitigated = null
                               where platform_id = %s and error_key_id in %s""", (system_id, tuple(to_unmitigate),))

            cur.close()
            self.conn.commit()
    
    def evaluate_vmaas(self, system_platform):
        # JSON to POST requests to vmaas updates endpoint
        updates_json = json.loads(system_platform[1])
        # JSON to POST requests to vmaas errata endpoint
        errata_json = {'errata_list': []}

        system_errata = set()
        system_cves = set()

        r = requests.post(self.vmaas_updates_endpoint, json=updates_json)
        if r.status_code == 200:
            updates_response_json = json.loads(r.text)
            for pkg in updates_response_json['update_list']:
                for upd in updates_response_json['update_list'][pkg].get('available_updates', []):
                    system_errata.add(upd['erratum'])
        else:
            logging.error("Error during request to VMaaS endpoint " + self.vmaas_updates_endpoint)
            logging.debug("Updates JSON: " + str(updates_json))

        if system_errata:
            errata_json['errata_list'] = list(system_errata)
            r = requests.post(self.vmaas_errata_endpoint, json=errata_json)

            if r.status_code == 200:
                errata_response_json = json.loads(r.text)

                for erratum in errata_response_json['errata_list']:
                    for cve in errata_response_json['errata_list'][erratum]['cve_list']:
                        system_cves.add(cve)
            else:
                logging.error("Error during request to VMaaS endpoint " + self.vmaas_errata_endpoint)
                logging.debug("Updates JSON: " + str(errata_json))

        self._store_cves(system_platform[0], system_cves, source_name="VMAAS")

    def evaluate_rules(self, rules_engine_response):
        system_cves = set()
        system_error_keys = set()

        for report in rules_engine_response["reports"]:
            # FIXME: get CVE IDs properly when they are available in rules results
            rule_id = report["rule_id"].upper()
            rule_id = rule_id.split("|")[0] # strip error key
            rule_id = rule_id.replace("_", "-")
            cve_id_parts = rule_id.split("-")
            if cve_id_parts[0] == "CVE" and cve_id_parts[1].isdigit() and cve_id_parts[2].isdigit():
                system_error_keys.add(report["rule_id"])
                system_cves.add("%s-%s-%s" % (cve_id_parts[0], cve_id_parts[1], cve_id_parts[2]))

        system_id = rules_engine_response["system"]["system_id"]
        self._store_error_keys(system_id, system_error_keys)
        self._store_cves(system_id, system_cves, source_name="RULES")

    def _prepare_rules_engine_request(self, listener_msg):
        return {
            "plugins": ["vmaas"],
            "rh_account": listener_msg["rh_account"],
            "url": listener_msg["url"],
            "hash": listener_msg["hash"]
        }

    def run(self):
        """
        This method process messages with type 'vmaas_updates'
        :return:
        """

        cur = self.conn.cursor()
        for message in self.consumer:
            if message.topic == kafka_evaluator_topic:
                msg_dict = json.loads(message.value.decode('utf-8'))
                if 'type' not in msg_dict:
                    logging.error("Received message is missing type field: %s", msg_dict)
                    continue
                if msg_dict['type'] == 'vmaas_updates':
                    logging.info("Received message type: %s", msg_dict['type'])
                    cur.execute("select platform_id, vmaas_json from system_platform")
                    # reevaluate updates for every system in the DB
                    for system_platform in cur.fetchall():
                        self.evaluate_vmaas(system_platform)
                elif msg_dict['type'] == 'upload_new_file':
                    logging.info("Received message type: %s", msg_dict['type'])
                    cur.execute("select platform_id, vmaas_json from system_platform where platform_id = %s", (msg_dict['system_id'],))
                    system_platform = cur.fetchone()
                    if system_platform is not None:
                        self.producer.send(kafka_rules_requests_topic,
                                           json.dumps(self._prepare_rules_engine_request(msg_dict)).encode("utf8"))
                        self.evaluate_vmaas(system_platform)
                    else:
                        logging.error("System with platform_id not found in DB: %s", msg_dict['system_id'])
                else:
                    logging.error("Received unknown message type: %s", msg_dict['type'])
            elif message.topic == kafka_rules_results_topic:
                logging.info("Received message on topic: %s", message.topic)
                msg_dict = json.loads(message.value.decode('utf-8'))
                self.evaluate_rules(msg_dict)
            else:
                logging.error("Received message on unsupported topic: %s", message.topic)

        self.consumer.close()
        cur.close()
        self.conn.commit()

def main():
    evaluator = QueueEvaluator(kafka_host, kafka_port, [kafka_evaluator_topic, kafka_rules_results_topic], kafka_group_id)
    evaluator.run()


if __name__ == "__main__":
    main()