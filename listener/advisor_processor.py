"""
Advisor message processor
"""
import hashlib
import json

from psycopg.rows import dict_row

from .common import AdvisorMsg
from .common import CFG
from .common import DATABASE_ERROR
from .common import DELETED_UPLOADED_ADVISOR
from .common import ImportStatus
from .common import NEW_SYSTEM_ADVISOR
from .common import UPDATE_SYSTEM_ADVISOR
from .processor import BaseProcessor
from common.logging import get_logger
from common.mqueue import MQWriter
from common.mqueue import Partitioners
from common.utils import reporter_allowed
from common.utils import send_msg_to_payload_tracker

LOGGER = get_logger(__name__)


class AdvisorMsgProcessor(BaseProcessor):
    # pylint: disable=no-self-use,broad-except
    """Advisor msg processor, processed messages from advisor"""

    def __init__(self, *args, **kwargs):
        """Constructor"""
        super().__init__(*args, **kwargs)
        self.grouper = MQWriter(CFG.grouper_advisor_topic, partitioner=Partitioners.org_id_partitioner)

    async def start(self):
        """Start the advisor processor"""
        await self.grouper.start()

    async def stop(self):
        """Stop the advisor processor"""
        await self.grouper.stop()

    async def _db_import_system(self, conn, fields: dict, org_id: str, inventory_id: str) -> (ImportStatus, int):
        """Import system to system_platform table, update if exists"""
        rh_account_id, system_id = await self._db_account_system_lookup(conn, org_id, inventory_id)
        fields["rh_account_id"] = rh_account_id
        if system_id:
            fields["system_id"] = system_id

        if not system_id:
            query = """
                INSERT INTO system_platform
                (rh_account_id, inventory_id, display_name, advisor_checksum, rule_results, stale_timestamp,
                 stale_warning_timestamp, culled_timestamp, last_upload, stale)
                VALUES (%(rh_account_id)s, %(inventory_id)s, %(display_name)s, %(advisor_checksum)s, %(rule_results)s, %(stale_timestamp)s,
                        %(stale_warning_timestamp)s, %(culled_timestamp)s, now(), 'F')
                ON CONFLICT (inventory_id) DO UPDATE SET
                inventory_id = EXCLUDED.inventory_id, display_name = EXCLUDED.display_name, advisor_checksum = EXCLUDED.advisor_checksum,
                rule_results = EXCLUDED.rule_results, stale_timestamp = EXCLUDED.stale_timestamp, stale_warning_timestamp = EXCLUDED.stale_warning_timestamp,
                culled_timestamp = EXCLUDED.culled_timestamp, last_upload = EXCLUDED.last_upload, stale = EXCLUDED.stale
                RETURNING (xmax = 0) AS inserted, id, when_deleted, advisor_unchanged_since, advisor_evaluated
            """
        else:
            query = """
                UPDATE system_platform
                SET display_name = %(display_name)s,
                    advisor_checksum = %(advisor_checksum)s,
                    rule_results = %(rule_results)s,
                    stale_timestamp = %(stale_timestamp)s,
                    stale_warning_timestamp = %(stale_warning_timestamp)s,
                    culled_timestamp = %(culled_timestamp)s,
                    last_upload = now(),
                    stale = FALSE
                WHERE id = %(system_id)s
                RETURNING (xmax = 0) AS inserted, id, when_deleted, advisor_unchanged_since, advisor_evaluated
            """
        async with conn.cursor(row_factory=dict_row) as cur:
            await cur.execute(query, fields)
            result = await cur.fetchone()
            if result["when_deleted"]:
                LOGGER.warning("Received recently deleted inventory_id: %s", fields["inventory_id"])
                DELETED_UPLOADED_ADVISOR.inc()
                return ImportStatus.FAILED, None
            status = None
            if result["inserted"]:
                status = ImportStatus.INSERTED | ImportStatus.CHANGED
                NEW_SYSTEM_ADVISOR.inc()
            else:
                status = ImportStatus.UPDATED
                UPDATE_SYSTEM_ADVISOR.inc()

            if not result["advisor_evaluated"] or (result["advisor_unchanged_since"] > result["advisor_evaluated"]):
                status |= ImportStatus.CHANGED

        return status, result["id"]

    def _parse_hits(self, reports: dict, rule_results: dict):
        """Parse rule hits from advisor message"""
        for report in reports:
            if "cves" in report["details"]:
                rule = report["rule_id"]
                for cve in report["details"]["cves"]:
                    if not report["details"]["cves"][cve]:
                        rule_results[cve] = {
                            "rule_id": rule,
                            "details": json.dumps(report["details"]),
                        }
                    elif report["details"]["cves"][cve]:
                        rule_results[cve] = {
                            "rule_id": rule,
                            "details": json.dumps(report["details"]),
                            "mitigation_reason": report["details"]["cves"][cve],
                        }

    def _parse_passes(self, passes: dict, rule_results: dict):
        """Parse rule passes from advisor message"""
        for pass_ in passes:
            if "cves" in pass_["details"]:
                rule_only = pass_["pass_id"].split("|")[0]
                for cve in pass_["details"]["cves"]:
                    rule_results[cve] = {
                        "rule_id": rule_only,
                        "details": json.dumps(pass_["details"]),
                        "mitigation_reason": pass_["details"]["cves"][cve],
                    }

    def _parse_db_fields(self, msg: AdvisorMsg) -> dict:
        """Prepare DB fields for system_platform table insertion query
        from advisor message"""
        fields = {}
        host = msg.msg["input"]["host"]

        fields["inventory_id"] = host["id"]
        fields["display_name"] = host["display_name"]

        rule_passes = {}
        passes = msg.msg["results"].get("pass", [])
        self._parse_passes(passes, rule_passes)

        rule_hits = {}
        hits = msg.msg["results"].get("reports", [])
        self._parse_hits(hits, rule_hits)

        results_raw = json.dumps({"rule_hits": rule_hits, "rule_passes": rule_passes}, sort_keys=True)

        fields["advisor_checksum"] = hashlib.sha256(results_raw.encode("utf-8")).hexdigest()
        fields["rule_results"] = results_raw

        fields["stale_timestamp"] = host.get("stale_timestamp")
        fields["stale_warning_timestamp"] = host.get("stale_warning_timestamp")
        fields["culled_timestamp"] = host.get("culled_timestamp")
        return fields

    def _parse_org_id(self, msg: AdvisorMsg) -> (str, str, str):
        """Extract org id, account id and inventory_id from advisor msg"""
        return msg.msg["input"]["host"]["org_id"], msg.msg["input"]["host"].get("account"), msg.msg["input"]["host"]["id"]

    def _parse_input_metadata(self, msg: AdvisorMsg) -> (str, str):
        """Extract request_id and timestamp from advisor message"""
        return msg.msg["input"].get("platform_metadata", {}).get("request_id", ""), msg.msg["input"]["timestamp"]

    def _send_for_evaluation(self, org_id: str, inventory_id: str, request_id: str, timestamp: str, import_status: ImportStatus):
        """Send message to evaluator to evaluate"""
        msg = {
            "type": "advisor_upload",
            "host": {
                "id": inventory_id,
                "changed": ImportStatus.CHANGED in import_status,
                "org_id": org_id,
            },
            "platform_metadata": {
                "request_id": request_id,
            },
            "timestamp": timestamp,
        }
        self.grouper.send(msg, loop=self.loop, key=org_id)

    def _send_to_payload_tracker(self, status: str, msg: AdvisorMsg, message=None):
        """Send payload tracker message"""
        send_msg_to_payload_tracker(self.payload_tracker, msg.msg["input"], status, status_msg=message, loop=self.loop)

    async def _process_upload(self, msg: AdvisorMsg):
        """Process message from advisor"""
        insert_fields = {}

        org_id, _, inventory_id = self._parse_org_id(msg)
        insert_fields = self._parse_db_fields(msg)

        async with self.db_pool.connection() as conn:
            try:
                async with conn.transaction():
                    import_status, _ = await self._db_import_system(conn, insert_fields, org_id, inventory_id)
                    if ImportStatus.FAILED in import_status:
                        return
            except Exception as exc:
                DATABASE_ERROR.inc()
                LOGGER.exception("Error importing system: %s", exc)
                return

        request_id, timestamp = self._parse_input_metadata(msg)
        LOGGER.info("advisor data inserted, system: %s, org_id: %s, request_id: %s", inventory_id, org_id, request_id)
        self._send_for_evaluation(org_id, inventory_id, request_id, timestamp, import_status)
        self._send_to_payload_tracker("received", msg, message="system received from advisor, sending to grouper")

    async def process_msg(self, msg: AdvisorMsg):
        """Process single advisor msg"""
        if reporter_allowed(msg.msg):
            await self._process_upload(msg)
