"""Module implementing kafka listener."""

import json
import os
import tempfile

from psycopg2 import DatabaseError
from prometheus_client import Counter, start_http_server
import requests

from common import mqueue
from common.database_handler import DatabaseHandler, init_db
from common.logging import init_logging, get_logger
from .archive_parser import ArchiveParser

LOGGER = get_logger(__name__)

PROMETHEUS_PORT = os.getenv('PROMETHEUS_PORT', '8086')

NEW_SYSTEM = Counter('ve_listener_upl_new_system', '# of new systems inserted')
UPDATE_SYSTEM = Counter('ve_listener_upl_update_system', '# of systems updated')
PROCESS_UPLOAD = Counter('ve_listener_upl_uploads_processed', '# of uploaded archives processed')
MISSING_ID = Counter('ve_listener_upl_missing_inventory_id', '# of upload-msgs missing inventory_id')
ARCHIVE_PARSE_FAILURE = Counter('ve_listener_upl_archive_excpetions', '# of exceptions during archive-processing')
ARCHIVE_NO_RPMDB = Counter('ve_listener_upl_no_rpmdb', '# of systems ignored due to missing rpmdb')


def format_vmaas_request(package_list, repo_list=None, modules_list=None):
    """Wrap package and repo list into the vmaas request format."""
    vmaas_request = {"package_list": package_list}
    if repo_list:
        vmaas_request["repository_list"] = repo_list
    if modules_list:
        vmaas_request["modules_list"] = modules_list
    return json.dumps(vmaas_request)


def db_import_system(conn, inventory_id, rh_account, s3_url, vmaas_json, satellite_managed):
    """Import initial system record to the DB."""
    # TODO: json_checksum
    with conn.cursor() as cur:
        try:
            # xmax is PG system column used to find out if row was inserted or updated
            cur.execute("""INSERT INTO system_platform
                        (inventory_id, rh_account, s3_url, vmaas_json, json_checksum, satellite_managed)
                        VALUES (%s, %s, %s, %s, %s, %s)
                        ON CONFLICT (inventory_id) DO UPDATE SET
                        rh_account = %s, s3_url = %s, vmaas_json = %s, json_checksum = %s, satellite_managed = %s
                        RETURNING (xmax = 0) AS inserted
                        """,
                        (inventory_id, rh_account, s3_url, vmaas_json, '0', satellite_managed,
                         rh_account, s3_url, vmaas_json, '0', satellite_managed,))
            inserted, = cur.fetchone()
            conn.commit()
            if inserted:
                NEW_SYSTEM.inc()
            else:
                UPDATE_SYSTEM.inc()
        except DatabaseError:
            LOGGER.exception("Error importing system: ")
            conn.rollback()


def main():
    """Main kafka listener entrypoint."""
    start_http_server(int(PROMETHEUS_PORT))
    init_logging()
    init_db()
    LOGGER.info("Starting upload listener.")
    # get DB connection
    conn = DatabaseHandler.get_connection()
    upload_queue = mqueue.MQReader(mqueue.UPLOAD_TOPIC)
    vuln_queue = mqueue.MQWriter(mqueue.EVALUATOR_TOPIC)

    session = requests.Session()

    def process_upload(msg):
        """Message processing logic"""
        PROCESS_UPLOAD.inc()
        LOGGER.info('Received message from topic %s: %s', msg.topic, msg.value)

        upload_data = json.loads(msg.value.decode("utf8"))

        # Inventory ID is missing
        if 'id' not in upload_data or upload_data["id"] is None:
            MISSING_ID.inc()
            LOGGER.warning("Unable to store system, inventory ID is missing.")
            return

        # Download archive an parse
        with tempfile.NamedTemporaryFile(delete=True) as tmp_file:
            LOGGER.debug("Writing temp file to %s", tmp_file.name)
            response = session.get(upload_data["url"], stream=True, allow_redirects=True)
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:  # filter out keep-alive new chunks
                    tmp_file.write(chunk)
            tmp_file.flush()
            parser = ArchiveParser(tmp_file.name)
            try:
                parser.parse()
            except Exception: # pylint: disable=broad-except
                ARCHIVE_PARSE_FAILURE.inc()
                LOGGER.exception("Unable to parse archive: ")
                return

        if parser.package_list:
            db_import_system(conn, upload_data["id"], upload_data["rh_account"], upload_data["url"],
                             format_vmaas_request(parser.package_list, repo_list=parser.repo_list,
                                                  modules_list=parser.modules_list),
                             upload_data.get("satellite_managed", False))
            new_upload_msg = {"type": "upload_new_file", "system_id": upload_data["id"]}
            vuln_queue.send(new_upload_msg)
            LOGGER.info('Sent message to topic %s: %s', mqueue.EVALUATOR_TOPIC,
                        json.dumps(new_upload_msg).encode("utf8"))
        else:
            ARCHIVE_NO_RPMDB.inc()
            LOGGER.error("Unable to store system, empty package list.")

    upload_queue.listen(process_upload)
    session.close()

if __name__ == '__main__':
    main()
