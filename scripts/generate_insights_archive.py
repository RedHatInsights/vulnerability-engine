#!/usr/bin/env python3
"""
Generates Insights archive based on VMaaS request.
For testing vulnerability engine only.
"""
import argparse
import datetime
import json
import os
import re
import sys
import tarfile
import tempfile
import uuid

META_DNF_MODULES_FILE = "meta_data/insights.specs.Specs.dnf_modules.json"
META_YUM_REPOS_D_FILE = "meta_data/insights.specs.Specs.yum_repos_d.json"
META_SYSTEMID_FILE = "meta_data/insights.specs.Specs.machine_id.json"
META_PKGLIST_FILE = "meta_data/insights.specs.Specs.installed_rpms.json"

DATA_DNF_MODULES_FILE = "data/etc/dnf/modules.d/all.module"
DATA_YUM_REPOS_D_FILE = "data/etc/yum.repos.d/redhat.repo"
DATA_SYSTEMID_FILE = "data/etc/insights-client/machine-id"
DATA_PKGLIST_FILE = "data/insights_commands/rpm_-qa"


NEVRA_RE = re.compile(r"(.*)-(([0-9]+):)?([^-]+)-([^-]+)\.([a-z0-9_]+)")


def split_packagename(filename):
    """
    Split rpm name (incl. epoch) to NEVRA components.

    Return a name, epoch, version, release, arch, e.g.::
        foo-1.0-1.i386.rpm returns foo, 0, 1.0, 1, i386
        bar-1:9-123a.ia64.rpm returns bar, 1, 9, 123a, ia64
    """

    if filename[-4:] == ".rpm":
        filename = filename[:-4]

    match = NEVRA_RE.match(filename)
    if not match:
        return "", "", "", "", ""

    name, _, epoch, version, release, arch = match.groups()
    if epoch is None:
        epoch = "(none)"
    return name, epoch, version, release, arch


def generate_module_files(tmpdir, vmaas_req):
    """Create module files stanza"""
    print("Generating module files... ", end="")
    modules_list = vmaas_req.get("modules_list", [])
    if modules_list:
        # Write meta-data file
        meta_modules_file = os.path.join(tmpdir, META_DNF_MODULES_FILE)
        os.makedirs(os.path.dirname(meta_modules_file), exist_ok=True)
        with open(meta_modules_file, "wt") as meta_modules_f:
            print(
                json.dumps(
                    {
                        "name": "insights.specs.Specs.dnf_modules",
                        "exec_time": 0.00015616416931152344,
                        "errors": [],
                        "results": [
                            {
                                "type": "insights.core.spec_factory.TextFileProvider",
                                "object": {"relative_path": "etc/dnf/modules.d/all.module", "rc": None},
                            }
                        ],
                        "ser_time": 0.013364076614379883,
                    }
                ),
                file=meta_modules_f,
            )
        # Write data file
        data_modules_file = os.path.join(tmpdir, DATA_DNF_MODULES_FILE)
        os.makedirs(os.path.dirname(data_modules_file), exist_ok=True)
        with open(data_modules_file, "wt") as data_module_f:
            for module in modules_list:
                print("[%s]" % module["module_name"], file=data_module_f)
                print("name=%s" % module["module_name"], file=data_module_f)
                print("stream=%s" % module["module_stream"], file=data_module_f)
        print("DONE")
    else:
        print("SKIPPED")


def generate_system_id_file(tmpdir, system_id):
    """Create system ID file"""
    print("Generating system ID file... ", end="")
    if system_id is None:
        system_id = str(uuid.uuid4())
    # Write meta-data file
    meta_system_id_file = os.path.join(tmpdir, META_SYSTEMID_FILE)
    os.makedirs(os.path.dirname(meta_system_id_file), exist_ok=True)
    with open(meta_system_id_file, "wt") as meta_system_id_f:
        print(
            json.dumps(
                {
                    "name": "insights.specs.Specs.machine_id",
                    "exec_time": 2.47955322265625e-05,
                    "errors": [],
                    "results": {
                        "type": "insights.core.spec_factory.TextFileProvider",
                        "object": {"relative_path": "etc/insights-client/machine-id", "rc": None},
                    },
                    "ser_time": 0.0020246505737304688,
                }
            ),
            file=meta_system_id_f,
        )
    # Write data file
    data_system_id_file = os.path.join(tmpdir, DATA_SYSTEMID_FILE)
    os.makedirs(os.path.dirname(data_system_id_file), exist_ok=True)
    with open(data_system_id_file, "wt") as data_system_id_f:
        print(system_id, file=data_system_id_f)
    print("DONE")


def generate_pkglist_file(tmpdir, vmaas_req):
    """Create pkglist file"""
    print("Generating pkglist file... ", end="")
    package_list = vmaas_req.get("package_list", [])
    if package_list:
        # Write meta-data file
        meta_packagelist_file = os.path.join(tmpdir, META_PKGLIST_FILE)
        os.makedirs(os.path.dirname(meta_packagelist_file), exist_ok=True)
        with open(meta_packagelist_file, "wt") as meta_packagelist_f:
            print(
                json.dumps(
                    {
                        "name": "insights.specs.Specs.installed_rpms",
                        "exec_time": 1.52587890625e-05,
                        "errors": [],
                        "results": {
                            "type": "insights.core.spec_factory.CommandOutputProvider",
                            "object": {"rc": None, "cmd": "/bin/rpm -qa", "args": None, "relative_path": "insights_commands/rpm_-qa"},
                        },
                        "ser_time": 0.30236101150512695,
                    }
                ),
                file=meta_packagelist_f,
            )
        # Write data file
        data_packagelist_file = os.path.join(tmpdir, DATA_PKGLIST_FILE)
        os.makedirs(os.path.dirname(data_packagelist_file), exist_ok=True)
        with open(data_packagelist_file, "wt") as data_packagelist_f:
            for package in package_list:
                name, epoch, version, release, arch = split_packagename(package)
                print(
                    "{"
                    '"name":"%s",'
                    '"epoch":"%s",'
                    '"version":"%s",'
                    '"release":"%s",'
                    '"arch":"%s"'
                    "}" % (name, epoch, version, release, arch),
                    file=data_packagelist_f,
                )
        print("DONE")
    else:
        print("SKIPPED")


def generate_repolist_file(tmpdir, vmaas_req):
    """Create repolist file"""
    print("Generating repolist file... ", end="")
    repository_list = vmaas_req.get("repository_list", [])
    if repository_list:
        # Write meta-data file
        meta_yum_repos_d_file = os.path.join(tmpdir, META_YUM_REPOS_D_FILE)
        os.makedirs(os.path.dirname(meta_yum_repos_d_file), exist_ok=True)
        with open(meta_yum_repos_d_file, "wt") as meta_repolist_f:
            print(
                json.dumps(
                    {
                        "name": "insights.specs.Specs.yum_repos_d",
                        "exec_time": 1.6927719116210938e-05,
                        "errors": [],
                        "results": [
                            {
                                "type": "insights.core.spec_factory.TextFileProvider",
                                "object": {"relative_path": "etc/yum.repos.d/redhat.repo", "rc": None},
                            }
                        ],
                        "ser_time": 0.0017766952514648438,
                    }
                ),
                file=meta_repolist_f,
            )
        # Write data file
        data_yum_repos_d_file = os.path.join(tmpdir, DATA_YUM_REPOS_D_FILE)
        os.makedirs(os.path.dirname(data_yum_repos_d_file), exist_ok=True)
        with open(data_yum_repos_d_file, "wt") as data_repolist_f:
            for repo in repository_list:
                print("[%s]\nenabled=1\n" % repo, file=data_repolist_f)
        print("DONE")
    else:
        print("SKIPPED")


def main():
    """Main entrypoint"""
    parser = argparse.ArgumentParser()
    parser.add_argument("vmaas_json", help='VMaaS JSON request file, "-" for stdin')
    parser.add_argument("--id", action="store", help="use following system id")
    parser.add_argument("-o", "--output", action="store", help="output TGZ file")
    args = parser.parse_args()

    if not os.path.isfile(args.vmaas_json) and not args.vmaas_json == "-":
        print("File doesn't exist: %s" % args.vmaas_json)
        sys.exit(1)

    if args.vmaas_json == "-":
        source = sys.stdin
    else:
        source = open(args.vmaas_json, "rt")
    try:
        vmaas_req = json.load(source)
    except json.decoder.JSONDecodeError:
        print("Unable to parse JSON file: %s" % args.vmaas_json)
        sys.exit(2)
    finally:
        if source != sys.stdin:
            source.close()

    with tempfile.TemporaryDirectory() as tmpdir:
        # This empty file seems needed
        with open(os.path.join(tmpdir, "insights_archive.txt"), "wt") as _:
            pass

        generate_module_files(tmpdir, vmaas_req)
        generate_system_id_file(tmpdir, args.id)
        generate_pkglist_file(tmpdir, vmaas_req)
        generate_repolist_file(tmpdir, vmaas_req)

        if args.output:
            targz_file = args.output
        else:
            targz_file = "/tmp/%s-%s.tar.gz" % (os.path.basename(tmpdir), datetime.datetime.now().strftime("%Y%m%d%H%M%S"))

        print("Building TGZ file... ", end="")
        with tarfile.open(targz_file, "w:gz") as tar:
            tar.add(tmpdir, arcname=os.path.basename(tmpdir))
        print("DONE\n")

        print(targz_file)


if __name__ == "__main__":
    main()
