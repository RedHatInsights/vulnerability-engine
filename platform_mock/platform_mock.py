"""Platform mock upload module."""
import base64
import datetime
import hashlib
import json
import os
import signal
import uuid

from insights.core import archives, dr
from insights.core.archives import InvalidContentType
from insights.core.context import HostArchiveContext
from insights.core.hydration import create_context
from insights.specs import Specs
from insights.parsers.dnf_modules import DnfModules
from insights.parsers.installed_rpms import Installed
from insights.parsers.yum_repos_d import YumReposD
from tornado.ioloop import IOLoop
from tornado.web import Application, RequestHandler

from common.logging import init_logging, get_logger
from common import mqueue
from common.database_handler import DatabasePool, DatabasePoolConnection

LOGGER = get_logger(__name__)
STORAGE_PATH = "/tmp/storage"


class BaseHandler(RequestHandler):
    """Base Handler."""

    def _get_rh_account(self):
        if "x-rh-identity" not in self.request.headers:
            return "0"
        encoded_value = self.request.headers["x-rh-identity"]
        decoded_value = base64.b64decode(encoded_value).decode("utf-8")
        identity = json.loads(decoded_value)
        return identity.get("identity", {}).get("account_number", "0")


class UploadHandler(BaseHandler):
    """Upload Handler."""

    def data_received(self, chunk):
        pass

    @staticmethod
    def _get_system_profile(archive_path):
        profile = {}
        default_packages = (
            "insights.specs.default",
            "insights.specs.insights_archive",
            "insights.combiners",
            "insights.parsers"
        )
        for pkg in default_packages:
            dr.load_components(pkg)
        broker = dr.Broker()
        try:
            with archives.extract(archive_path) as ex:
                ctx = create_context(ex.tmp_dir, HostArchiveContext)
                broker[ctx.__class__] = ctx
                broker = dr.run(components=[Specs.machine_id, Installed, DnfModules, YumReposD],
                                broker=broker)
                if Specs.machine_id in broker:
                    profile["id"] = broker[Specs.machine_id].content[0].strip()
                profile["installed_packages"] = []
                if Installed in broker:
                    pkglist = broker[Installed]
                    for pkg_name in pkglist.packages:
                        pkg = pkglist.get_max(pkg_name)
                        profile["installed_packages"].append(pkg.nevra)

                profile["yum_repos"] = []
                if YumReposD in broker:
                    repolist = broker[YumReposD]
                    for repo_file in repolist:
                        if repo_file.file_name == 'redhat.repo':
                            for repo in repo_file:
                                if repo_file[repo].get('enabled', '1').lower() in ('1', 'true', 'enabled', 'yes', 'on'):
                                    profile["yum_repos"].append(repo)
                            break

                profile["dnf_modules"] = []
                if DnfModules in broker:
                    for module in broker[DnfModules]:
                        for module_name in module.sections():
                            profile["dnf_modules"].append({'name': module_name,
                                                           'stream': module.get(module_name, 'stream')})
                LOGGER.info(profile)
        except InvalidContentType:
            LOGGER.error("Unable to parse archive.")
        return profile

    def _get_upload_multiplier(self):
        if "x-upload-multiplier" not in self.request.headers:
            return 1
        multiplier = self.request.headers["x-upload-multiplier"]
        return int(multiplier) if multiplier.isdigit() else 1

    def post(self):
        """Answer POST request.
           curl -X POST -F "file=@./file.tar.gz" http://localhost:8100/api/v1/upload
           curl -X POST -F "file=@./file.tar.gz" -H "x-upload-multiplier: 10" http://localhost:8100/api/v1/upload
        """
        if self.request.files and "file" in self.request.files:
            sha1 = hashlib.sha1(self.request.files["file"][0]["body"]).hexdigest()
            file_name = "%s.tar.gz" % sha1
            file_path = os.path.join(STORAGE_PATH, file_name)
            if not os.path.exists(file_path):
                with open(file_path, "wb") as open_file:
                    open_file.write(self.request.files["file"][0]["body"])
            if sha1 in self.application.archive_to_profile_cache:
                profile = self.application.archive_to_profile_cache[sha1]
            else:
                profile = self._get_system_profile(file_path)
                self.application.archive_to_profile_cache[sha1] = profile
                self.application.inventory_id_to_profile_cache[profile.get("id", None)] = profile
            download_url = "http://platform_mock:8000/api/v1/download/%s" % file_name
            rh_account = self._get_rh_account()
            timestamp = datetime.datetime.utcnow().isoformat()
            upload_message = {"host": {"id": profile.get("id", None), "account": rh_account,
                                       "display_name": sha1 + ".example.com",
                                       "system_profile": {
                                           "installed_packages": profile["installed_packages"],
                                           "yum_repos": [{"id": r, "name": r, "enabled": True} for r in profile["yum_repos"]],
                                           "dnf_modules": profile["dnf_modules"],
                                           "insights_client_version": "3.0.13-1"},
                                       "insights_id": "0"
                                       },
                              "platform_metadata": {"request_id": str(uuid.uuid1()), "url": download_url,
                                                    "b64_identity": self.request.headers.get("x-rh-identity", "")},
                              "timestamp": timestamp,
                              "type": "created"
                              }
            for _ in range(self._get_upload_multiplier()):
                self.application.queue.send(upload_message)
                with DatabasePoolConnection() as conn:
                    with conn.cursor() as cur:
                        cur.execute("""
                                        insert into inventory.hosts_v1_1 values (%s, 0, %s, '[]', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP, '2030-07-21 05:35:53.682554+00', '{}')
                                        on conflict (id) do update set display_name = EXCLUDED.display_name, updated = CURRENT_TIMESTAMP 
                                     """, (upload_message["host"]["id"],
                                           upload_message["host"]["display_name"]))
                    conn.commit()
            LOGGER.info("New upload: %s", upload_message)
        else:
            self.set_status(400)
        self.finish()


class DownloadHandler(BaseHandler):
    """Download Handler."""

    def data_received(self, chunk):
        pass

    def get(self, path):
        """Answer GET request."""
        file_path = os.path.join(STORAGE_PATH, path)
        if not os.path.isfile(file_path):
            self.set_status(404)
        else:
            self.set_header("Content-Type", "application/octet-stream")
            with open(file_path, "rb") as open_file:
                self.write(open_file.read())
        self.finish()


class DeleteHandler(BaseHandler):
    """Delete Handler."""

    def data_received(self, chunk):
        pass

    def delete(self, inventory_id):
        """Answer DELETE request."""
        rh_account = self._get_rh_account()
        delete_message = {"type": "delete", "id": inventory_id, "account": rh_account}
        self.application.queue.send(delete_message)
        LOGGER.info("Delete: %s", delete_message)
        self.finish()


class RbacHandler(BaseHandler):
    """RBAC mock"""

    def data_received(self, chunk):
        pass

    def get(self):
        """Answer GET request"""
        self.write(json.dumps({'meta': {'count': 1, 'limit': 10, 'offset': 0},
                               'links': {'first': '/api/rbac/v1/access/?application=vulnerability&limit=1000&offset=0',
                                         'next': None, 'previous': None, 'last': '/api/rbac/v1/access/?application=vulnerability&limit=1000&offset=0'},
                               'data': [{'permission': 'vulnerability:*:*', 'resourceDefinitions': []}]}))


class InsightsRulesHandler(BaseHandler):
    """Insights rule API mock"""

    def data_received(self, chunk):
        pass

    def get(self, rule_id):  # pylint: disable=unused-argument
        """Answer GET request"""
        self.write("""{
            "rule_id": "CVE_2017_14491_dnsmasq|CVE_2017_14491_ERROR",
            "created_at": "2019-02-07T19:02:34.162678Z",
            "updated_at": "2020-02-21T13:39:30.779402Z",
            "ruleset": {
                "created_at": "2018-12-21T01:33:00Z",
                "updated_at": "2018-12-21T01:33:00Z",
                "rule_source": "https://gitlab.cee.redhat.com/insights-open-source/insights-security",
                "description": "Security"
            },
            "description": "CVE-2017-14491: dnsmasq code execution with listening processes",
            "active": true,
            "category": {
                "id": 2,
                "name": "Security"
            },
            "impact": {
                "name": "Remote Code Execution",
                "impact": 4
            },
            "likelihood": 4,
            "node_id": "3199382",
            "tags": "cve security",
            "playbook_count": 1,
            "reboot_required": false,
            "publish_date": "2017-10-02T13:00:00Z",
            "summary": "A buffer overflow vulnerability was found in `Dnsmasq`, a popular lightweight DNS and DHCP server. This can lead to remote code execution. Dnsmasq is used either standalone or directly by applications including `libvirt`.\n",
            "generic": "A vulnerability was discovered in Dnsmasq which allows an attacker to overflow a heap buffer and crash or take control of Dnsmasq. This is accomplished through DNS requests to Dnsmasq querying a domain controlled by the attacker. \n\nDnsmasq is a popular lightweight DNS and DHCP server, often used in home networks and cloud environments as a caching DNS\nstub resolver and to manage DHCP leases. It is used either standalone or directly by applications including libvirt, and\nin a number of layered products. libvirt is a management tool for managing Linux containers and virtual machines.\n\nThis vulnerability can lead to remote code execution and could be triggered by a malicious user on the network.\n\nRed Hat recommends that you update Dnsmasq packages to include the [CVE-2017-14491](http://access.redhat.com/security/cve/CVE-2017-14491) security release.",
            "reason": "This system is vulnerable because:\n\n* It is running a vulnerable package",
            "more_info": "* For more information about this specific flaw, see its [knowledge base article](https://access.redhat.com/security/vulnerabilities/3199382).\n*",
            "impacted_systems_count": 0,
            "reports_shown": false,
            "resolution_set": [
                {
                "system_type": 105,
                "resolution": "Red Hat recommends that you update the `dnsmasq` package",
                "resolution_risk": {
                    "name": "Update Package",
                    "risk": 1
                },
                "has_playbook": true
                }
            ],
            "total_risk": 4,
            "hosts_acked_count": 0,
            "rating": 0
            }""".replace('\n', ''))


class InventoryHandler(BaseHandler):
    """Inventory mock"""

    def data_received(self, chunk):
        pass

    def get(self, inventory_id):
        """Answer GET request"""
        if inventory_id not in self.application.inventory_id_to_profile_cache:
            self.set_status(404)
        else:
            prof = self.application.inventory_id_to_profile_cache[inventory_id]
            self.set_header("Content-Type", "application/json")
            self.write(
                json.dumps({"results": [{
                    "id": inventory_id,
                    "system_profile": {
                        "installed_packages": prof["installed_packages"],
                        "yum_repos": [{"id": r, "name": r, "enabled": True} for r in prof["yum_repos"]],
                        "dnf_modules": prof["dnf_modules"]}
                }]}))
        self.finish()


class PatchAdvisoriesHandler(BaseHandler):
    """Patchman Advisories mock"""

    def data_received(self, chunk):
        pass

    def get(self, system_id):  # pylint: disable=unused-argument
        """Answer GET request"""
        self.write(json.dumps({"data": [
            {
                "attributes": {
                    "advisory_type": 1,
                    "applicable_systems": 10,
                    "description": "The bash packages provide Bash...",
                    "public_date": "2020-09-01T15:22:07Z",
                    "severity": 2,
                    "synopsis": "Moderate: bash security update"},
                "id": "RHSA-2020:3592",
                "type": "advisory"}],
            'links': {},
            'meta': {}}))
        self.finish()


class PatchSystemsHandler(BaseHandler):
    """Patchman Systems mock"""

    def data_received(self, chunk):
        pass

    def get(self, advisory_id):  # pylint: disable=unused-argument
        """Answer GET request"""
        self.write(json.dumps({"data": [
            {
                "attributes": {
                    "display_name": "inv-3.example.com",
                    "last_evaluation": "2020-10-05T16:56:12.810595Z",
                    "last_upload": "2020-10-05T16:56:12.612509Z",
                    "rhsa_count": 1,
                    "rhba_count": 5,
                    "rhea_count": 0,
                    "stale": False,
                    "packages_installed": 1,
                    "packages_updatable": 1
                },
                "id": "00000000-0000-0000-0000-000000000003",
                "type": "system"}],
            'links': {},
            'meta': {}}))
        self.finish()


class PatchViewsSystemsAdvHandler(BaseHandler):
    """Patchman /views/systems/advisories mock"""

    def data_received(self, chunk):
        pass

    def post(self):
        """Answer POST request"""
        data = json.loads(self.request.body)

        systems = data.get('systems', [])
        advisories = data.get('advisories', [])

        if len(systems) >= 1 and len(advisories) >= 1:
            self.write(json.dumps({"data": {
                '00000000-0000-0000-0000-000000000005': ['RHSA-2014:1999'],
            }}))
        else:
            self.write(json.dumps({"data": {}}))
        self.finish()


class ExploitsHandler(BaseHandler):
    """Backoffice-proxy for prod sec /v1/exploits mock"""

    def data_received(self, chunk):
        pass

    def get(self):
        """Answer GET request"""
        self.write(json.dumps([
            {
                "cves": [
                    "CVE-2016-1"
                ],
                "exploits": [
                    {
                        "cvss3_temporal_metrics": "E:F/RL:U/RC:R",
                        "disclosure_date": "2010-10-18T00:00:00Z",
                        "first_seen": "2020-09-18T14:40:52Z",
                        "last_updated": "2020-09-22T02:56:51Z",
                        "name": "exploit/linux/local/name",
                        "source": "metasploit",
                        "summary": "some summary"
                    },
                ],
                "id": 1
            },
            {
                "cves": [
                    "CVE-2013-1"
                ],
                "exploits": [
                    {
                        "cvss3_temporal_metrics": "E:F/RL:U/RC:R",
                        "disclosure_date": "2010-10-18T00:00:00Z",
                        "first_seen": "2020-09-18T14:40:52Z",
                        "last_updated": "2020-09-22T02:56:51Z",
                        "name": "exploit/linux/local/name",
                        "source": "metasploit",
                        "summary": "some summary"
                    },
                ],
                "id": 2
            },
        ]))
        self.finish()


class ServerApplication(Application):
    """Platform mock application."""

    def __init__(self):
        handlers = [
            (r"/api/v1/upload/?", UploadHandler),
            (r"/api/v1/download/(.+)", DownloadHandler),
            (r"/api/v1/delete/(.+)", DeleteHandler),
            (r"/api/rbac/v1/access.+", RbacHandler),
            (r"/api/inventory/v1/hosts/(.+)/system_profile", InventoryHandler),
            (r"/api/insights/v1/rule/(.+)", InsightsRulesHandler),
            (r"/api/patch/v1/systems/(.+)/advisories", PatchAdvisoriesHandler),
            (r"/api/patch/v1/advisories/(.+)/systems", PatchSystemsHandler),
            (r"/api/patch/v1/views/systems/advisories", PatchViewsSystemsAdvHandler),
            (r"/v1/exploits", ExploitsHandler),
        ]
        Application.__init__(self, handlers)
        self.instance = IOLoop.instance()
        self.queue = mqueue.MQWriter(mqueue.EVENTS_TOPIC, bootstrap_servers="localhost:9092")
        self.archive_to_profile_cache = {}
        self.inventory_id_to_profile_cache = {}

    def start(self):
        """Start platform mock server."""
        self.instance.start()

    async def stop(self):
        """Stop platform mock server."""
        await self.queue.stop()
        self.instance.stop()


def main():
    """Main platform mock entrypoint."""
    init_logging()
    if not os.path.exists(STORAGE_PATH):
        os.makedirs(STORAGE_PATH)
    DatabasePool(1)
    LOGGER.info("Starting platform mock.")
    app = ServerApplication()
    app.listen(8000)

    def terminate(*_):
        """Trigger shutdown."""
        LOGGER.info("Signal received, stopping application.")
        IOLoop.instance().add_callback_from_signal(app.stop)

    signals = (signal.SIGHUP, signal.SIGTERM, signal.SIGINT)
    for sig in signals:
        signal.signal(sig, terminate)

    app.start()
    LOGGER.info("Shutting down.")


if __name__ == '__main__':
    main()
