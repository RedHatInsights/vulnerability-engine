"""Platform mock upload module."""
import base64
import hashlib
import json
import os
import signal
import uuid
from datetime import datetime
from datetime import timezone

from data.rules import RULES
from distutils.util import strtobool
from insights import make_metadata
from insights import rule
from insights import run
from insights.parsers.dnf_modules import DnfModules
from insights.parsers.installed_rpms import Installed
from insights.parsers.yum_repos_d import YumReposD
from insights.specs import Specs
from tornado.ioloop import IOLoop
from tornado.web import Application
from tornado.web import RequestHandler

from common import mqueue
from common.config import Config
from common.database_handler import DatabasePool
from common.database_handler import DatabasePoolConnection
from common.logging import get_logger
from common.logging import init_logging

LOGGER = get_logger(__name__)
STORAGE_PATH = "/tmp/storage"

CFG = Config()


@rule(
    optional=[
        Specs.machine_id,
        Installed,
        YumReposD,
        DnfModules
    ]
)
def system_profile(machine_id, installed_rpms, yum_repos_d, dnf_modules):
    profile = {}
    if machine_id:
        profile["id"] = machine_id.content[0].strip()
    profile["installed_packages"] = []
    if installed_rpms:
        for pkg_name in installed_rpms.packages:
            pkg = installed_rpms.get_max(pkg_name)
            profile["installed_packages"].append(pkg.nevra)

    profile["yum_repos"] = []
    if yum_repos_d:
        for repo_file in yum_repos_d:
            if repo_file.file_name == 'redhat.repo':
                for repo in repo_file:
                    if repo_file[repo].get('enabled', '1').lower() in ('1', 'true', 'enabled', 'yes', 'on'):
                        profile["yum_repos"].append(repo)
                break

    profile["dnf_modules"] = []
    if dnf_modules:
        for module in dnf_modules:
            for module_name in module.sections():
                profile["dnf_modules"].append({'name': module_name,
                                               'stream': module.get(module_name, 'stream')})
    metadata_response = make_metadata()
    metadata_response.update(profile)
    return metadata_response


def generate_hits(sha1):
    passed = []
    reports = []
    for rule in RULES:
        keys = list(RULES[rule].keys())
        key = keys[int(sha1, 16) % len(keys)]
        if key == 'pass':
            passed.append(RULES[rule][key])
        else:
            reports.append(RULES[rule][key])
    return passed, reports


class BaseHandler(RequestHandler):
    """Base Handler."""

    def _get_rh_account(self):
        if "x-rh-identity" not in self.request.headers:
            return "0", "0"
        encoded_value = self.request.headers["x-rh-identity"]
        decoded_value = base64.b64decode(encoded_value).decode("utf-8")
        identity = json.loads(decoded_value)
        return identity.get("identity", {}).get("account_number", "0"), identity.get("identity", {}).get("org_id", "0")


class UploadHandler(BaseHandler):
    """Upload Handler."""

    def data_received(self, chunk):
        pass

    def _get_upload_multiplier(self):
        if "x-upload-multiplier" not in self.request.headers:
            return 1
        multiplier = self.request.headers["x-upload-multiplier"]
        return int(multiplier) if multiplier.isdigit() else 1

    def _should_include_rules(self):
        return strtobool(self.request.headers.get("x-include-rules", "false"))

    def _get_reporter(self):
        return self.request.headers.get("x-reporter", "puptoo")

    def post(self):
        """Answer POST request.
           curl -X POST -F "file=@./file.tar.gz" http://localhost:8100/api/v1/upload
           curl -X POST -F "file=@./file.tar.gz" -H "x-upload-multiplier: 10" http://localhost:8100/api/v1/upload
           curl -X POST -F "file=@./file.tar.gz" -H "x-include-rules: true" http://localhost:8100/api/v1/upload
           curl -X POST -F "file=@./file.tar.gz" -H "x-reporter: rhsm-system-profile-bridge" http://localhost:8100/api/v1/upload
        """
        if self.request.files and "file" in self.request.files:
            sha1 = hashlib.sha1(self.request.files["file"][0]["body"]).hexdigest()
            file_name = "%s.tar.gz" % sha1
            file_path = os.path.join(STORAGE_PATH, file_name)
            if not os.path.exists(file_path):
                with open(file_path, "wb") as open_file:
                    open_file.write(self.request.files["file"][0]["body"])
            if sha1 in self.application.archive_to_profile_cache:
                profile = self.application.archive_to_profile_cache[sha1]
            else:
                broker = run(system_profile, root=file_path)
                profile = broker[system_profile]
                self.application.archive_to_profile_cache[sha1] = profile
                self.application.inventory_id_to_profile_cache[profile.get("id", None)] = profile
            download_url = "http://platform_mock:8000/api/v1/download/%s" % file_name
            rh_account, org_id = self._get_rh_account()
            timestamp = datetime.now(timezone.utc).isoformat()
            upload_message = {"host": {"id": profile.get("id", None), "account": rh_account,
                                       "org_id": org_id,
                                       "display_name": sha1 + ".example.com",
                                       "system_profile": {
                                           "installed_packages": profile["installed_packages"],
                                           "yum_repos": [{"id": r, "name": r, "enabled": True} for r in profile["yum_repos"]],
                                           "dnf_modules": profile["dnf_modules"],
                                           "insights_client_version": "3.0.13-1"},
                                       "reporter": self._get_reporter()
                                       },
                              "platform_metadata": {"request_id": str(uuid.uuid1()), "url": download_url,
                                                    "b64_identity": self.request.headers.get("x-rh-identity", "")},
                              "timestamp": timestamp,
                              "type": "created"
                              }
            passed, reports = generate_hits(sha1)
            advisor_message = {
                "results": {
                    "pass": passed,
                    "reports": reports,
                },
                "input": {
                    "host": {
                        "id": profile.get("id", None),
                        "account": rh_account,
                        "org_id": org_id,
                        "display_name": sha1 + ".example.com",
                        "reporter": self._get_reporter()
                    },
                    "platform_metadata": {
                        "request_id": str(uuid.uuid1()),
                        "url": download_url,
                        "b64_identity": self.request.headers.get("x-rh-identity", "")
                    },
                    "timestamp": timestamp
                }
            }
            with DatabasePoolConnection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                                insert into inventory.hosts_v1_1 values (%s, 0, %s, '[]', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP, '2030-07-21 05:35:53.682554+00', '{}', %s, '[]')
                                on conflict (id) do update set display_name = EXCLUDED.display_name, updated = CURRENT_TIMESTAMP
                                """, (upload_message["host"]["id"],
                                      upload_message["host"]["display_name"],
                                      upload_message["host"]["id"]))
                conn.commit()
            for _ in range(self._get_upload_multiplier()):
                self.application.inventory_queue.send(upload_message)
                LOGGER.info("New inventory upload: %s", upload_message)
                if self._should_include_rules():
                    self.application.advisor_queue.send(advisor_message)
                    LOGGER.info("New advisor upload: %s", advisor_message)
        else:
            self.set_status(400)
        self.finish()


class DownloadHandler(BaseHandler):
    """Download Handler."""

    def data_received(self, chunk):
        pass

    def get(self, path):
        """Answer GET request."""
        file_path = os.path.join(STORAGE_PATH, path)
        if not os.path.isfile(file_path):
            self.set_status(404)
        else:
            self.set_header("Content-Type", "application/octet-stream")
            with open(file_path, "rb") as open_file:
                self.write(open_file.read())
        self.finish()


class DeleteHandler(BaseHandler):
    """Delete Handler."""

    def data_received(self, chunk):
        pass

    def delete(self, inventory_id):
        """Answer DELETE request."""
        rh_account, org_id = self._get_rh_account()
        delete_message = {"type": "delete", "id": inventory_id,
                          "account": rh_account, "org_id": org_id}
        self.application.inventory_queue.send(delete_message)
        LOGGER.info("Delete: %s", delete_message)
        self.finish()


class RbacHandler(BaseHandler):
    """RBAC mock"""

    def data_received(self, chunk):
        pass

    def get(self):
        """Answer GET request"""
        self.write(
            json.dumps(
                {
                    "meta": {"count": 1, "limit": 10, "offset": 0},
                    "links": {
                        "first": "/api/rbac/v1/access/?application=vulnerability&limit=1000&offset=0",
                        "next": None,
                        "previous": None,
                        "last": "/api/rbac/v1/access/?application=vulnerability,inventory&limit=1000&offset=0",
                    },
                    "data": [
                        {"permission": "vulnerability:*:*", "resourceDefinitions": []},
                        {"permission": "remediations:remediation:read", "resourceDefinitions": []},
                        {"permission": "inventory:hosts:*", "resourceDefinitions": []},
                    ],
                }
            )
        )


class InsightsRulesHandler(BaseHandler):
    """Insights rule API mock"""

    def data_received(self, chunk):
        pass

    def get(self, rule_id):  # pylint: disable=unused-argument
        """Answer GET request"""
        self.write("""{
            "rule_id": "CVE_2017_14491_dnsmasq|CVE_2017_14491_ERROR",
            "created_at": "2019-02-07T19:02:34.162678Z",
            "updated_at": "2020-02-21T13:39:30.779402Z",
            "ruleset": {
                "created_at": "2018-12-21T01:33:00Z",
                "updated_at": "2018-12-21T01:33:00Z",
                "rule_source": "https://gitlab.cee.redhat.com/insights-open-source/insights-security",
                "description": "Security"
            },
            "description": "CVE-2017-14491: dnsmasq code execution with listening processes",
            "active": true,
            "category": {
                "id": 2,
                "name": "Security"
            },
            "impact": {
                "name": "Remote Code Execution",
                "impact": 4
            },
            "likelihood": 4,
            "node_id": "3199382",
            "tags": "cve security",
            "playbook_count": 1,
            "reboot_required": false,
            "publish_date": "2017-10-02T13:00:00Z",
            "summary": "A buffer overflow vulnerability was found in `Dnsmasq`, a popular lightweight DNS and DHCP server. This can lead to remote code execution. Dnsmasq is used either standalone or directly by applications including `libvirt`.\n",
            "generic": "A vulnerability was discovered in Dnsmasq which allows an attacker to overflow a heap buffer and crash or take control of Dnsmasq. This is accomplished through DNS requests to Dnsmasq querying a domain controlled by the attacker. \n\nDnsmasq is a popular lightweight DNS and DHCP server, often used in home networks and cloud environments as a caching DNS\nstub resolver and to manage DHCP leases. It is used either standalone or directly by applications including libvirt, and\nin a number of layered products. libvirt is a management tool for managing Linux containers and virtual machines.\n\nThis vulnerability can lead to remote code execution and could be triggered by a malicious user on the network.\n\nRed Hat recommends that you update Dnsmasq packages to include the [CVE-2017-14491](http://access.redhat.com/security/cve/CVE-2017-14491) security release.",
            "reason": "This system is vulnerable because:\n\n* It is running a vulnerable package",
            "more_info": "* For more information about this specific flaw, see its [knowledge base article](https://access.redhat.com/security/vulnerabilities/3199382).\n*",
            "impacted_systems_count": 0,
            "reports_shown": false,
            "resolution_set": [
                {
                "system_type": 105,
                "resolution": "Red Hat recommends that you update the `dnsmasq` package",
                "resolution_risk": {
                    "name": "Update Package",
                    "risk": 1
                },
                "has_playbook": true
                }
            ],
            "total_risk": 4,
            "hosts_acked_count": 0,
            "rating": 0
            }""".replace('\n', ''))


class InventoryHandler(BaseHandler):
    """Inventory mock"""

    def data_received(self, chunk):
        pass

    def get(self, inventory_id):
        """Answer GET request"""
        if inventory_id not in self.application.inventory_id_to_profile_cache:
            self.set_status(404)
        else:
            prof = self.application.inventory_id_to_profile_cache[inventory_id]
            self.set_header("Content-Type", "application/json")
            self.write(
                json.dumps({"results": [{
                    "id": inventory_id,
                    "system_profile": {
                        "installed_packages": prof["installed_packages"],
                        "yum_repos": [{"id": r, "name": r, "enabled": True} for r in prof["yum_repos"]],
                        "dnf_modules": prof["dnf_modules"]}
                }]}))
        self.finish()


class ExploitHandler(BaseHandler):
    """/api/v1/exploits mock"""

    def data_received(self, chunk):
        pass

    def get(self):
        """Answer GET request"""
        self.write(json.dumps(
            {"content": base64.b64encode(json.dumps({
                "CVE-2016-1": [
                    {
                        "date": "2022-01-01",
                        "source": "CISA",
                        "reference": "N/A"
                    },
                ],
                "CVE-2013-1": [
                    {
                        "date": "2022-01-01",
                        "source": "CISA",
                        "reference": "N/A"
                    },
                ],
            }).encode('utf-8')).decode()
            }
        ))
        self.finish()


class ServerApplication(Application):
    """Platform mock application."""

    def __init__(self):
        handlers = [
            (r"/api/v1/upload/?", UploadHandler),
            (r"/api/v1/download/(.+)", DownloadHandler),
            (r"/api/v1/delete/(.+)", DeleteHandler),
            (r"/api/rbac/v1/access.+", RbacHandler),
            (r"/api/inventory/v1/hosts/(.+)/system_profile", InventoryHandler),
            (r"/api/insights/v1/rule/(.+)", InsightsRulesHandler),
            (r"/api/v1/exploits", ExploitHandler),
        ]
        Application.__init__(self, handlers)
        self.instance = IOLoop.instance()
        self.inventory_queue = mqueue.MQWriter(CFG.events_topic, bootstrap_servers="localhost:9092")
        self.advisor_queue = mqueue.MQWriter(CFG.advisor_results_topic, bootstrap_servers="localhost:9092")
        self.archive_to_profile_cache = {}
        self.inventory_id_to_profile_cache = {}

    def start(self):
        """Start platform mock server."""
        self.instance.start()

    async def stop(self):
        """Stop platform mock server."""
        await self.inventory_queue.stop()
        await self.advisor_queue.stop()
        self.instance.stop()


def main():
    """Main platform mock entrypoint."""
    init_logging()
    if not os.path.exists(STORAGE_PATH):
        os.makedirs(STORAGE_PATH)
    DatabasePool(1)
    LOGGER.info("Starting platform mock.")
    app = ServerApplication()
    app.listen(8000)

    def terminate(*_):
        """Trigger shutdown."""
        LOGGER.info("Signal received, stopping application.")
        IOLoop.instance().add_callback_from_signal(app.stop)

    signals = (signal.SIGHUP, signal.SIGTERM, signal.SIGINT)
    for sig in signals:
        signal.signal(sig, terminate)

    app.start()
    LOGGER.info("Shutting down.")


if __name__ == '__main__':
    main()
