# -*- coding: utf-8 -*-
# pylint: disable=no-self-use
"""
Unit tests for listener module
"""

import asyncio
from concurrent.futures import ThreadPoolExecutor
from copy import deepcopy
import logging

import pytest

import listener.upload_listener
from listener.upload_listener import format_vmaas_request, db_import_system, process_upload, LOGGER, \
    terminate, LISTENER_QUEUE, EVALUATOR_QUEUE, on_thread_done, \
    db_delete_system, process_delete, ImportStatus, db_import_repos, db_import_system_repos, db_init_repo_cache, \
    db_delete_other_system_repos, db_update_system, process_update
from common.database_handler import DatabasePool, DatabasePoolConnection
from common.mqueue import MQWriter

# We should refactor upload_listener to be a class where db and other things
# are initialized in __init__() method.  This would allow us to override
# those things in unit tests here.

PACKAGE_LIST = ['package-a', 'package-b']
REPO_LIST = ['repo-c', 'repo-d']
MODULES_LIST = ['module-e', 'module-f']
RESULT_JSON = '{"package_list": ["package-a", "package-b"], ' \
              '"repository_list": ["repo-c", "repo-d"], ' \
              '"modules_list": ["module-e", "module-f"]}'

A_SYSTEM = {'vmaas-json': 'NEW-JSON', 'host': {'id': 'NEW-ID',
                                               'account': 'NEW-ACCT',
                                               'display_name': 'example.com',
                                               'stale_timestamp': '2020-01-09T10:17:33.881280+00:00',
                                               'stale_warning_timestamp': '2020-01-16T10:17:33.881280+00:00',
                                               'culled_timestamp': '2020-01-23T10:17:33.881280+00:00'},
            'platform_metadata': {'url': 'NEW-URL'}}
A_SYSTEM_DELETE = {'id': 'NEW-ID', 'account': 'NEW-ACCT'}
A_SYSTEM_UPDATE = {'host': {'id': 'NEW-ID', 'display_name': 'new.example.com'}}


class TestUploadListner:
    """Unit tests for vulnerability-listener."""

    @pytest.mark.asyncio
    async def test_terminate(self):
        """test_terminate"""
        loop = asyncio.new_event_loop()
        await terminate(0, loop)
        assert not loop.is_running()
        assert not LISTENER_QUEUE.connected
        assert not EVALUATOR_QUEUE.connected

    def test_on_thread_done(self, caplog):
        "test_on_thread_done"
        with caplog.at_level(logging.ERROR):
            with ThreadPoolExecutor(max_workers=1) as executor:
                future_ok = executor.submit(lambda: True)
                future_ok.add_done_callback(on_thread_done)
        assert not caplog.records  # empty log
        caplog.clear()

        with caplog.at_level(logging.ERROR):
            with ThreadPoolExecutor(max_workers=1) as executor:
                future_fail = executor.submit(lambda: 1/0)
                future_fail.add_done_callback(on_thread_done)
        assert caplog.records  # not empty log
        caplog.clear()

    def test_format_vmaas_request(self):
        """test_format_vmaas_request"""
        result = format_vmaas_request(PACKAGE_LIST, repo_list=REPO_LIST, modules_list=MODULES_LIST)
        assert result
        assert result == RESULT_JSON

    @staticmethod
    def _mark_evaluated(inventory_id: str):
        with DatabasePoolConnection() as conn:
            with conn.cursor() as cur:
                cur.execute("""update system_platform set last_evaluation = CURRENT_TIMESTAMP
                               where inventory_id = %s""", (inventory_id,))
            conn.commit()

    def test_import_system(self, pg_db_conn, caplog):  # pylint: disable=unused-argument
        """Test importing a system not-in-the-db, followed by same so it's-already-there"""
        # new system
        with DatabasePool(1):
            rtrn = db_import_system(A_SYSTEM, A_SYSTEM['vmaas-json'], [])
            assert ImportStatus.INSERTED | ImportStatus.CHANGED == rtrn

            self._mark_evaluated(A_SYSTEM['host']['id'])

            # And now it's an rtrn['updated'], but same json
            rtrn = db_import_system(A_SYSTEM, A_SYSTEM['vmaas-json'], [])
            assert ImportStatus.UPDATED == rtrn

            # And now it's another rtrn['updated'], same json
            rtrn = db_import_system(A_SYSTEM, A_SYSTEM['vmaas-json'], [])
            assert ImportStatus.UPDATED == rtrn

            # And now it's an rtrn['updated'], with diff json
            rtrn = db_import_system(A_SYSTEM, A_SYSTEM['vmaas-json'] + '-1', [])
            assert ImportStatus.UPDATED | ImportStatus.CHANGED == rtrn

            # And try to import system with invalid inventory id
            with caplog.at_level(logging.ERROR):
                system_copy = deepcopy(A_SYSTEM)
                system_copy['host']['id'] = None
                db_import_system(system_copy, A_SYSTEM['vmaas-json'], [])
            assert caplog.records[0].msg.startswith("Error importing system:")
            caplog.clear()

    def test_process_upload(self, pg_db_conn, monkeypatch, caplog):  # pylint: disable=unused-argument
        """Test to see that upload only sends eval-msgs on new systems and ones with new vmaas_json"""
        upld_data = {'host': {'id': 'A-SYSTEM-ID', 'account': 'AN-ACCOUNT', 'system_profile': {'installed_packages': ['kernel']}},
                     'platform_metadata': {'url': 'A-URL', 'request_id': 'some-request-id'},
                     'timestamp': 'some-time-stamp'}
        monkeypatch.setattr(MQWriter, 'send', lambda self, msg, loop: LOGGER.info('SENT'))

        with DatabasePool(1):
            # first-upload - should send
            caplog.clear()
            with caplog.at_level(logging.INFO):
                sent = process_upload(upld_data, None)
            assert caplog.records[0].msg == 'SENT'
            assert sent is True

            self._mark_evaluated(upld_data['host']['id'])

            # re-upload - should not send
            caplog.clear()
            with caplog.at_level(logging.INFO):
                sent = process_upload(upld_data, None)
            assert sent is False

            # same-id, diff pkg profile - should send
            upld_data['host']['system_profile']['installed_packages'].append('glibc')
            caplog.clear()
            with caplog.at_level(logging.INFO):
                sent = process_upload(upld_data, None)
            assert caplog.records[0].msg == 'SENT'
            assert sent is True

    def test_update_system(self, pg_db_conn, caplog):  # pylint: disable=unused-argument
        """Test updating a system."""
        with DatabasePool(1):
            # make sure system is in DB
            db_import_system(A_SYSTEM, A_SYSTEM['vmaas-json'], [])

            # now update the system
            rtrn = db_update_system(A_SYSTEM_UPDATE)
            assert rtrn['updated']
            assert not rtrn['failed']

            # try to update system with non-existing id
            rtrn = db_update_system({'host': {'id': '1-XXX', 'display_name': 'new.example.com'}})
            assert not rtrn['updated']
            assert not rtrn['failed']
            caplog.clear()

    def test_process_update(self, pg_db_conn, caplog):  # pylint: disable=unused-argument
        """Test updating a system."""

        with DatabasePool(1):
            # make sure system is in DB
            db_import_system(A_SYSTEM, A_SYSTEM['vmaas-json'], [])

            # update the system
            with caplog.at_level(logging.INFO):
                process_update(A_SYSTEM_UPDATE)
            assert caplog.records[0].msg.startswith("Updated system with inventory_id:")
            caplog.clear()

            # try to update system with non-existing id
            with caplog.at_level(logging.INFO):
                process_update({'host': {'id': '1-XXX', 'display_name': 'new.example.com'}})
            assert caplog.records[0].msg.startswith('Unable to update system, inventory_id not found: ')
            caplog.clear()

    def test_delete_system(self, pg_db_conn, caplog):  # pylint: disable=unused-argument
        """Test deleting a system."""
        with DatabasePool(1):
            # make sure system is in DB
            db_import_system(A_SYSTEM, A_SYSTEM['vmaas-json'], [])

            # now delete the system
            rtrn = db_delete_system(A_SYSTEM_DELETE)
            assert rtrn['deleted']
            assert not rtrn['failed']

            # and again, same result, because the record in system_platform still exists
            rtrn = db_delete_system(A_SYSTEM_DELETE)
            assert rtrn['deleted']
            assert not rtrn['failed']

            # try to delete system with non-existing id
            rtrn = db_delete_system({'id': '0', 'account': 'NEW-ACCT'})
            assert not rtrn['deleted']
            assert not rtrn['failed']
            caplog.clear()

    def test_process_delete(self, pg_db_conn, caplog):  # pylint: disable=unused-argument
        """Test deleting a system."""

        msg_dict = {'id': A_SYSTEM_DELETE['id'] + '1', 'account': A_SYSTEM_DELETE['account']}

        with DatabasePool(1):
            # make sure system is in DB
            system_copy = deepcopy(A_SYSTEM)
            system_copy['host']['id'] += '1'
            db_import_system(system_copy, system_copy['vmaas-json'], [])

            # delete the system
            with caplog.at_level(logging.INFO):
                process_delete(msg_dict)
            assert caplog.records[0].msg.startswith("Deleted system with inventory_id:")
            caplog.clear()

            with caplog.at_level(logging.WARNING):
                db_import_system(system_copy, system_copy['vmaas-json'], [])
            assert caplog.records[0].msg.startswith('Received recently deleted inventory id:')
            caplog.clear()

    @staticmethod
    def _create_testing_system(cur, inventory_id: str):
        cur.execute("""insert into system_platform
                       (inventory_id, rh_account_id, s3_url, vmaas_json, json_checksum)
                       values (%s, 0, 'url', '{}', '0') returning id""", (inventory_id,))
        return cur.fetchone()[0]

    @staticmethod
    def _clean_tmp_db_items(cur, inventory_ids: tuple):
        cur.execute("""delete from system_repo""")
        cur.execute("""delete from repo""")
        cur.execute("""delete from system_platform where inventory_id in %s""", (inventory_ids,))
        listener.upload_listener.REPO_ID_CACHE = {}

    def test_import_repos(self, pg_db_conn):
        """Test import repos to db. Ensure unique repos."""

        cur = pg_db_conn.cursor()
        self._clean_tmp_db_items(cur, ("s1",))
        inserted = db_import_repos(cur, ["repo1", "repo2", "repo1"])
        assert len(inserted) == 2
        assert set(inserted) == {"repo1", "repo2"}

        inserted = db_import_repos(cur, ["repo2", "repo3", "repo4"])
        assert len(inserted) == 2
        assert set(inserted) == {"repo3", "repo4"}

        cur.execute("""select name from repo""")
        rows = cur.fetchall()
        assert len(rows) == 4
        assert {"repo1", "repo2", "repo3", "repo4"} == {repo_name for repo_name, *_ in rows}
        self._clean_tmp_db_items(cur, ("s1",))

    def test_init_repo_cache(self, pg_db_conn):
        """Test initializing repo cache."""

        cur = pg_db_conn.cursor()
        self._clean_tmp_db_items(cur, ("s1",))
        inserted = db_import_repos(cur, ["repo1", "repo2", "repo1"])
        assert len(inserted) == 2
        assert set(inserted) == {"repo1", "repo2"}
        assert len(listener.upload_listener.REPO_ID_CACHE) == 2
        listener.upload_listener.REPO_ID_CACHE = {}
        with DatabasePool(1):
            db_init_repo_cache()
        assert len(listener.upload_listener.REPO_ID_CACHE) == 2
        self._clean_tmp_db_items(cur, ("s1",))

    def test_import_system_repos(self, pg_db_conn):
        """Test import system_repo items to db."""

        cur = pg_db_conn.cursor()
        self._clean_tmp_db_items(cur, ("s1",))
        repos = ["repo1", "repo2"]
        db_import_repos(cur, repos)
        system_id = self._create_testing_system(cur, "s1")
        inserted = db_import_system_repos(cur, repos, system_id)
        assert len(inserted) == 2
        cur.execute("select system_id, repo.name from system_repo inner join repo on repo.id = repo_id")
        rows = cur.fetchall()
        assert len(rows) == 2
        assert set(rows) == {(system_id, "repo1"), (system_id, "repo2")}
        self._clean_tmp_db_items(cur, ("s1",))

    def test_delete_other_system_repos(self, pg_db_conn):
        """Test delete not actual system_repo items."""

        cur = pg_db_conn.cursor()
        self._clean_tmp_db_items(cur, ("s1",))
        repos = ["repo1", "repo2", "repo3"]
        inserted_repos = db_import_repos(cur, repos)
        assert len(inserted_repos) == 3
        system_id = self._create_testing_system(cur, "s1")
        inserted = db_import_system_repos(cur, ["repo1", "repo2", "repo3"], system_id)
        assert len(inserted) == 3
        deleted_system_repos = db_delete_other_system_repos(cur, ["repo3"], system_id)
        assert len(deleted_system_repos) == 2
