# -*- coding: utf-8 -*-
# pylint: disable=no-self-use
"""
Unit tests for vmaas_sync module
"""
import asyncio
import logging
import os
import datetime
import pytest
from tornado.web import Application
import tornado.websocket

from common.database_handler import DatabasePool
from common import constants

from vmaas_sync.vmaas_sync import sync_cve_md, sync_repo_md, ServerApplication, LOGGER
import vmaas_sync.vmaas_sync as vmaas_sync
from ..scripts.vmaas_mock import CVES_RESPONSE, REPOS_RESPONSE


class VmaasServerApplication(ServerApplication):
    """Subclass to override __init__ and ignore aiokafka setup"""

    def __init__(self):  # pylint: disable=super-init-not-called
        handlers = None
        Application.__init__(self, handlers)  # pylint: disable=non-parent-init-called
        self.instance = None
        self.vmaas_websocket_url = "ws://%s/" % os.getenv("VMAAS_WEBSOCKET_HOST", "vmaas_websocket:8082")
        self.vmaas_websocket = None
        self.reconnect_callback = None
        self.evaluator_queue = None


class TestMqueueWriter:
    """Pretends to know how to send kafka msgs"""
    @staticmethod
    async def _do_nothing():
        pass

    def send(self, msg):
        """send from cve sync"""
        LOGGER.info(msg)
        return asyncio.ensure_future(self._do_nothing())

    def send_list(self, msg_list):
        """send from re_evaluate_systems"""
        for msg in msg_list:
            LOGGER.info(msg['host']['id'])
        return asyncio.ensure_future(self._do_nothing())


class TestVmaasSync:
    """Tests for vmaas_sync and friends"""
    # pylint: disable=too-many-public-methods

    @staticmethod
    def check_cve_sync_logs(records, start_offset):
        """Check to see we got the expected msgs from sync_cve_md"""
        assert records[start_offset].msg == 'Syncing CVE metadata'
        assert records[start_offset+1].msg.startswith('Importing CVE metadata')
        assert records[start_offset+2].msg == 'Finished syncing CVE metadata'

    @staticmethod
    def check_repo_sync_logs(records, start_offset):
        """Check to see that we tried to sync repos"""
        assert records[start_offset].msg == 'Syncing repo metadata'
        # Because monkeypatch is set for CVE
        assert records[start_offset+1].msg == 'Cannot sync repo metadata from vmaas'

    @staticmethod
    def check_re_evaluate_all_logs(records, start_offset):
        """Check to see we got the expected msgs from re_evaluate_vmaas all systems"""
        assert records[start_offset].msg == 'Re-evaluating all systems'

    @staticmethod
    def check_re_eval_repo_based_logs(records, start_offset):
        """Check to see we got the expected msgs from re_evaluate_vmaas repo based"""
        assert records[start_offset].message == '%s repos found updated since 2018-04-04T23:23:45+00:00' \
            % len(REPOS_RESPONSE["repository_list"])
        assert records[start_offset+1].msg == 'Re-evaluating in repo-based mode'

    def test_sync_cve_md_positive(self, pg_db_conn, monkeypatch, caplog, cleanup):  # pylint: disable=unused-argument
        """Test calling sync_cve_md with vmaas responding with data"""
        monkeypatch.setattr(vmaas_sync, 'paging', lambda endpoint, cve_request: (True, CVES_RESPONSE))

        with caplog.at_level(logging.INFO):
            with DatabasePool(1):
                result = sync_cve_md()
            assert result
        self.check_cve_sync_logs(caplog.records, 0)
        caplog.clear()

    def test_sync_cve_md_negative(self, pg_db_conn, monkeypatch, caplog, cleanup):  # pylint: disable=unused-argument
        """Test calling sync_cve_md with vmaas responding with nothing"""
        monkeypatch.setattr(vmaas_sync, 'paging', lambda endpoint, cve_request: (False, {}))

        with caplog.at_level(logging.INFO):
            with DatabasePool(1):
                result = sync_cve_md()
            assert not result
        assert caplog.records[0].msg == 'Syncing CVE metadata'
        caplog.clear()

    @pytest.mark.asyncio
    async def test_re_evaluate_all(self, pg_db_conn, monkeypatch, caplog):  # pylint: disable=unused-argument
        """Test re_evaluate_systems - all-systems mode"""
        monkeypatch.setattr(ServerApplication, '_websocket_reconnect', lambda self: True)
        monkeypatch.setattr(tornado.websocket, 'websocket_connect', lambda: True)
        srvapp = VmaasServerApplication()
        srvapp.evaluator_queue = TestMqueueWriter()  # mqueue.MQWriter(mqueue.EVALUATOR_TOPIC)
        with caplog.at_level(logging.INFO):
            with DatabasePool(1):
                await srvapp.re_evaluate_systems(repo_based=False)
        self.check_re_evaluate_all_logs(caplog.records, 0)
        caplog.clear()

    @pytest.mark.asyncio
    async def test_re_evaluate_repo_based(self, pg_db_conn, monkeypatch, caplog):  # pylint: disable=unused-argument
        """Test re_evaluate_systems - repo-based mode with page control"""
        monkeypatch.setattr(vmaas_sync, 'paging', lambda endpoint, repos_request: (True, REPOS_RESPONSE))
        monkeypatch.setattr(ServerApplication, '_websocket_reconnect', lambda self: True)
        monkeypatch.setattr(tornado.websocket, 'websocket_connect', lambda: True)
        srvapp = VmaasServerApplication()
        srvapp.evaluator_queue = TestMqueueWriter()  # mqueue.MQWriter(mqueue.EVALUATOR_TOPIC)
        with caplog.at_level(logging.INFO):
            with DatabasePool(1):
                await srvapp.re_evaluate_systems(repo_based=True)
        self.check_re_eval_repo_based_logs(caplog.records, 0)
        caplog.clear()

    @pytest.mark.asyncio
    async def test_read_websocket(self, pg_db_conn, monkeypatch, caplog):  # pylint: disable=unused-argument
        """Test getting msg from mqueue - requires combined sync_cve/re-evaluate setup"""
        # prep for sync_cve_md
        monkeypatch.setattr(vmaas_sync, 'paging', lambda endpoint, cve_request: (True, CVES_RESPONSE))
        # prep for re_evaluate_systems
        monkeypatch.setattr(ServerApplication, '_websocket_reconnect', lambda self: True)
        monkeypatch.setattr(tornado.websocket, 'websocket_connect', lambda: True)
        srvapp = VmaasServerApplication()
        srvapp.evaluator_queue = TestMqueueWriter()  # mqueue.MQWriter(mqueue.EVALUATOR_TOPIC)

        with caplog.at_level(logging.INFO):
            with DatabasePool(1):
                await srvapp._read_websocket_message('webapps-refreshed')  # pylint: disable=protected-access

        assert caplog.records[0].msg == 'VMaaS cache refreshed'
        self.check_cve_sync_logs(caplog.records, 1)
        self.check_repo_sync_logs(caplog.records, 4)
        self.check_re_evaluate_all_logs(caplog.records, 6)
        caplog.clear()

    def test_bogus_message(self, caplog):
        """Test getting EMPTY and UNRECOGNIZED msg from mqueue"""
        class EmptyWebsocket:
            """Lets us warn about websocket close-failure"""

            def __init__(self):
                self.close_reason = 'TEST'
                self.close_code = 666
        srvapp = VmaasServerApplication()
        srvapp.vmaas_websocket = EmptyWebsocket()

        with caplog.at_level(logging.INFO):
            srvapp._read_websocket_message(None)  # pylint: disable=protected-access
        assert caplog.records[0].levelname == 'WARNING'
        assert caplog.record_tuples[0][2] == 'Connection to ws://vmaas_websocket:8082/ closed: TEST (666)'
        caplog.clear()

        with caplog.at_level(logging.INFO):
            srvapp._read_websocket_message('whatthehell?!?')  # pylint: disable=protected-access
        assert not caplog.records
        caplog.clear()

    def test_select_inv_ids_1(self, pg_db_conn):
        """Test select all inventory_ids"""
        with pg_db_conn:
            cur = pg_db_conn.cursor()
            ServerApplication.select_all_inventory_ids(cur)
            assert len(cur.fetchall()) == 15

    def test_select_inv_ids_2(self, pg_db_conn):
        """Test select inventory_ids repo collection"""
        with pg_db_conn:
            cur = pg_db_conn.cursor()
            repos = ["repo1"]
            ServerApplication.select_repo_based_inventory_ids(cur, repos)
            assert len(cur.fetchall()) == 2

    def test_select_inv_ids_3(self, pg_db_conn):
        """Test select inventory_ids with empty repo collection"""
        with pg_db_conn:
            cur = pg_db_conn.cursor()
            repos = []
            ServerApplication.select_repo_based_inventory_ids(cur, repos)
            assert list(cur.fetchall()) == []

    def test_last_repobased_eval_tms_1(self, pg_db_conn):
        """Test select repo-based eval timestamp"""
        with pg_db_conn:
            cur = pg_db_conn.cursor()
            val = ServerApplication.get_last_repobased_eval_tms(cur)
            assert val is not None

    def test_last_repobased_eval_tms_2(self, pg_db_conn):
        """Test select empty repo-based eval timestamp"""
        with pg_db_conn:
            cur = pg_db_conn.cursor()
            cur.execute("delete from timestamp_kv where name = %s", (constants.TIMESTAMP_LAST_REPO_BASED_EVAL,))
            val = ServerApplication.get_last_repobased_eval_tms(cur)
            assert val is None

    def test_last_repobased_eval_tms_3(self, pg_db_conn):
        """Test update repo-based eval timestamp"""
        with pg_db_conn:
            cur = pg_db_conn.cursor()
            cur.execute("delete from timestamp_kv where name = %s", (constants.TIMESTAMP_LAST_REPO_BASED_EVAL,))
            val = datetime.datetime(2014, 1, 1, 8, 1, 1, tzinfo=datetime.timezone(datetime.timedelta(hours=2)))
            val_ret, inserted = ServerApplication.set_last_repobased_eval_tms(cur, val)
            assert inserted
            assert val_ret.isoformat() == '2014-01-01T06:01:01+00:00'

    def test_last_repobased_eval_tms_4(self, pg_db_conn):
        """Test update repo-based eval timestamp"""
        with pg_db_conn:
            cur = pg_db_conn.cursor()
            val = datetime.datetime(2014, 1, 1, 6, 1, 1, tzinfo=datetime.timezone(datetime.timedelta(hours=2)))
            val_ret, inserted = ServerApplication.set_last_repobased_eval_tms(cur, val)
            assert not inserted  # updated
            assert val_ret.isoformat() == '2014-01-01T04:01:01+00:00'

    # pylint: disable=unused-argument
    def test_sync_cve_md_delete(self, pg_db_conn, monkeypatch, caplog, cleanup):
        """Test calling sync_cve_md with vmaas responding with data"""
        cves = CVES_RESPONSE.copy()
        del cves['cve_list']['CVE-2017-3']
        del cves['cve_list']['CVE-2018-1']
        monkeypatch.setattr(vmaas_sync, 'paging', lambda endpoint, cve_request: (True, cves))

        with caplog.at_level(logging.INFO):
            with DatabasePool(1):
                result = sync_cve_md()
            assert result

        assert caplog.records[2].msg.startswith('Deleting')
        assert caplog.records[3].msg == 'Finished deleting unnecessary CVE metadata'
        assert caplog.records[4].msg.startswith('Unable to delete')
        caplog.clear()

    def test_sync_repo_md_positive(self, pg_db_conn, monkeypatch, caplog, cleanup):
        """Check if engine will perform correct sync"""
        monkeypatch.setattr(vmaas_sync, "paging", lambda endpoint, repo_request: (True, REPOS_RESPONSE))

        with caplog.at_level(logging.INFO):
            with DatabasePool(1):
                result = sync_repo_md()
            assert result

        assert caplog.messages[0] == 'Syncing repo metadata'
        assert caplog.messages[1] == 'Inserting %s new repositories' % (len(REPOS_RESPONSE["repository_list"]))
        # This is because our ve_db_dev_data.sql has two initial repos REPO1 & REPO2
        # and repo2 has no linked repositories
        assert caplog.messages[2] == 'Checking for deletion %s repositories' % (2)
        # This is not linked repo2
        assert caplog.messages[3] == 'Deleting %s repositories' % (1)
        # This is linked repo1
        assert 'Unable to delete %s repositories' % (1) in caplog.messages[4]
        assert 'repo1' in caplog.messages[4]
        assert caplog.messages[5] == 'Finished syncing repo metadata'
        caplog.clear()

        with pg_db_conn:
            cur = pg_db_conn.cursor()
            cur.execute("select name from repo")
            added_repos = list(REPOS_RESPONSE["repository_list"].keys())
            # Need to add repo1 because that is added by default
            added_repos.append("repo1")
            for repo in cur:
                assert repo[0] in added_repos

    def test_sync_repo_md_deletion(self, pg_db_conn, monkeypatch, caplog, cleanup):
        """Check if repo gets deleted when its not in vmaas but its in engine and some is linked"""
        repos = REPOS_RESPONSE.copy()
        # Keep our original repos from dev data, we will delete it later
        repos["repository_list"]["repo1"] = {}
        repos["repository_list"]["repo2"] = {}

        monkeypatch.setattr(vmaas_sync, "paging", lambda endpoint, repo_request: (True, repos))
        with caplog.at_level(logging.INFO):
            with DatabasePool(1):
                result = sync_repo_md()
            assert result

        assert caplog.messages[0] == 'Syncing repo metadata'
        # 3 new repositories, because REPO1 and REPO2 are default
        assert caplog.messages[1] == 'Inserting %s new repositories' % (3)
        assert caplog.messages[2] == 'Finished syncing repo metadata'

        removed_repos = ["repo1", "repo2", "vmaas-test-rhel8-module"]
        # Now we will remove the 3 repos we inserted at start
        for removed_repo in removed_repos:
            del repos["repository_list"][removed_repo]

        monkeypatch.setattr(vmaas_sync, "paging", lambda endpoint, repo_request: (True, repos))

        with caplog.at_level(logging.INFO):
            with DatabasePool(1):
                result = sync_repo_md()
            assert result

        assert caplog.messages[3] == 'Syncing repo metadata'
        # 2 repos are default (repo1, repo2) + 1 deleted from dict
        assert caplog.messages[4] == 'Checking for deletion %s repositories' % (3)
        # This is because vmaas-test... and repo2 are not linked with any system
        assert caplog.messages[5] == 'Deleting %s repositories' % (2)
        # Repo1 is linked
        assert 'Unable to delete %s' % (1) in caplog.messages[6]
        assert 'repo1' in caplog.messages[6]
        assert caplog.messages[7] == 'Finished syncing repo metadata'
        caplog.clear()

        with pg_db_conn:
            cur = pg_db_conn.cursor()
            cur.execute("select name from repo")
            for name in cur:
                assert name != removed_repo

    def test_sync_repo_md_empty(self, pg_db_conn, monkeypatch, caplog, cleanup):
        """Check if sync is empty"""
        monkeypatch.setattr(vmaas_sync, "paging", lambda endpoint, repo_request: (True, {}))

        with caplog.at_level(logging.INFO):
            with DatabasePool(1):
                result = sync_repo_md()
            assert not result

        assert caplog.messages[0] == 'Syncing repo metadata'
        assert caplog.messages[1] == 'Cannot sync repo metadata from vmaas'
        caplog.clear()

    def test_sync_repo_md_empty_repos(self, pg_db_conn, monkeypatch, caplog, cleanup):
        """Give empty repository list, so delete all repos"""
        monkeypatch.setattr(vmaas_sync, "paging", lambda endpoint, repo_request: (True, {"repository_list": {}}))

        with pg_db_conn:
            cur = pg_db_conn.cursor()
            cur.execute("select count(name) from repo")
            repos_len = cur.fetchall()[0][0]

        with caplog.at_level(logging.INFO):
            with DatabasePool(1):
                result = sync_repo_md()
            assert result

        assert caplog.messages[0] == 'Syncing repo metadata'
        assert caplog.messages[1] == 'Checking for deletion %s repositories' % (repos_len)
        # Repo1 is not linked with any system
        assert caplog.messages[2] == 'Deleting %s repositories' % (1)
        # Repo2 is still linked with system
        assert 'Unable to delete %s' % (1) in caplog.messages[3]
        assert 'repo1' in caplog.messages[3]
        assert caplog.messages[4] == 'Finished syncing repo metadata'
        caplog.clear()
