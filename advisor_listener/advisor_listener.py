"""Rules engine results listener"""
import asyncio
from datetime import datetime, timedelta
import json
from os import getenv
import signal

from prometheus_client import Counter, start_http_server
from psycopg2.extras import execute_values
import pytz

from common import mqueue
from common.bounded_executor import BoundedExecutor
from common.database_handler import DatabaseError, DatabasePool, DatabasePoolConnection
from common.identity import get_identity, is_entitled_smart_management
from common.logging import init_logging, get_logger

LOGGER = get_logger(__name__)

PROMETHEUS_PORT = getenv('PROMETHEUS_PORT', '8086')
WORKER_THREADS = int(getenv('WORKER_THREADS', '30'))
MAX_QUEUE_SIZE = int(getenv('MAX_QUEUE_SIZE', '30'))
SYSTEM_DELETION_THRESHOLD = int(getenv('SYSTEM_DELETION_THRESHOLD', '24'))  # 24 hours

PROCESS_MESSAGES = Counter('ve_advisor_listener_messages_processed', '# of messages processed')
NEW_SYSTEM = Counter('ve_advisor_listener_upl_new_system', '# of new systems inserted by advisor')
UPDATE_SYSTEM = Counter('ve_advisor_listener_upl_update_system', '# of systems updated')
UNCHANGED_SYSTEM = Counter('ve_advisor_listener_upl_unchanged_system', '# of system-updates with same rules hit')
MESSAGE_PARSE_ERROR = Counter('ve_advisor_listener_message_parse_error', '# of message parse errors')
INVALID_IDENTITY = Counter('ve_advisor_listener_invalid_identity', '# of skipped uploads because of invalid identity')
MISSING_SMART_MANAGEMENT = Counter('ve_advisor_listener_non_smart_management', '# of skipped uploads because of entitlement check')
DATABASE_ERROR = Counter('ve_advisor_listener_database_error', '# of database errors')
DELETED_UPLOADED = Counter('ve_advisor_listener_deleted_uploaded', '# of systems uploaded after being deleted')
NEW_RH_ACCOUNT = Counter('ve_advisor_listener_upl_new_rh_account', '# of new rh accounts inserted')


ADVISOR_QUEUE = mqueue.MQReader([mqueue.ADVISOR_RESULTS_TOPIC])

RULE_BLACKLIST = ['CVE_2017_5715_cpu_virt|VIRT_CVE_2017_5715_CPU_3_ONLYKERNEL']

RULES_CACHE = {}
CVES_CACHE = {}


async def terminate(_, loop):
    """Trigger shutdown."""
    LOGGER.info('Signal received, stopping kafka consumers.')
    await ADVISOR_QUEUE.stop()
    loop.stop()


def db_import_cve(cve: str):
    """Import missing CVE metadata into database"""
    with DatabasePoolConnection() as conn:
        with conn.cursor() as cur:
            try:
                cur.execute("""INSERT INTO cve_metadata (cve, description, impact_id) VALUES %s ON CONFLICT (cve) DO UPDATE SET cve = %s
                RETURNING id AS inserted""", ((cve, 'unknown', 0,), cve))
                conn.commit()
                inserted = cur.fetchone()
                CVES_CACHE[cve] = inserted[0]
            except DatabaseError:
                DATABASE_ERROR.inc()
                LOGGER.exception("Error updating CVEs cache: ")


def db_import_rule(rule_id: str):
    """Import single error key into database"""
    with DatabasePoolConnection() as conn:
        with conn.cursor() as cur:
            try:
                cur.execute("""INSERT INTO insights_rule (name) VALUES(%s) ON CONFLICT (name) DO UPDATE SET name = %s
                RETURNING id AS inserted""", ((rule_id,), rule_id))
                conn.commit()
                inserted = cur.fetchone()
                RULES_CACHE[rule_id] = inserted
            except DatabaseError:
                DATABASE_ERROR.inc()
                LOGGER.exception("Error updating rules cache: ")
                conn.rollback()


def db_import_rule_hits(cur, rh_account_id: int, system_id: int, opt_out: bool, rule_hits: dict):
    """Associate rules hits with system"""

    to_update = []
    system_cves = []
    updated_rules = {}  # system cves which previously had no rule associated
    if rule_hits:
        cur.execute("""SELECT id, cve_id, rule_id, when_mitigated, status_id FROM system_vulnerabilities WHERE system_id = %s AND cve_id IN %s""",
                    (system_id, tuple(rule_hits.keys()),))
        for row_id, cve_id, rule_id, when_mitigated, status_id in cur.fetchall():
            if rule_id is None:
                updated_rules[cve_id] = (row_id, rule_id, when_mitigated, status_id)
            to_update.append((row_id, rule_hits[cve_id],))
            del rule_hits[cve_id]  # rule hits become dict of completely new system cves
            system_cves.append(cve_id)

    fixed_rules = {}
    if system_cves:
        cur.execute("""SELECT id, cve_id, rule_id, when_mitigated, status_id FROM system_vulnerabilities
                    WHERE system_id = %s AND rule_id IS NOT NULL AND cve_id NOT IN %s""",
                    (system_id, tuple(system_cves),))
    else:
        cur.execute("""SELECT id, cve_id, rule_id, when_mitigated, status_id FROM system_vulnerabilities WHERE system_id = %s AND rule_id IS NOT NULL""",
                    (system_id,))
    for row_id, cve_id, rule_id, when_mitigated, status_id in cur.fetchall():
        to_update.append((row_id, None,))
        fixed_rules[cve_id] = (row_id, rule_id, when_mitigated, status_id)

    if rule_hits:
        insert_new_cves(cur, system_id, rule_hits)
    if to_update:
        update_cves(cur, to_update)
    if not opt_out:
        update_caches(cur, rh_account_id, rule_hits, updated_rules, fixed_rules)


def update_caches(cur, rh_account_id: int, new_rule_hits: dict, updated_rules: dict, fixed_rules: dict):  # pylint: disable=too-many-branches
    """Update CVE caches"""
    print('rule hits: ', new_rule_hits)
    print('updated_rules: ', updated_rules)
    print('fixed_rules: ', fixed_rules)
    new_cves_ids = list(new_rule_hits.keys())
    updated_cves_ids = list(updated_rules.keys())
    fixed_cves_ids = list(fixed_rules.keys())
    all_cves_ids = new_cves_ids + updated_cves_ids + fixed_cves_ids

    if not all_cves_ids:
        return

    inc_cves = []
    inc_cves_divergent_status = []
    dec_cves = []
    dec_cves_divergent_status = []
    cur.execute("""select cve_id, status_id from cve_account_data
                       where rh_account_id = %s and cve_id in %s
                       order by cve_id for update""",
                (rh_account_id, tuple(all_cves_ids),))
    for cve_id, status_id in cur.fetchall():
        # completely new system_vulnerabilities record, update caches
        if cve_id in new_cves_ids:
            if status_id == 0:
                inc_cves.append(cve_id)
            else:
                inc_cves_divergent_status.append(cve_id)
        # do not double increase counts if CVE has already been imported by VMaaS
        elif cve_id in updated_cves_ids and updated_rules[cve_id][2] is not None:
            if status_id == updated_rules[cve_id][3]:
                inc_cves.append(cve_id)
            else:
                inc_cves_divergent_status.append(cve_id)
        # decrease counter only when VMaaS thinks we're not vulnerabale
        elif cve_id in fixed_cves_ids and fixed_rules[cve_id][2] is not None:
            if status_id == fixed_rules[cve_id][3]:
                dec_cves.append(cve_id)
            else:
                dec_cves_divergent_status.append(cve_id)
        all_cves_ids.remove(cve_id)

    insert_cves = [(cve_id, rh_account_id, 1, 0) for cve_id in all_cves_ids]

    if dec_cves:
        cur.execute("""update cve_account_data set systems_affected = systems_affected - 1
                            where rh_account_id = %s and cve_id in %s""", (rh_account_id, tuple(dec_cves)))

    if dec_cves_divergent_status:
        cur.execute("""update cve_account_data set systems_affected = systems_affected - 1,
                                                    systems_status_divergent = systems_status_divergent - 1
                        where rh_account_id = %s and cve_id in %s""", (rh_account_id, tuple(dec_cves_divergent_status)))

    if inc_cves:
        cur.execute("""update cve_account_data set systems_affected = systems_affected + 1
                            where rh_account_id = %s and cve_id in %s""", (rh_account_id, tuple(inc_cves)))

    if inc_cves_divergent_status:
        cur.execute("""update cve_account_data set systems_affected = systems_affected + 1,
                                                    systems_status_divergent = systems_status_divergent + 1
                        where rh_account_id = %s and cve_id in %s""", (rh_account_id, tuple(inc_cves_divergent_status)))

    if insert_cves:
        execute_values(cur, """insert into cve_account_data
                                (cve_id, rh_account_id, systems_affected, systems_status_divergent) values %s
                                on conflict (cve_id, rh_account_id) do update set
                                    systems_affected = cve_account_data.systems_affected
                                                    + excluded.systems_affected,
                                    systems_status_divergent = cve_account_data.systems_status_divergent
                                                            + excluded.systems_status_divergent""",
                       insert_cves, page_size=len(insert_cves))


def db_import_system(system_data: dict, rule_hits: dict):
    """Import results from advisor into DB"""
    with DatabasePoolConnection() as conn:
        with conn.cursor() as cur:
            rh_account_id, system_id, opt_out = db_import_system_platform(cur, system_data)
            if system_id is None:
                return
            db_import_rule_hits(cur, rh_account_id, system_id, opt_out, rule_hits)
            conn.commit()


def db_import_system_platform(cur, system_data: dict):
    """Import/update system platform data"""
    curr_time = datetime.now(tz=pytz.utc)
    cur.execute("""select inventory_id from deleted_systems where inventory_id = %s and when_deleted > %s""",
                (system_data['inventory_id'], curr_time - timedelta(hours=SYSTEM_DELETION_THRESHOLD, )))
    if cur.fetchone() is not None:
        LOGGER.warning('Received recently deleted inventory id: %s', system_data['inventory_id'])
        DELETED_UPLOADED.inc()
        return None, None, None

    cur.execute("""INSERT INTO rh_account (name) VALUES(%s) ON CONFLICT (name) DO NOTHING
                RETURNING (xmax = 0) AS inserted""", (system_data['rh_account'],))
    inserted = cur.fetchone()
    if inserted:
        NEW_RH_ACCOUNT.inc()

    cur.execute("""SELECT id FROM rh_account WHERE name = %s""", (system_data['rh_account'],))
    rh_account_id = cur.fetchone()[0]

    cur.execute("""INSERT INTO system_platform
                (inventory_id, rh_account_id, display_name)
                VALUES (%s, %s, %s)
                ON CONFLICT (inventory_id) DO UPDATE SET
                rh_account_id = %s, display_name = %s
                RETURNING (xmax = 0) AS inserted, id, opt_out""",
                (system_data['inventory_id'], rh_account_id, system_data['display_name'],
                 rh_account_id, system_data['display_name']))

    inserted, system_id, opt_out = cur.fetchone()
    if inserted:
        NEW_SYSTEM.inc()
    else:
        UPDATE_SYSTEM.inc()

    return rh_account_id, system_id, opt_out


def db_init_caches():
    """Init caches for faster lookups"""
    with DatabasePoolConnection() as conn:
        with conn.cursor() as cur:
            try:
                cur.execute("""SELECT id, name FROM insights_rule""")
                for rule_db_id, rule_name in cur.fetchall():
                    RULES_CACHE[rule_name] = rule_db_id
                cur.execute("""SELECT id, cve FROM cve_metadata""")
                for cve_id, cve_name in cur.fetchall():
                    CVES_CACHE[cve_name] = cve_id
            except DatabaseError:
                DATABASE_ERROR.inc()
                LOGGER.exception("Error initializing caches: ")
                conn.rollback()


def insert_new_cves(cur, system_id, new_rule_hits):
    """Import completely new system_vulnerability record, not found by VMaaS"""
    cve_system_list = [(system_id, cve, new_rule_hits[cve],) for cve in new_rule_hits]
    execute_values(cur, """INSERT INTO system_vulnerabilities (system_id, cve_id, rule_id) values %s""",
                   cve_system_list, page_size=len(cve_system_list))


def update_cves(cur, to_update):
    """Updates existing records in system_vulnerabilities, either adding new rule hit or updating it"""
    execute_values(cur, """UPDATE system_vulnerabilities AS sv SET rule_id = v.rule_id FROM (VALUES %s) AS v(id, rule_id) WHERE v.id = sv.id""",
                   to_update, template="(%s, %s::integer)", page_size=len(to_update))


def main():
    """Application entrypoint"""
    start_http_server(int(PROMETHEUS_PORT))
    init_logging()
    LOGGER.info('Starting advisor listener.')

    loop = asyncio.get_event_loop()
    signals = (signal.SIGHUP, signal.SIGTERM, signal.SIGINT)
    for sig in signals:
        loop.add_signal_handler(
            sig, lambda sig=sig: loop.create_task(terminate(sig, loop)))
    executor = BoundedExecutor(MAX_QUEUE_SIZE, max_workers=WORKER_THREADS)

    def process_message(msg):
        """Message processing logic"""
        PROCESS_MESSAGES.inc()
        LOGGER.info('Received message on topic %s', msg.topic)
        LOGGER.debug('Message body: %s', msg.value)

        try:
            msg_dict = json.loads(msg.value.decode('utf8'))
        except json.decoder.JSONDecodeError:
            MESSAGE_PARSE_ERROR.inc()
            LOGGER.exception('Unable to parse message: ')
            return

        identity = get_identity(msg_dict['input']['platform_metadata']['b64_identity'])
        if identity is None:
            INVALID_IDENTITY.inc()
            LOGGER.warning('Skipped advisor result due to invalid identity header.')
            return
        if not is_entitled_smart_management(identity, allow_missing_section=True):
            # TODO: remove with together with SM removal
            MISSING_SMART_MANAGEMENT.inc()
            LOGGER.debug('Skipped advisor result due to missing smart_management entitlement.')
            return

        # TODO: insert system into database if it's 1st upload, shall we update last seen?
        system_data = {
            'rh_account': msg_dict['input']['host']['account'],
            'display_name': msg_dict['input']['host']['display_name'],
            'inventory_id': msg_dict['input']['host']['id']
        }

        rule_hits = {}

        reports = msg_dict['results']['reports']
        for report in reports:
            failed_cves = report['details'].get('cves_fail', [])
            if failed_cves:
                rule = report['rule_id']
                if rule in RULE_BLACKLIST:
                    # TODO: remove this once CVE_2017_5753_4_cpu_kernel and CVE_2017_5715_cpu_virt are merged
                    continue
                if rule not in RULES_CACHE:
                    db_import_rule(rule)
                for cve in failed_cves:
                    if cve not in CVES_CACHE:
                        db_import_cve(cve)
                    rule_hits[CVES_CACHE[cve]] = RULES_CACHE[rule]

        db_import_system(system_data, rule_hits)

    with DatabasePool(WORKER_THREADS):
        db_init_caches()

        ADVISOR_QUEUE.listen(process_message)

        loop.run_forever()

        LOGGER.info('Shutting down.')
        executor.shutdown()


if __name__ == '__main__':
    main()
