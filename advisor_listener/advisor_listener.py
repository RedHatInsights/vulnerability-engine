"""Rules engine results listener"""
import asyncio
import json
from os import getenv
import signal

from prometheus_client import Counter, start_http_server

from common import mqueue
from common.bounded_executor import BoundedExecutor
from common.database_handler import DatabaseError, DatabasePool, DatabasePoolConnection
from common.identity import get_identity, is_entitled_smart_management
from common.logging import init_logging, get_logger

LOGGER = get_logger(__name__)

PROMETHEUS_PORT = getenv('PROMETHEUS_PORT', '8086')
WORKER_THREADS = int(getenv('WORKER_THREADS', '30'))
MAX_QUEUE_SIZE = int(getenv('MAX_QUEUE_SIZE', '30'))

PROCESS_MESSAGES = Counter('ve_advisor_listener_messages_processed', '# of messages processed')
NEW_SYSTEM = Counter('ve_advisor_listener_upl_new_system', '# of new systems inserted by advisor')
UPDATE_SYSTEM = Counter('ve_advisor_listener_upl_update_system', '# of systems updated')
UNCHANGED_SYSTEM = Counter('ve_advisor_listener_upl_unchanged_system', '# of system-updates with same rules hit')
MESSAGE_PARSE_ERROR = Counter('ve_advisor_listener_message_parse_error', '# of message parse errors')
INVALID_IDENTITY = Counter('ve_advisor_listener_invalid_identity', '# of skipped uploads because of invalid identity')
MISSING_SMART_MANAGEMENT = Counter('ve_advisor_listener_non_smart_management', '# of skipped uploads because of entitlement check')
DATABASE_ERROR = Counter('ve_advisor_listener_database_error', '# of database errors')

ADVISOR_QUEUE = mqueue.MQReader([mqueue.ADVISOR_RESULTS_TOPIC])


RULES_CACHE = {}


async def terminate(_, loop):
    """Trigger shutdown."""
    LOGGER.info('Signal received, stopping kafka consumers.')
    await ADVISOR_QUEUE.stop()
    loop.stop()


def db_import_rule(rule_id: str):
    """Import single error key into database"""
    with DatabasePoolConnection() as conn:
        with conn.cursor() as cur:
            try:
                cur.execute("""INSERT INTO insights_rule (name) VALUES(%s) ON CONFLICT (name) DO UPDATE
                RETURNING id AS inserted""", (rule_id,))
                conn.commit()
                inserted = cur.fetchone()
                RULES_CACHE[rule_id] = inserted
            except DatabaseError:
                DATABASE_ERROR.inc()
                LOGGER.exception("Error updating rules cache: ")
                conn.rollback()


def db_init_rules_cache():
    """Init rules cache for faster lookups"""
    with DatabasePoolConnection() as conn:
        with conn.cursor() as cur:
            try:
                cur.execute("""SELECT id, name FROM insights_rule""")
                for rule_db_id, rule_name in cur.fetchall():
                    RULES_CACHE[rule_name] = rule_db_id
            except DatabaseError:
                DATABASE_ERROR.inc()
                LOGGER.exception("Error initializing rules cache: ")
                conn.rollback()


def main():
    """Application entrypoint"""
    start_http_server(int(PROMETHEUS_PORT))
    init_logging()
    LOGGER.info('Starting advisor listener.')

    loop = asyncio.get_event_loop()
    signals = (signal.SIGHUP, signal.SIGTERM, signal.SIGINT)
    for sig in signals:
        loop.add_signal_handler(
            sig, lambda sig=sig: loop.create_task(terminate(sig, loop)))
    executor = BoundedExecutor(MAX_QUEUE_SIZE, max_workers=WORKER_THREADS)

    def process_message(msg):
        """Message processing logic"""
        PROCESS_MESSAGES.inc()
        LOGGER.info('Received message on topic %s', msg.topic)

        try:
            msg_dict = json.loads(msg.value.decode('utf8'))
        except json.decoder.JSONDecodeError:
            MESSAGE_PARSE_ERROR.inc()
            LOGGER.exception('Unable to parse message: ')
            return

        identity = get_identity(msg_dict['input']['platform_metadata']['b64_identity'])
        if identity is None:
            INVALID_IDENTITY.inc()
            LOGGER.warning('Skipped advisor result due to invalid identity header.')
            return
        if not is_entitled_smart_management(identity, allow_missing_section=True):
            MISSING_SMART_MANAGEMENT.inc()
            LOGGER.debug('Skipped advisor result due to missing smart_management entitlement.')
            return

        # TODO: insert system into database if it's 1st upload, shall we update last seen?

        rule_hits = {}

        reports = msg_dict['results']['reports']
        for report in reports:
            failed_cves = report['details'].get('cves_fail', [])
            if failed_cves:
                rule = report['rule_id']
                if rule not in RULES_CACHE:
                    db_import_rule(rule)
                rule_hits[RULES_CACHE[rule]] = failed_cves

    with DatabasePool(WORKER_THREADS):
        db_init_rules_cache()

        ADVISOR_QUEUE.listen(process_message)

        loop.run_forever()

        LOGGER.info('Shutting down.')
        executor.shutdown()


if __name__ == '__main__':
    main()
