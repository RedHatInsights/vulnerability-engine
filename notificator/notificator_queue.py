"""
NotificatorQueue, processes potential notifications from queues.
"""

import asyncio
from datetime import datetime
from datetime import timedelta
from datetime import timezone

import asyncpg
from prometheus_client import Counter

from common import mqueue
from common.config import Config
from common.config import Singleton
from common.logging import get_logger
from common.logging import init_logging
from common.peewee_model import NotificationType

CFG = Config()
LOGGER = get_logger(__name__)
EVALUATION_WAIT_MINUTES = 5
SENT_NOTIFICATIONS = Counter("ve_notificator_sent_notifs_cnt", "# of sent notifications")


class QueueItem:
    """Represents notifiable cve in (unknown / normal) queue"""

    def __init__(self, cve: str, cve_id: int, rh_account_id: int, org_id: str, events: [NotificationType]):
        self.cve = cve
        self.cve_id = cve_id
        self.rh_account_id = rh_account_id
        self.org_id = org_id
        self.notif_events = events


class NotificatorQueue(metaclass=Singleton):
    """Represents queue with possible CVE notifications"""

    def __init__(self, period: int, pool: asyncpg.Pool, conditions, loop: asyncio.AbstractEventLoop):
        init_logging()
        self.loop = loop
        self.notifications_topic = mqueue.MQWriter(CFG.notifications_topic)
        self.conditions = conditions
        self.notif_cves_queue = {}
        self.unkno_cves_queue = {}
        self.db_pool = pool
        self.notified_accounts = None
        self.period = period

    async def init(self):
        """Async constructor"""
        await self.refresh_map()

    async def stop(self):
        """Stops queue loop"""
        await self.notifications_topic.stop()

    async def refresh_map(self):
        """Refresh notified accounts map"""
        self.notified_accounts = await self._create_notif_accs_map()

    async def _create_notif_accs_map(self):
        """Creates a map with already notified customers with notification event types"""
        res = {}
        async with self.db_pool.acquire() as conn:
            async with conn.transaction():
                rows = await conn.fetch("""SELECT rh_account_id, cve_id, notif_type FROM notified_accounts""")
                for notif_row in rows:
                    rh_acc = notif_row[0]
                    cve_id = notif_row[1]
                    notif_type = NotificationType(notif_row[2])
                    if (rh_acc, cve_id) not in res:
                        res[(rh_acc, cve_id)] = set()
                    res[(rh_acc, cve_id)].add(notif_type)
        return res

    async def _is_already_notified(self, rh_account_id, cve_id, event_type):
        """Returns already notified events for customer"""
        notif_events = self.notified_accounts.get((rh_account_id, cve_id), set())
        if event_type in notif_events:
            return True

        # cache can be outdated, try to fetch db and add result to cache
        new_events = set()
        async with self.db_pool.acquire() as conn:
            async with conn.transaction():
                rows = await conn.fetch(
                    """SELECT notif_type FROM notified_accounts WHERE cve_id = $1 AND rh_account_id = $2""", cve_id, rh_account_id
                )
                for notif_row in rows:
                    new_events.add(NotificationType(notif_row[0]))
        if new_events:
            self.notified_accounts[(rh_account_id, cve_id)] = new_events
        return event_type in new_events

    def _create_notif_events(self, cve_id):
        """Create list of events for notifications"""
        cve = self.conditions.get_cve(cve_id)
        if not cve:
            return []
        return [
            {
                "metadata": {},
                "payload": {
                    "reported_cve": cve["cve"],
                    "cvss_score": float(cve["cvss_score"]),
                    "impact_id": cve["impact_id"],
                    "known_exploit": cve["exploits"],
                    "has_rule": cve["is_rule"],
                    "publish_date": cve["public_date"].isoformat(),
                },
            }
        ]

    def _send_kafka_notif(
        self,
        org_id: str,
        inventory_id: str,
        display_name: str,
        event_type: str,
        events: list,
        only_admins=False,
        ignore_user_preferences=False,
        loop=None,
    ):
        """
        Sends kafka msg to notification kafka.

        org_id: org_id of user
        event_type: Notifications event type for vulnerability
        events: List with data for email templates
        only_admins: If notif should be sent only to orgs admin
        ignore_user_preferences: Ignores users settings in notifications app
        """
        msg = {
            "bundle": "rhel",
            "application": "vulnerability",
            "version": "v1.1.0",
            "event_type": event_type,
            "timestamp": datetime.utcnow().isoformat(),
            "context": {"display_name": display_name, "inventory_id": str(inventory_id)},
            "events": events,
            "recipients": [
                {
                    "only_admins": only_admins,
                    "ignore_user_preferences": ignore_user_preferences,
                }
            ],
        }
        if org_id:
            msg["org_id"] = org_id
            msg["context"]["org_id"] = org_id
        LOGGER.debug("Sending notification: %s", msg)
        self.notifications_topic.send(msg, loop=loop)

    async def _register_notified_acc(self, cve_id: int, notif_events: set(NotificationType), rh_account_id):
        """Registers new notified accounts into notified_accounts table"""
        if not notif_events:
            return

        tuples = [(rh_account_id, cve_id, notif_event.value) for notif_event in notif_events]
        async with self.db_pool.acquire() as conn:
            await conn.executemany("""INSERT INTO notified_accounts (rh_account_id, cve_id, notif_type) VALUES ($1, $2, $3)""", tuples)

        if (rh_account_id, cve_id) not in self.notified_accounts:
            self.notified_accounts[(rh_account_id, cve_id)] = notif_events
        else:
            self.notified_accounts[(rh_account_id, cve_id)] = notif_events.union(self.notified_accounts[(rh_account_id, cve_id)])

    async def _get_sys_vuln_row(self, sys_vuln_id, rh_account_id):
        """Get single system_vulnerabilities row"""
        async with self.db_pool.acquire() as conn:
            return await conn.fetchrow(
                """SELECT sp.last_evaluation, sp.advisor_evaluated, sv.mitigation_reason,
                                                sv.when_mitigated, ir.active, ir.rule_only, sp.inventory_id,
                                                sp.display_name
                                         FROM system_platform AS sp
                                         JOIN system_vulnerabilities_active AS sv ON (sv.id = $1 AND sv.system_id = sp.id AND sv.rh_account_id = $2)
                                         LEFT JOIN insights_rule AS ir ON (ir.id = sv.rule_id)
                                         WHERE sv.id = $1 AND sv.rh_account_id = $2
                                         LIMIT 1
                                         """,
                sys_vuln_id,
                rh_account_id,
            )

    @staticmethod
    def _is_fully_evaluated(sys_vuln_row):
        """Check if sys vuln was evaluated by evaluator and advisor."""
        # if both are set, count it as evaluated
        if sys_vuln_row[0] is not None and sys_vuln_row[1] is not None:
            return True
        evaluated_threshold = datetime.now(timezone.utc) - timedelta(minutes=EVALUATION_WAIT_MINUTES)
        # give 5 minutes, to wait for second component or count it as evaluated
        if sys_vuln_row[1] is not None:
            return sys_vuln_row[1] < evaluated_threshold
        if sys_vuln_row[0] is not None:
            return sys_vuln_row[0] < evaluated_threshold
        return False

    @staticmethod
    def _is_not_mitigated(sys_vuln_row):
        """Check if sys vuln is not mitigated."""
        return sys_vuln_row[3] is None or (sys_vuln_row[4] is True and sys_vuln_row[5] is False)

    async def _process_normal_queue(self):
        """Process queued notifications for CVEs
        1. Check if customer was not notified already
        2. Check if evaluation is complete (advisor + evaluator)
        3. Check if the evaluation did not get mitigated (rule pass)"""
        LOGGER.debug("Processing %s records in normal queue", len(self.notif_cves_queue))
        for sys_vuln_id in list(self.notif_cves_queue):
            try:
                item = self.notif_cves_queue[sys_vuln_id]
            except KeyError:
                continue
            sys_vuln_row = await self._get_sys_vuln_row(sys_vuln_id, item.rh_account_id)
            # sys vuln row dissapeared, delete from queue
            if not sys_vuln_row:
                LOGGER.debug("Dissapeared sys_vuln id, skipping: %s", sys_vuln_id)
                del self.notif_cves_queue[sys_vuln_id]
                continue

            # system is not fully evaluated yet, skip and leave in queue
            if not self._is_fully_evaluated(sys_vuln_row):
                LOGGER.debug("System is still not fully evaluated: %s", sys_vuln_row)
                continue

            # system is mitigated, delete from queue
            if not self._is_not_mitigated(sys_vuln_row):
                LOGGER.debug("System got mititgated, removing from queue: %s", sys_vuln_row)
                del self.notif_cves_queue[sys_vuln_id]
                continue

            inventory_id = sys_vuln_row[6]
            display_name = sys_vuln_row[7]
            new_notified = set()
            for notif_event in item.notif_events:
                # if customer was not already notified for given cve + notif type
                if not await self._is_already_notified(item.rh_account_id, item.cve_id, notif_event):
                    events = self._create_notif_events(item.cve_id)
                    self._send_kafka_notif(item.org_id, inventory_id, display_name, notif_event.value, events, loop=self.loop)
                    LOGGER.info("Sending notification about CVE: %s (%s) for %s org", item.cve, item.cve_id, item.org_id)
                    SENT_NOTIFICATIONS.inc()
                    new_notified.add(notif_event)
                else:
                    LOGGER.info("Skipping notification about CVE: %s (%s), already sent for %s org", item.cve, item.cve_id, item.org_id)
            # register sent notif
            if new_notified:
                await self._register_notified_acc(item.cve_id, new_notified, item.rh_account_id)
            # delete from queue, resolved
            del self.notif_cves_queue[sys_vuln_id]

    async def _process_unknown_queue(self):
        """Process queued unknown CVE notification
        1. Check if the CVE got known to vulnerability
        2. Send to normal queue"""
        LOGGER.debug("Processing %s records in unknown queue", len(self.unkno_cves_queue))
        for sys_vuln_id in list(self.unkno_cves_queue):
            try:
                item = self.unkno_cves_queue[sys_vuln_id]
            except KeyError:
                continue

            # check if cve got fetched and exists, if not exists, skip and wait until exists
            if not await self.conditions.cve_exists(item.cve_id):
                continue

            # create queue item, put to queue
            cve = self.conditions.cve_map[item.cve_id]["cve"]
            LOGGER.debug("%s got fetched, moving to normal queue", cve)
            events = self.conditions.make_events_for_cve(item.cve_id)
            if events:
                item = QueueItem(cve, item.cve_id, item.rh_account_id, item.org_id, events)
                self.notif_cves_queue[sys_vuln_id] = item
            # delete from queue, resolved
            del self.unkno_cves_queue[sys_vuln_id]

    async def process_queue(self):
        """Infinite loop which should be encapsulated with asyncio task"""
        LOGGER.info("Starting queue processor, running every %s seconds", self.period)
        while True:
            await asyncio.sleep(self.period)
            await self._process_queue()

    async def _process_queue(self):
        """Wrapper of single queue processing"""
        await self._process_normal_queue()
        await self._process_unknown_queue()
