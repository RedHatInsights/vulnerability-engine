# Vulnerability Engine Taskomatic

## Overview
Vulnerability Engine Taskomatic is a service for running periodic tasks in given intervals. It uses Python apscheduler as the backend for scheduling and all executed actions by the scheduler are blocking, which means if a job is taking too long and other run of the job should fire it will be skipped until the job is completed so no more than one instance of a job may run at given time.

### Adding new job
To add a new job periodically executed by Taskomatic, simply add a Python file into the `jobs` directory and ensure the Python file contains the `run()` function which is the entrypoint to the job and function which will be executed by Taskomatic. Configuration of the job is done through environment variables as there are no parameters passed into the `run` function.

### Testing or manually running the job
Jobs can be executed manually using Python, e.g. 
`python3 -c "import jobs.stale_systems as ss; ss.run()"`
If you are using devel compose, which maps your git directory into the running container you need to prepend `taskomatic` to the path of the import, e.g.
`python3 -c "import taskomatic.jobs.stale_systems as ss; ss.run()`

If you are using logging you need to do `init_logging()` first otherwise logs are not printed.
Example of manually running the job in devel container with enabled logging:
`python3 -c "from common.logging import init_logging; init_logging(); import taskomatic.jobs.stale_systems as ss; ss.run()"`

### Configuration
As stated above configuration of the job has to be through environmental variables.
To enable the newly added job you need to edit the `JOBS` variable by adding configuration of the job.
Example configuration for a dummy job located in `jobs/foo.py` run each 3 minutes would be:
`JOBS=foo:3`
If multiple jobs are to be run, simply separate them with comma character, e.g.
`JOBS=foo:3,bar:7,baz:15`
It's also possible in the OpenShift environment to have multiple Taskomatic pods running, each with different jobs enabled. However if two pods are given the same job to execute, there's no mechanism in place to ensure synchronization between the pods executing the job in order to prevent simultaneous execution.
