#!/usr/bin/env python3
"""
Taskomatic service
"""

from datetime import datetime
import asyncio
import importlib
import signal

from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.schedulers.tornado import TornadoScheduler
from apscheduler.util import undefined
from tornado.ioloop import IOLoop
from tornado.web import Application, RequestHandler

from common.config import Config
from common.logging import init_logging, get_logger
from common.utils import a_ensure_minimal_schema_version
from common.status_app import create_status_app, create_status_runner

LOGGER = get_logger(__name__)
CFG = Config()
JOBS = CFG.jobs
JOBS_STARTUP = CFG.jobs_startup
PROMETHEUS_PORT = CFG.prometheus_port or str(CFG.taskomatic_prometheus_port)
SCHEDULER = TornadoScheduler()
MAIN_LOOP = IOLoop.instance()


class RunJobHandler(RequestHandler):
    """API to immediately run job"""

    def data_received(self, chunk):
        pass

    def put(self, job_name):
        """Answer PUT request"""
        job = SCHEDULER.get_job(job_id=job_name)
        if job:
            job.modify(next_run_time=datetime.now())
            LOGGER.info("Job triggered using API: %s", job_name)
        else:
            self.set_status(404)
        self.finish()


APP = Application([
    (r"/api/v1/run/(.+)", RunJobHandler),
])
APP.listen(CFG.private_port)


def import_job(job_name):
    """Import module with job, return None if not found"""
    try:
        return importlib.import_module('.%s' % job_name, package='.taskomatic.jobs')
    except ModuleNotFoundError:
        return None


def terminate(*_):
    """Terminate the scheduler and wait for the work to finish"""
    if SCHEDULER.running:
        SCHEDULER.shutdown(wait=True)
    IOLoop.instance().add_callback_from_signal(IOLoop.instance().stop)


def main():
    """Creates scheduler, fills it up with tasks and runs it"""
    init_logging()

    LOGGER.info("Opening port [%s] for prometheus", PROMETHEUS_PORT)

    loop = asyncio.get_event_loop()
    status_app = create_status_app(LOGGER)
    _, status_site = create_status_runner(status_app, int(PROMETHEUS_PORT), LOGGER, loop)
    loop.run_until_complete(status_site.start())

    loop.run_until_complete(a_ensure_minimal_schema_version())

    signals = (signal.SIGHUP, signal.SIGTERM, signal.SIGINT)
    for sin in signals:
        signal.signal(sin, terminate)

    for job_info in JOBS:
        job_name, interval = job_info.split(':')
        job = import_job(job_name)
        if job:
            run_on_startup = job_name in JOBS_STARTUP
            if run_on_startup:
                next_run_time = datetime.now()
            else:
                next_run_time = undefined
            LOGGER.info('Adding job: %s, cadence each %s minutes, run on startup: %s', job_name, interval, run_on_startup)
            SCHEDULER.add_job(job.run, IntervalTrigger(minutes=int(interval)), id=job_name, next_run_time=next_run_time)
        else:
            LOGGER.error('Couldn\'t find job data for job: %s', job_name)
    SCHEDULER.start()
    MAIN_LOOP.start()
    LOGGER.info("Stopped.")


if __name__ == '__main__':
    main()
