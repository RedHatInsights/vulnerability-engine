#!/usr/bin/env python3
"""
Taskomatic service
"""

from datetime import datetime
import asyncio
import importlib
import signal

from apscheduler.triggers.interval import IntervalTrigger
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.util import undefined
from aiohttp import web

from common.config import Config
from common.logging import init_logging, get_logger
from common.utils import a_ensure_minimal_schema_version
from common.status_app import create_status_app, create_status_runner

LOGGER = get_logger(__name__)
CFG = Config()
JOBS = CFG.jobs
JOBS_STARTUP = CFG.jobs_startup
PROMETHEUS_PORT = CFG.prometheus_port or str(CFG.taskomatic_prometheus_port)
SCHEDULER = AsyncIOScheduler()
MAIN_LOOP = asyncio.get_event_loop()


class RunJobHandler(web.View):
    """API to immediately run job"""

    async def put(self):
        """Answer PUT request"""
        job_name = self.request.match_info.get("job_id", None)
        job = SCHEDULER.get_job(job_id=job_name)
        if job:
            job.modify(next_run_time=datetime.now())
            LOGGER.info("Job triggered using API: %s", job_name)
        else:
            return web.Response(status=400)
        return web.Response(status=200)


class TaskomaticApp:
    """Represents taskomatic app api"""

    def __init__(self):
        self.app = web.Application(logger=LOGGER)
        self.app.router.add_view(r"/api/v1/run/{job_id}", RunJobHandler)


async def create_app():
    """Start taskomatic API"""
    app = TaskomaticApp()
    runner = web.AppRunner(app.app)
    await runner.setup()
    site = web.TCPSite(runner, "0.0.0.0", CFG.private_port)
    return runner, site, app


def import_job(job_name):
    """Import module with job, return None if not found"""
    try:
        return importlib.import_module(".%s" % job_name, package=".taskomatic.jobs")
    except ModuleNotFoundError:
        return None


def main():
    """Creates scheduler, fills it up with tasks and runs it"""
    init_logging()

    LOGGER.info("Opening port [%s] for prometheus", PROMETHEUS_PORT)

    status_app = create_status_app(LOGGER)
    status_runner, status_site = create_status_runner(status_app, int(PROMETHEUS_PORT), LOGGER, MAIN_LOOP)
    MAIN_LOOP.run_until_complete(status_site.start())

    MAIN_LOOP.run_until_complete(a_ensure_minimal_schema_version())

    taskomatic_runner, taskomatic_site, _ = MAIN_LOOP.run_until_complete(create_app())
    MAIN_LOOP.run_until_complete(taskomatic_site.start())

    signals = (signal.SIGHUP, signal.SIGTERM, signal.SIGINT)
    for sin in signals:

        def terminate(*_):
            if SCHEDULER.running:
                SCHEDULER.shutdown(wait=True)
            MAIN_LOOP.create_task(taskomatic_runner.cleanup())
            MAIN_LOOP.create_task(status_runner.cleanup())
            MAIN_LOOP.stop()

        signal.signal(sin, terminate)

    for job_info in JOBS:
        job_name, interval = job_info.split(":")
        job = import_job(job_name)
        if job:
            run_on_startup = job_name in JOBS_STARTUP
            if run_on_startup:
                next_run_time = datetime.now()
            else:
                next_run_time = undefined
            LOGGER.info(
                "Adding job: %s, cadence each %s minutes, run on startup: %s", job_name, interval, run_on_startup
            )
            SCHEDULER.add_job(job.run, IntervalTrigger(minutes=int(interval)), id=job_name, next_run_time=next_run_time)
        else:
            LOGGER.error("Couldn't find job data for job: %s", job_name)
    SCHEDULER.start()
    MAIN_LOOP.run_forever()
    LOGGER.info("Stopped.")


if __name__ == "__main__":
    main()
