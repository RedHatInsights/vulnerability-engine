#!/usr/bin/env python3
"""
Periodic DB metrics to Prometheus exporter
"""

from prometheus_client import Gauge

from common.logging import get_logger, init_logging
from taskomatic.jobs.common import get_conn

LOGGER = get_logger(__name__)

METRIC_SYSTEMS = Gauge("ve_db_systems_count", "Total number of systems in DB")
METRIC_CYNDI_SYSTEMS = Gauge("ve_db_cyndi_systems_count", "Total number of systems in Cyndi schema in DB")
METRIC_SYSTEMS_MISSING_IN_CYNDI = Gauge("ve_db_systems_missing_cyndi_count", "Total number of systems in DB but missing in Cyndi schema")
METRIC_TABLE_SIZE = Gauge("ve_db_table_size", "Size of tables in DB", ["table"])
METRIC_TOP_10_ACCOUNTS_SYSTEMS = Gauge("ve_db_top_10_account_systems", "Number of systems in 10 largest accounts", ["account"])
METRIC_ACCOUNTS_COUNT = Gauge("ve_db_accounts_count", "Count of accounts by number of systems", ["bucket"])


def run():
    """Application entrypoint"""
    LOGGER.info("Started db_metrics job")

    conn = get_conn()
    cur = conn.cursor()

    cur.execute("""SELECT COUNT(*) FROM system_platform""")
    METRIC_SYSTEMS.set(int(cur.fetchone()[0]))

    cur.execute("""SELECT COUNT(*) FROM inventory.hosts""")
    METRIC_CYNDI_SYSTEMS.set(int(cur.fetchone()[0]))

    cur.execute(
        """SELECT COUNT(*)
                   FROM system_platform sp LEFT JOIN
                        inventory.hosts ih ON sp.inventory_id = ih.id
                   WHERE ih.id IS NULL
                   AND sp.when_deleted IS NULL"""
    )
    METRIC_SYSTEMS_MISSING_IN_CYNDI.set(int(cur.fetchone()[0]))

    cur.execute(
        """SELECT tablename AS key, pg_total_relation_size(quote_ident(tablename)) AS value
                   FROM (SELECT * FROM pg_catalog.pg_tables WHERE schemaname = 'public') t"""
    )
    for key, value in cur.fetchall():
        METRIC_TABLE_SIZE.labels(table=key).set(int(value))

    cur.execute(
        """SELECT a.account_number AS account, COUNT(*) AS total_systems
                   FROM system_platform sp JOIN rh_account a ON a.id = sp.rh_account_id
                   GROUP BY a.account_number ORDER BY 2 DESC LIMIT 10"""
    )
    METRIC_TOP_10_ACCOUNTS_SYSTEMS.clear()  # Need to reset because more than 10 labels would be exported when order changes
    for account, total_systems in cur.fetchall():
        METRIC_TOP_10_ACCOUNTS_SYSTEMS.labels(account=account).set(int(total_systems))

    cur.execute(
        """SELECT COUNT(*) FILTER (WHERE t.total_systems >= 1) AS at_least_1_sys,
                          COUNT(*) FILTER (WHERE t.total_systems >= 10) AS at_least_10_sys,
                          COUNT(*) FILTER (WHERE t.total_systems >= 100) AS at_least_100_sys,
                          COUNT(*) FILTER (WHERE t.total_systems >= 1000) AS at_least_1000_sys,
                          COUNT(*) FILTER (WHERE t.total_systems >= 10000) AS at_least_10000_sys,
                          COUNT(*) FILTER (WHERE t.total_systems >= 100000) AS at_least_100000_sys
                   FROM (SELECT a.account_number, COUNT(*) AS total_systems
                         FROM system_platform sp JOIN rh_account a ON a.id = sp.rh_account_id
                         GROUP BY a.account_number ORDER BY 2 DESC)t"""
    )
    at_least_1_sys, at_least_10_sys, at_least_100_sys, at_least_1000_sys, at_least_10000_sys, at_least_100000_sys = cur.fetchone()
    METRIC_ACCOUNTS_COUNT.labels(bucket=">= 1 system").set(int(at_least_1_sys))
    METRIC_ACCOUNTS_COUNT.labels(bucket=">= 10 systems").set(int(at_least_10_sys))
    METRIC_ACCOUNTS_COUNT.labels(bucket=">= 100 systems").set(int(at_least_100_sys))
    METRIC_ACCOUNTS_COUNT.labels(bucket=">= 1,000 systems").set(int(at_least_1000_sys))
    METRIC_ACCOUNTS_COUNT.labels(bucket=">= 10,000 systems").set(int(at_least_10000_sys))
    METRIC_ACCOUNTS_COUNT.labels(bucket=">= 100,000 systems").set(int(at_least_100000_sys))

    cur.close()
    conn.close()
    LOGGER.info("Finished db_metrics job")


if __name__ == "__main__":
    init_logging()
    run()
