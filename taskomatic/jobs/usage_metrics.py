"""
Feature and product usage metrics.
"""
import io
import os
import datetime
import time
from functools import wraps

from prometheus_client import Gauge
from psycopg2.extras import execute_values

from common.database_handler import DatabasePool, DatabasePoolConnection, NamedCursor
from common.logging import init_logging, get_logger

LOGGER = get_logger(__name__)

ACCOUNTS_BLACKLIST = os.getenv('ACCOUNTS_BLACKLIST', None)

MAX_RESULTS_COUNT = 20
SYSTEM_NUMS = [50, 100, 500, 1000]

CVE_STATUS_USAGE_T = Gauge("ve_usage_cve_status_t", "Total number of cve status usage", ["account"])
CVE_STATUS_USAGE_TF = Gauge("ve_usage_cve_status_tf", "Total number of cve status usage excluded RH accounts", ["account"])
SYSTEM_CVE_STATUS_USAGE_T = Gauge("ve_usage_system_cve_status_t", "Total number of system cve status usage", ["account"])
SYSTEM_CVE_STATUS_USAGE_TF = Gauge("ve_usage_system_cve_status_tf", "Total number of system cve status usage excluded RH accounts", ["account"])
CVE_BRISK_USAGE_T = Gauge("ve_usage_cve_business_risk_t", "Total number of business risk usage", ["account"])
CVE_BRISK_USAGE_TF = Gauge("ve_usage_cve_business_risk_tf", "Total number of business risk usage excluded RH accounts", ["account"])
ACCOUNTS_WITH_SYSTEMS_COUNT_F = Gauge("ve_usage_accounts_with_systems_count_f", "Total number of accounts with systems excluded RH accounts", ["systems"])


def timer(report_name):
    """Count"""

    def _decorator_timer(func):
        @wraps(func)
        def _wrapper_timer(*args, **kwargs):
            start = time.time()

            LOGGER.debug("Generating %s report...", report_name)
            try:
                return func(*args, **kwargs)
            finally:
                end = (time.time() - start) * 1000

                LOGGER.debug("-----------------------------------")
                LOGGER.info("%s query took %s milliseconds", report_name, str(end))

        return _wrapper_timer

    return _decorator_timer


class StatsManager:
    """Class behaves as middle layer between db statistics table and code."""

    def __init__(self, conn):
        self.db_conn = conn

    def save_data(self, tuples):
        """Saves tuples into db"""
        with self.db_conn.cursor() as cur:
            execute_values(cur, """
                INSERT INTO usage_statistics
                (name, recorded, cve_status_usage, system_cve_status_usage,
                cve_business_risk_usage) VALUES %s
            """, tuples, page_size=len(tuples))

    def load_data(self, timestamp):
        """Loads tuples with statistics from db by timestamps"""
        with self.db_conn.cursor() as cur:
            cur.execute("""
                SELECT name, cve_status_usage, system_cve_status_usage,
                       cve_business_risk_usage
                FROM usage_statistics
                WHERE recorded = %s
            """, (timestamp,))
            return cur.fetchall()

    def remove_data(self, timestamp):
        """Removes statistics by timestamp"""
        with self.db_conn.cursor() as cur:
            cur.execute("""
                DELETE FROM usage_statistics WHERE recorded = %s
                """, (timestamp,))

    def remove_multiple(self, timestamps):
        """Removes statistics by timestamps"""
        with self.db_conn.cursor() as cur:
            cur.execute("""
                DELETE FROM usage_statistics WHERE recorded IN %s
            """, (timestamps,))

    def are_data(self, timestamp):
        """Checks if there are some data for given timestamp"""
        with self.db_conn.cursor() as cur:
            cur.execute("""
                SELECT id
                FROM usage_statistics
                WHERE recorded = %s
            """, (timestamp,))
            res = cur.fetchone()
            if res:
                return True
            return False

    def load_timestamps(self):
        """Loads all timestamps from db"""
        with self.db_conn.cursor() as cur:
            cur.execute("""
                SELECT DISTINCT(recorded) FROM usage_statistics
            """)
            res = cur.fetchall()
            res = map(lambda x: x[0], res)
            return res


class MetricsGatherer:
    """Metrics Gatherer"""

    def __init__(self, stats_manager, exclude_accounts_text=None):
        # self.debug = debug
        self.stats_manager: StatsManager = stats_manager
        self.exclude_accounts: set = self.process_exclude_accounts_text(exclude_accounts_text)
        LOGGER.debug("Exclude accounts: %s", sorted(self.exclude_accounts))
        self.today = datetime.date.today()

    @staticmethod
    def process_exclude_accounts_text(exclude_accounts_text) -> set:
        """Retrieve list of exclude accounts from env var"""
        exclude_accounts = set()
        if exclude_accounts_text:
            excludes_input = io.StringIO(exclude_accounts_text)
            lines = excludes_input.readlines()
            for line in lines:
                account = line.split('#')[0].strip()
                if account:
                    exclude_accounts.add(account)
        return exclude_accounts

    @staticmethod
    @timer('CVE-status')
    def query_cve_status_usage(connection):
        """Query for cve status usage."""
        cve_status_usage = []
        LOGGER.debug("  account    # CVE-status set")
        LOGGER.debug("------------ ----------------------")
        with NamedCursor(connection) as cur:
            cur.execute("""SELECT ra.name,
                                  count(ra.name)
                             FROM cve_account_data cad
                             JOIN rh_account ra
                               ON cad.rh_account_id = ra.id
                            WHERE cad.status_id != 0
                         GROUP BY ra.name
                         ORDER BY count(ra.name) DESC""")
            for row in cur.fetchall():
                cve_status_usage.append(row)
                LOGGER.debug("%12s %s", row[0], row[1])
        return cve_status_usage

    @staticmethod
    @timer('system-CVE-status')
    def query_system_cve_status_usage(connection):
        """Query for system cve status usage."""
        system_cve_status_usage = []
        LOGGER.debug("  account    # system-CVE-status set")
        LOGGER.debug("------------ ----------------------")
        with NamedCursor(connection) as cur:
            cur.execute("""SELECT ra.name,
                                  count(ra.name)
                             FROM system_vulnerabilities sv
                             JOIN system_platform sp
                               ON sv.system_id = sp.id
                             JOIN rh_account ra
                               ON sp.rh_account_id = ra.id
                            WHERE sv.status_id != 0
                              AND sp.opt_out = false
                              AND sp.stale = false
                              AND sp.when_deleted IS NULL
                              AND sv.rh_account_id = sp.rh_account_id
                         GROUP BY ra.name
                         ORDER BY count(ra.name) DESC""")
            for row in cur.fetchall():
                system_cve_status_usage.append(row)
                LOGGER.debug("%12s %s", row[0], row[1])
        return system_cve_status_usage

    @staticmethod
    @timer('CVE-business risk')
    def query_cve_business_risk_usage(connection):
        """Query for cve business risk usage."""
        cve_business_risk_usage = []
        LOGGER.debug("  account    # CVE-business risk set")
        LOGGER.debug("------------ ----------------------")
        with NamedCursor(connection) as cur:
            cur.execute("""SELECT ra.name,
                                  count(ra.name)
                             FROM cve_account_data cad
                             JOIN rh_account ra
                               ON cad.rh_account_id = ra.id
                            WHERE cad.business_risk_id != 0
                         GROUP BY ra.name
                         ORDER BY count(ra.name) DESC""")
            for row in cur.fetchall():
                cve_business_risk_usage.append(row)
                LOGGER.debug("%12s %s", row[0], row[1])
        return cve_business_risk_usage

    @timer('count-non-rh-acc-with-systems')
    def query_count_account_with_systems(self, connection) -> list:
        """Query for count number of non rh accounts with number of systems in a predefined range"""
        sys_acc_count = []
        LOGGER.debug("   systems   # accounts ")
        LOGGER.debug("------------ ----------------------")
        for i, num in enumerate(SYSTEM_NUMS):
            with NamedCursor(connection) as cur:
                try:
                    upper_bound = SYSTEM_NUMS[i + 1] - 1
                    cur.execute("""SELECT count(*)
                               FROM (
                                   SELECT count(sp.rh_account_id)
                                   FROM system_platform sp
                                   JOIN rh_account ra ON sp.rh_account_id = ra.id
                                   GROUP BY sp.rh_account_id, ra.name
                                   HAVING count(sp.id) BETWEEN %s AND %s AND ra.name NOT IN (%s)
                               ) a""", (num, upper_bound, list(self.exclude_accounts)))
                except IndexError:
                    cur.execute("""SELECT count(*)
                               FROM (
                                   SELECT count(sp.rh_account_id)
                                   FROM system_platform sp
                                   JOIN rh_account ra ON sp.rh_account_id = ra.id
                                   GROUP BY sp.rh_account_id, ra.name
                                   HAVING count(sp.id) >= %s AND ra.name NOT IN (%s)
                               ) a""", (num, list(self.exclude_accounts)))
                count = cur.fetchone()[0]
                sys_acc_count.append((num, count))
                LOGGER.debug('%12s %s', num, count)
        return sys_acc_count

    @staticmethod
    def metrics_tuple_list_to_map(tuple_list) -> dict:
        """Given a tuple list, return the metrics values in map keyed on account."""
        to_map = {}
        for (key, value) in tuple_list:
            to_map[key] = value
        return to_map

    @staticmethod
    def create_db_map(cve_s_map, system_cve_map, cve_br_map, timestamp):
        """Creates dict of new records to db, with tuples"""
        with DatabasePoolConnection() as conn:
            with conn.cursor() as cur:
                cur.execute("""
                        SELECT name FROM rh_account
                    """)
                names = cur.fetchall()

        result = {}
        for name in names:
            name_ = name[0]
            result[name_] = (name_,
                             timestamp,
                             cve_s_map.get(name_, 0),
                             system_cve_map.get(name_, 0),
                             cve_br_map.get(name_, 0))
        return result

    def prep_filtered_results(self, tuple_list) -> tuple:
        """Apply exclude_accounts filter and return top MAX_RESULTS_COUNT."""
        unfiltered_list = []
        filtered_list = []
        for (account, metric) in tuple_list:
            if len(unfiltered_list) < MAX_RESULTS_COUNT:
                unfiltered_list.append((account, metric))
            if account not in self.exclude_accounts:
                filtered_list.append((account, metric))
                if len(filtered_list) == MAX_RESULTS_COUNT:
                    break
        return unfiltered_list, filtered_list

    def collect_usage_metrics(self, data, p_metric, p_metric_f):
        """Filter and collect metrics"""
        unfiltered, filtered = self.prep_filtered_results(data)
        for (account, metric) in unfiltered:
            p_metric.labels(account=account).set(int(metric))
        for (account, metric) in filtered:
            p_metric_f.labels(account=account).set(int(metric))

    def run(self):
        """Run the metrics gathering."""
        LOGGER.info("Started usage_metrics job")
        with DatabasePoolConnection() as conn:
            cve_status_usage = self.query_cve_status_usage(conn)
            system_cve_status_usage = self.query_system_cve_status_usage(conn)
            cve_business_risk_usage = self.query_cve_business_risk_usage(conn)
            sys_acc_count = self.query_count_account_with_systems(conn)
            conn.commit()

        LOGGER.info("Start metrics collecting")
        for (sys_num, acc_count) in sys_acc_count:
            ACCOUNTS_WITH_SYSTEMS_COUNT_F.labels(systems=str(sys_num)).set(int(acc_count))

        self.collect_usage_metrics(cve_status_usage, CVE_STATUS_USAGE_T, CVE_STATUS_USAGE_TF)
        self.collect_usage_metrics(system_cve_status_usage, SYSTEM_CVE_STATUS_USAGE_T, SYSTEM_CVE_STATUS_USAGE_TF)
        self.collect_usage_metrics(cve_business_risk_usage, CVE_BRISK_USAGE_T, CVE_BRISK_USAGE_TF)
        LOGGER.info("Finished metrics collecting")

        LOGGER.info("Saving data to database")
        cve_status_map = self.metrics_tuple_list_to_map(cve_status_usage)
        system_cve_status_map = self.metrics_tuple_list_to_map(system_cve_status_usage)
        cve_business_risk_map = self.metrics_tuple_list_to_map(cve_business_risk_usage)
        current_db_map = self.create_db_map(cve_status_map,
                                            system_cve_status_map,
                                            cve_business_risk_map,
                                            self.today)

        if self.stats_manager.are_data(self.today):
            # replace existing day's data with that just gathered
            # in case something went wrong the first time around.
            LOGGER.info("Replacing %s data", self.today)
            self.stats_manager.remove_data(self.today)
        self.stats_manager.save_data(current_db_map.values())
        LOGGER.info("Data saved successfully")

        timestamps_to_delete = []
        for timestamp in self.stats_manager.load_timestamps():
            if timestamp.day != 1:
                timestamps_to_delete.append(timestamp)
        if timestamps_to_delete:
            LOGGER.debug("Clearing unnecessary data from db")
            self.stats_manager.remove_multiple(tuple(timestamps_to_delete))

        LOGGER.info("Finished usage_metrics job")


def run():
    """Application entrypoint"""
    with DatabasePool(2):
        with DatabasePoolConnection() as conn:
            stats_mng = StatsManager(conn)
            mgather = MetricsGatherer(stats_mng,
                                      exclude_accounts_text=ACCOUNTS_BLACKLIST)
            mgather.run()
            conn.commit()


if __name__ == "__main__":
    init_logging()
    run()
