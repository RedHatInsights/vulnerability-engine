"""
Various utility functions.
"""
import asyncio
import json
from datetime import datetime, timedelta, timezone
from time import sleep

import asyncpg
import requests
from dateutil.parser import isoparse
from prometheus_client import Counter
from psycopg2.extras import Json

from common.config import Config
from common.constants import remediation
from common.database_handler import DatabasePool, DatabasePoolConnection
from common.logging import get_logger

CFG = Config()
LOGGER = get_logger(__name__)

# prometheus probes
# counts
VMAAS_RETURN_ERR = Counter('ve_evaluator_vmaas_return_errors', 'Number of non-200 RCs from VMaaS')
VMAAS_CNX_ERR = Counter('ve_evaluator_vmaas_cnx_errors', 'Number of connection-errors from VMaaS')
FUTURE_ERR = Counter('ve_future_errors', 'Number of Future errors')


def external_service_request(endpoint, data_json=None, session=None, method='POST', headers=None, service_access=None, timeout=5, **kwargs):
    """Sends request to external service"""
    # pylint: disable=too-many-branches, disable=too-many-nested-blocks
    default_headers = {'Content-type': 'application/json',
                       'Accept': 'application/json'}
    if headers and isinstance(headers, dict):
        default_headers.update(headers)

    tries = 0
    while True:
        if tries >= CFG.request_retries:
            break
        try:
            if session:
                response = session.request(method=method, url=endpoint, headers=default_headers, json=data_json, timeout=timeout, **kwargs)
            else:
                response = requests.request(method=method, url=endpoint, headers=default_headers, json=data_json, timeout=timeout, **kwargs)
            if response.status_code == 200:
                if service_access is not None:
                    service_access.status = True
                return response.json()
            if response.status_code >= 500:
                if service_access is not None:
                    service_access.status = False
                    LOGGER.info("External service - %s temporarily unavailable.", endpoint)
                    break
                LOGGER.info("External service - %s temporarily unavailable, retrying...", endpoint)
                sleep(1)
            else:
                tries += 1
                VMAAS_RETURN_ERR.inc()
                LOGGER.error("Error during %s request to endpoint %s: HTTP %s, %s",
                             method, endpoint, response.status_code, response.text)
                LOGGER.debug("JSON: %s", str(data_json))
                # Do not retry for 4xx HTTP codes
                if 400 <= response.status_code < 500:
                    if service_access is not None:
                        if response.status_code == 404:
                            service_access.status = True
                        else:
                            service_access.status = False
                    break
        except requests.exceptions.Timeout:
            VMAAS_CNX_ERR.inc()
            LOGGER.exception("Timeout error calling external service: %s: ", endpoint)
            break
        except requests.exceptions.RequestException:
            tries += 1
            VMAAS_CNX_ERR.inc()
            LOGGER.exception("Error calling external service %s: ", endpoint)
    return None


def on_thread_done(future):
    """Callback to call after ThreadPoolExecutor worker finishes."""
    try:
        future.result()
    except Exception:  # pylint: disable=broad-except
        FUTURE_ERR.inc()
        LOGGER.exception("Future %s hit exception: ", future)


def str_or_none(value):
    """Return string or None i value not exist"""
    return str(value) if value else None


def format_datetime(datetime_obj):
    """Convert datetime format to string ISO format"""
    if isinstance(datetime_obj, datetime):
        return datetime_obj.isoformat()
    return str(datetime_obj) if datetime_obj else None


def send_msg_to_payload_tracker(producer, msg_dict, status, status_msg=None, loop=None, service="vulnerability-vmaas"):
    """prepare and send message to payload-tracker"""
    request_id = msg_dict['platform_metadata'].get('request_id')
    if not request_id:
        return
    tracking_payload = {
        'service': service,
        'account': msg_dict['host']['account'],
        'org_id': msg_dict['host']['org_id'],
        'request_id': request_id,
        'inventory_id': msg_dict["host"]["id"],
        'status': status,
        'date': str(datetime.utcnow())}
    if status_msg:
        tracking_payload['status_msg'] = status_msg
    producer.send(tracking_payload, loop=loop)
    LOGGER.debug('Sent message to topic %s: %s', producer.topic, str(tracking_payload))


def send_remediations_update(producer, inventory_id: str, cves: list, loop=None) -> None:
    """
    Send a message in format of remediations application updates using given Kafka producer

    Args:
        producer (MQWriter): Kafka producer
        inventory_id (str): Inventory ID
        cves (list): List of CVE identifiers
        loop (asyncio.event_loop, optional): asyncio event loop to be used by producer
    """
    msg = {
        'host_id': inventory_id,
        'issues': ['vulnerabilities:{}'.format(cve) for cve in cves]
    }
    producer.send(msg, loop=loop)


def send_slack_notification(message: str) -> None:
    """If SLACK_WEBHOOK is set, sends notification to Slack"""
    if CFG.slack_webhook:
        requests.post(CFG.slack_webhook, json={'text': '[{}] {}'.format(CFG.vulnerability_env, message)}, headers={'Content-type': 'application/json'})


def ensure_minimal_schema_version():
    """Ensure that database schema is up-to-date, wait if it's not."""
    with DatabasePool(1):
        with DatabasePoolConnection() as conn:
            with conn.cursor() as cur:
                while True:
                    cur.execute("SELECT version FROM db_version WHERE name = 'schema_version'")
                    current_schema = int(cur.fetchone()[0])
                    if current_schema >= CFG.minimal_schema:
                        LOGGER.info("Current schema version: %s, minimal required: %s, OK", current_schema, CFG.minimal_schema)
                        return
                    LOGGER.warning("Current schema version: %s, minimal required: %s, waiting...", current_schema, CFG.minimal_schema)
                    sleep(10)


async def a_ensure_minimal_schema_version():
    """Ensure that database schema is up-to-date, in async."""
    with DatabasePool(1):
        with DatabasePoolConnection() as conn:
            with conn.cursor() as cur:
                while True:
                    cur.execute("SELECT version FROM db_version WHERE name = 'schema_version'")
                    current_schema = int(cur.fetchone()[0])
                    if current_schema >= CFG.minimal_schema:
                        LOGGER.info("Current schema version: %s, minimal required: %s, OK", current_schema, CFG.minimal_schema)
                        return
                    LOGGER.warning("Current schema version: %s, minimal required: %s, waiting...", current_schema, CFG.minimal_schema)
                    await asyncio.sleep(10)


def validate_kafka_msg(msg_dict, required_fields, default_type="unknown"):
    """Check if all required fields are in msg_dict of kafka message.

       All fields are type of dict, where each key is represented by string,
       or tuple. In tuple the first value is key string and second is
       boolean value if key is nullable.
    """
    for key, required_inner_keys in required_fields.items():
        if key not in msg_dict:
            if 'input' in msg_dict:
                msg_dict = msg_dict['input']
            LOGGER.warning("Missing key '%s' in msg_dict, skipping %s., reporter: %s", key, msg_dict.get(
                "type", default_type), msg_dict.get('host', {}).get('reporter', 'unknown'))
            return False
        inner_msg_dict = msg_dict[key]
        for inner_key in required_inner_keys:
            if isinstance(inner_key, dict):
                if not validate_kafka_msg(inner_msg_dict, inner_key, default_type=msg_dict.get("type", default_type)):
                    return False
            else:
                key = None
                is_nullable = True
                if isinstance(inner_key, tuple) and inner_key:
                    try:
                        key, is_nullable = inner_key
                    except ValueError:
                        key = inner_key[0]
                else:
                    key = inner_key
                if inner_msg_dict is None or key not in inner_msg_dict or (inner_msg_dict[key] is None and not is_nullable):
                    if 'input' in msg_dict:
                        msg_dict = msg_dict['input']
                    LOGGER.warning("Missing key '%s.%s' in msg_dict, skipping %s., reporter: %s", key, inner_key,
                                   msg_dict.get("type", default_type), msg_dict.get('host', {}).get('reporter', 'unknown'))
                    return False
    return True


def construct_cve_row(cve, impact_id_map, asyncpg_type=False):
    """Helper function to construct CVE row to be insterted/updated in the DB"""
    description = cve['description']
    impact_id = impact_id_map[cve['impact']]
    public_date = (isoparse(cve['public_date']) if asyncpg_type else cve['public_date']) or None
    modified_date = (isoparse(cve['modified_date']) if asyncpg_type else cve['modified_date']) or None
    cvss3_score = float(cve['cvss3_score']) if cve.get('cvss3_score') else None
    cvss3_metrics = cve.get('cvss3_metrics')
    cvss2_score = float(cve['cvss2_score']) if cve.get('cvss2_score') else None
    cvss2_metrics = cve.get('cvss2_metrics')
    redhat_url = cve.get('redhat_url', None)
    secondary_url = cve.get('secondary_url', None)
    advisories_list = json.dumps(cve.get('errata_list', None)) if asyncpg_type else Json(cve.get('errata_list', None))
    return (cve['synopsis'], description, impact_id, public_date, modified_date, cvss3_score, cvss3_metrics,
            cvss2_score, cvss2_metrics, redhat_url, secondary_url, advisories_list)


def _is_system_msg_recent(inventory_id: str, timestamp: str):
    try:
        msg_ts = isoparse(timestamp)
        if (datetime.now(timezone.utc) - msg_ts) <= timedelta(seconds=CFG.listeners_valid_system_sec):
            return True
    except ValueError:
        LOGGER.info("Cannot evaluate datetime: %s for system: %s", timestamp, inventory_id)
        return True
    return False


def validate_system_inventory(inventory_id: str, timestamp: str) -> bool:
    """Check if system is still valid in inventory, since messsages are coming also from insights-engine.
       Validity is only checked for systems which message is older then CFG.listeners_valid_system_sec seconds."""
    if _is_system_msg_recent(inventory_id, timestamp):
        return True

    with DatabasePoolConnection() as conn:
        with conn.cursor() as cur:
            cur.execute("""SELECT true FROM inventory.hosts AS ih
                           WHERE ih.id = %s LIMIT 1""", (inventory_id,))
            res = bool(cur.fetchone())
            return res


async def a_validate_system_inventory(inventory_id: str, timestamp: str, async_db_pool: asyncpg.pool.Pool) -> bool:
    """Check if system is still valid in inventory, since messsages are coming also from insights-engine.
       Validity is only checked for systems which message is older then CFG.listeners_valid_system_sec seconds."""
    if _is_system_msg_recent(inventory_id, timestamp):
        return True

    async with async_db_pool.acquire() as conn:
        res = await conn.fetchrow("""SELECT true FROM inventory.hosts AS ih
                                     WHERE ih.id = $1 LIMIT 1""", inventory_id)
        return bool(res)


def validate_cve_cache_keepalive(last_timestamp, threshold):
    """Check if keepalive timestamp for account is valid. This is for limiting number of updates/cache generations."""
    return last_timestamp and (datetime.now(timezone.utc) - last_timestamp) <= timedelta(hours=threshold)


def get_available_remediation_type(advisory_available: bool, when_mitigated, mitigation_reason: str, playbook_count) -> int:
    """Get the best available remediation type considering both VMaaS and rule CVEs."""
    available_remediation = remediation.NONE.value
    if not when_mitigated:  # CVE is active and reported from VMaaS
        if advisory_available:
            available_remediation = max(remediation.PLAYBOOK.value, available_remediation)
        else:
            available_remediation = max(remediation.MANUAL.value, available_remediation)
    if not mitigation_reason:  # CVE is active and reported from rules
        if playbook_count:
            available_remediation = max(remediation.PLAYBOOK.value, available_remediation)
        else:
            available_remediation = max(remediation.MANUAL.value, available_remediation)
    return available_remediation


def release_semaphore(semaphore: asyncio.BoundedSemaphore):
    """Releases given semaphore wrapped function was run"""
    def decorator(func):
        async def wrapper(*args, **kwargs):
            try:
                result = await func(*args, **kwargs)
            except Exception as exc:
                semaphore.release()
                raise exc
            semaphore.release()
            return result
        return wrapper
    return decorator


def send_notifications(notif_topic, new_sys_vulns, mit_sys_vulns, unmit_sys_vulns, rh_account_id, acc_num, org_id):
    """Sends kafka message to notificator with system_vulnerabilities"""
    if not new_sys_vulns and not mit_sys_vulns and not unmit_sys_vulns:
        return
    if not acc_num:
        LOGGER.info("Attempt to send notification to unknown account number: %s", rh_account_id)
        return

    msg = {
        "rh_account_id": rh_account_id,
        "account_number": acc_num,
        "org_id": org_id,
        "new_system_vulnerabilities_ids": [{"sys_vuln_id": sys_vuln_id, "cve_id": cve_id} for sys_vuln_id, cve_id in new_sys_vulns],
        "mitigated_system_vulnerabilities_ids": [{"sys_vuln_id": sys_vuln_id, "cve_id": cve_id} for sys_vuln_id, cve_id in mit_sys_vulns],
        "unmitigated_system_vulnerabilities_ids": [{"sys_vuln_id": sys_vuln_id, "cve_id": cve_id} for sys_vuln_id, cve_id in unmit_sys_vulns]
    }
    LOGGER.debug("Sending evaluation result to notificator: %s", msg)
    notif_topic.send(msg)
