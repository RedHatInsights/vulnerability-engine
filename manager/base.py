"""
Common and utility functions/classes for vulnerability-manager
"""
import csv
import json
import re
import uuid
from dataclasses import dataclass
from datetime import datetime
from datetime import timezone
from enum import Enum
from io import StringIO
from math import floor
from time import sleep
from typing import Callable
from typing import Dict
from typing import List
from typing import Optional
from typing import Tuple
from urllib.parse import unquote

from connexion import context
from connexion.lifecycle import ConnexionResponse
from peewee import JOIN
from peewee import SQL
from peewee import Case
from peewee import DataError
from peewee import Expression
from peewee import PeeweeException
from peewee import fn
from prometheus_client import Counter
from prometheus_client import Histogram

from common.config import Config
from common.constants import remediation
from common.identity import get_identity
from common.logging import get_logger
from common.peewee_conditions import system_is_active
from common.peewee_model import DB
from common.peewee_model import DB_READ_REPLICA
from common.peewee_model import CveMetadata
from common.peewee_model import CveRuleMapping
from common.peewee_model import InsightsRule
from common.peewee_model import InventoryHosts
from common.peewee_model import RHAccount
from common.peewee_model import Status
from common.peewee_model import SystemPlatform
from common.peewee_model import SystemVulnerabilities
from common.strtobool import strtobool
from common.utils import EXCEPTION_COUNT
from common.utils import format_datetime
from common.utils import show_cves_without_errata
from common.utils import validate_cve_cache_keepalive

from .filters import apply_filters
from .rbac_manager import RbacManager

LOGGER = get_logger(__name__)
CFG = Config()

IDENTITY_HEADER = "x-rh-identity"
DEFAULT_PAGE_SIZE = 20
DEFAULT_BUSINESS_RISK = "Not Defined"
CVE_SYNOPSIS_SORT = [fn.SUBSTRING(SQL("cve_name"), r"-(\d+)-").cast("integer"),
                     fn.SUBSTRING(SQL("cve_name"), r"-(\d+)$").cast("integer")]

UI_REFERER = re.compile("(.*).redhat.com")
API_SOURCE = "API"
UI_SOURCE = "UI"

DEFAULT_REMEDIATION_FILTER = [remediation.PLAYBOOK.value, remediation.MANUAL.value]

LOGGER.info("Access URL: %s", CFG.default_route)

# Prometheus support
# Counter for all-the-get-calls, dealt with in BaseHandler
REQUEST_COUNTS = Counter("ve_manager_invocations", "Number of calls per handler", ["method", "endpoint"])
ACCOUNT_REQUESTS = Counter("ve_manager_account_invocations", "Number of calls per account", ["account", "source"])
ADMIN_REQUESTS = Counter("ve_manager_admin_invocations", "Number of calls on admin API")
REQUEST_DURATION = Histogram("ve_manager_durations", "Duration of requests", ["method", "endpoint"], buckets=[1, 1.5, 1.75, 2, 2.5, 3, 3.5, 4])

OS_INFO_QUERY = SQL("""
    CASE WHEN system_profile->'operating_system'->'name' IS NULL
        THEN 'N/A'
    WHEN system_profile->'operating_system'->'major' IS NULL
        THEN (system_profile->'operating_system'->>'name')
    WHEN system_profile->'operating_system'->'minor' IS NULL
        THEN (system_profile->'operating_system'->>'name') || ' ' || (system_profile->'operating_system'->>'major')
    ELSE
        (system_profile->'operating_system'->>'name') || ' ' || (system_profile->'operating_system'->>'major') ||
            '.' || (system_profile->'operating_system'->>'minor')
    END
""")

OS_INFO_SORT = [
    SQL("system_profile->'operating_system'->>'name'"),
    SQL("system_profile->'operating_system'->'major'"),
    SQL("system_profile->'operating_system'->'minor'")
]

STATUS_CACHE = {}
WAIT_INTERVAL_SEC = 2


class reporter(Enum):  # pylint: disable=invalid-name
    """Sources of reported CVE"""
    NONE = 0
    VMAAS = 1
    RULE = 2
    BOTH = 3


class InvalidArgumentException(Exception):
    """Illegal arguments for pagination/filtering/sorting"""


class ApplicationException(Exception):
    """General exception in the application"""

    def __init__(self, message, status_code):
        self.message = message
        self.status_code = status_code
        super().__init__()

    def format_exception(self):
        """Formats error message to desired format"""
        if isinstance(self.message, dict):
            return self.message, self.status_code
        return Request.format_exception(self.message, self.status_code)


class MissingEntitlementException(Exception):
    """entitlement is missing"""


class ReadOnlyModeException(Exception):
    """manager is running in read-only mode"""


@dataclass
class AccountData:
    """Represents data about a single customer account in DB"""
    id: int
    cves_without_errata: bool

    cve_cache_from: datetime
    cve_cache_keepalive: datetime
    cve_cache_groups: List[List[Dict[str, str]]]


def basic_auth(username, password, required_scopes=None):  # pylint: disable=unused-argument
    """
    Basic auth is done on 3scale level.
    """
    raise MissingEntitlementException


def auth_common(identity, x_rh_identity):  # pylint: disable=unused-argument
    """
    Check account number and entitlements
    """
    if "identity" not in identity:
        return None
    id_details = identity["identity"]

    if "account_number" not in id_details and "org_id" not in id_details:
        return None
    account_number = id_details.get("account_number")
    org_id = id_details.get("org_id")

    # Parse fields required for System cert auth
    identity_type = id_details.get("type")
    system_cn = id_details.get("system", {}).get("cn")
    if system_cn:
        try:
            system_cn = uuid.UUID(system_cn)
        except ValueError:
            LOGGER.warning("Invalid system UUID: %s", system_cn)
            return None

    if identity_type != "System":  # Call RBAC by default for non-system identity types (User, ServiceAccount)
        rbac_manager = RbacManager()
        rbac_perms, group_ids = rbac_manager.fetch_permissions(x_rh_identity)
    else:
        rbac_perms, group_ids = [], []

    return {"uid": {"account_number": account_number, "org_id": org_id, "identity_type": identity_type, "system_cn": system_cn,
                    "rbac_perms": rbac_perms, "group_ids": group_ids}}


def auth(x_rh_identity, required_scopes=None):  # pylint: disable=unused-argument
    """
    Parses account number from the x-rh-identity header
    """
    identity = get_identity(x_rh_identity)
    return auth_common(identity, x_rh_identity) if identity is not None else None


def auth_admin(x_rh_identity, required_scopes=None):  # pylint: disable=unused-argument
    """
    Parses user name from the x-rh-identity header
    """
    identity = get_identity(x_rh_identity)
    user = identity.get("identity", {}).get("associate", {}).get("email")
    LOGGER.info("User '%s' accessed admin API.", user)
    return {"uid": user} if user else None


def forbidden_missing_entitlement(request, exception):  # pylint: disable=unused-argument
    """Override default connexion 401 coming from auth() with 403"""
    return ConnexionResponse(
        body=json.dumps({"errors": [{"detail": "insights entitlement is missing", "status": "403"}]}),
        status_code=403,
        mimetype="application/vnd.api+json"
    )


def forbidden_rbac(request, exception):  # pylint: disable=unused-argument
    """Override default connexion 401 coming from auth() with 403"""
    return ConnexionResponse(
        body=json.dumps({"errors": [{"detail": exception.message, "status": "403"}]}),
        status_code=403,
        mimetype="application/vnd.api+json"
    )


class Request:
    """general class for processing requests"""

    _endpoint_name: str

    @staticmethod
    def _check_int_arg(kwargs, key, dflt, zero_allowed=False):
        val = kwargs.get(key, dflt)
        if val < 0 or (val == 0 and not zero_allowed):
            raise ApplicationException("Requested %s out of range: %s" % (key, val), 400)
        return val

    @staticmethod
    def _check_read_only_mode():
        if CFG.read_only_mode:
            raise ReadOnlyModeException("Service is running in read-only mode. Please try again later.")

    @staticmethod
    def _format_data(output_data_format, data_list, ids_only=False):
        if output_data_format == "csv":
            output = StringIO()
            if data_list:
                fields = None
                if ids_only:
                    # if endpoint returns ids only - id, type, attributes does not exist
                    fields = []
                    fields.extend(data_list[0].keys())
                else:
                    # create list of columns - type, id and all keys from attributes
                    fields = ["type", "id"]
                    fields.extend(data_list[0]["attributes"].keys())
                writer = csv.DictWriter(output, fields)
                writer.writeheader()
                for item in data_list:
                    # create flat dictionary (type, id + values from attributes) and write it
                    writer.writerow({field: item.get(field) or (not ids_only and item["attributes"].get(field)) for field in fields})
            return output.getvalue()
        return data_list

    @classmethod
    def _parse_list_arguments(cls, kwargs):
        # We may get limit/offset, or page/page_size, or both
        # limit/offset 'wins', if it's set
        # page/page_size defaults to 0/DEFAULT_PAGE_SIZE and limit/offset to DEFAULT_PAGE_SIZE if *neither* are set
        # regardless, make sure limit/offset and page/page_size a) both exist, and b) are consistent, before we leave
        offset_set = kwargs.get("offset", "") or kwargs.get("limit", "")
        page_set = kwargs.get("page", "") or kwargs.get("page_size", "")

        if offset_set:
            limit = cls._check_int_arg(kwargs, "limit", DEFAULT_PAGE_SIZE)
            offset = cls._check_int_arg(kwargs, "offset", 0, True)
            page = floor(offset / limit) + 1
            page_size = limit
        elif page_set:
            page = cls._check_int_arg(kwargs, "page", 1)
            page_size = cls._check_int_arg(kwargs, "page_size", DEFAULT_PAGE_SIZE)
            limit = page_size
            offset = (page - 1) * page_size
        else:
            page = 1
            offset = 0
            page_size = DEFAULT_PAGE_SIZE
            limit = DEFAULT_PAGE_SIZE

        data_format = kwargs.get("data_format", "json")
        if data_format not in ["json", "csv"]:
            raise InvalidArgumentException(f"Invalid data format: {kwargs.get('data_format', None)}")

        if limit > CFG.maximum_page_size and not UI_REFERER.search(context.request.headers.get("referer", "")):
            raise InvalidArgumentException(f"Page limit of size: {limit} is too high, maximum is {CFG.maximum_page_size}")

        return {
            "filter": remove_str_nulls(kwargs.get("filter", None)),
            "sort": remove_str_nulls(kwargs.get("sort", None)),
            "page": page,
            "page_size": page_size,
            "limit": limit,
            "offset": offset,
            "data_format": data_format
        }

    @staticmethod
    def format_exception(text, status_code):
        """Formats error message to desired format"""
        return {"errors": [{"status": str(status_code), "detail": text}]}, status_code

    @staticmethod
    def _sanitize_argument(arg):
        """Sanitizes arguments in list or string, from null chars"""
        retval = arg
        if isinstance(arg, list):
            retval = [Request._sanitize_argument(part) for part in arg]
        if isinstance(arg, str):
            retval = arg.replace("\x00", "")
        return retval

    @staticmethod
    def _parse_arguments(kwargs, argv):
        """
        Utility method for getting parameters from request which come as string
        and their conversion to a object we'd like to have.
        Expects array of {"arg_name" : some_str, "convert_func" : e.g. float, int}
        Returns dict of values if succeeds, throws exception in case of fail
        """
        retval = {}
        errors = []
        for arg in argv:
            retval[arg["arg_name"]] = kwargs.get(arg["arg_name"], None)
            if retval[arg["arg_name"]] is not None:
                retval[arg["arg_name"]] = Request._sanitize_argument(retval[arg["arg_name"]])
                try:
                    if arg["convert_func"] is not None:
                        retval[arg["arg_name"]] = arg["convert_func"](retval[arg["arg_name"]])
                except (ValueError, OverflowError):
                    errors.append({"status": "400",
                                   "detail": "Error in argument %s: '%s'" % (arg["arg_name"], retval[arg["arg_name"]])})
        if errors:
            raise ApplicationException({"errors": errors}, 400)
        return retval

    @classmethod
    def handle_errors(cls, fun, **kwargs):
        """ Execute provided function, while handling all common errors, and returning a formatted response """
        # pylint: disable=too-many-return-statements
        try:
            return fun(**kwargs)
        except ApplicationException as exc:
            return exc.format_exception()
        # TODO: Can this disclose any information ? Should we provide generic response message ?
        except DataError as exc:
            return cls.format_exception(str(exc).split(":")[0], 400)
        except InvalidArgumentException as exc:
            return cls.format_exception(str(exc), 400)
        except ReadOnlyModeException as exc:
            return cls.format_exception(str(exc), 503)
        except Exception:  # pylint: disable=broad-except
            EXCEPTION_COUNT.inc()
            LOGGER.exception("Unhandled exception: ")
            return cls.format_exception("Internal server error", 500)

    @classmethod
    def handle_request(cls, method: str, endpoint_name: str, handler_func: Callable, **kwargs):
        """Process a request and collect Prometheus metrics."""
        if isinstance(context.context.get("user"), dict):
            ACCOUNT_REQUESTS.labels(context.context["user"]["org_id"], UI_SOURCE if "referer" in context.request.headers and
                                    UI_REFERER.search(context.request.headers["referer"]) else API_SOURCE).inc()
        elif isinstance(context.context.get("user"), str):
            ADMIN_REQUESTS.inc()
        REQUEST_COUNTS.labels(method, endpoint_name).inc()
        with REQUEST_DURATION.labels(method, endpoint_name).time():
            return cls.handle_errors(handler_func, **kwargs)


class GetRequest(Request):
    """general class for processing GET requests"""

    _endpoint_name: str

    @classmethod
    def get(cls, **kwargs):
        """Answer GET request"""
        return cls.handle_request("get", cls._endpoint_name, cls.handle_get, **kwargs)

    @classmethod
    def handle_get(cls, **kwargs):  # pragma: no cover
        """To be implemented in child classes"""
        raise NotImplementedError


class ReadWriteRequest(Request):
    """ Base class for request implementations which require database to be opened in write mode"""

    _endpoint_name: str

    @classmethod
    def handle_errors(cls, fun, **kwargs):
        """ Handle common errors, and check whether read_only mode is enabled or disabled"""

        def readonly_fun(**kwargs):
            cls._check_read_only_mode()
            return fun(**kwargs)

        return super().handle_errors(readonly_fun, **kwargs)


class PatchRequest(ReadWriteRequest):
    """general class for processing PATCH requests"""

    _endpoint_name: str

    @classmethod
    def patch(cls, **kwargs):
        """Answer PATCH request"""
        return cls.handle_request("patch", cls._endpoint_name, cls.handle_patch, **kwargs)

    @classmethod
    def handle_patch(cls, **kwargs):  # pragma: no cover
        """To be implemented in child classes"""
        raise NotImplementedError


class PostRequest(ReadWriteRequest):
    """general class for processing POST requests"""

    _endpoint_name: str

    @classmethod
    def post(cls, **kwargs):
        """Answer POST request"""
        return cls.handle_request("post", cls._endpoint_name, cls.handle_post, **kwargs)

    @classmethod
    def handle_post(cls, **kwargs):  # pragma: no cover
        """To be implemented in child classes"""
        raise NotImplementedError


class PutRequest(ReadWriteRequest):
    """general class for processing PUT requests"""

    _endpoint_name: str

    @classmethod
    def put(cls, **kwargs):
        """Answer PUT request"""
        return cls.handle_request("put", cls._endpoint_name, cls.handle_put, **kwargs)

    @classmethod
    def handle_put(cls, **kwargs):  # pragma: no cover
        """To be implemented in child classes"""
        raise NotImplementedError


class DeleteRequest(ReadWriteRequest):
    """general class for processing DELETE requests"""

    _endpoint_name: str

    @classmethod
    def delete(cls, **kwargs):
        """Answer DELETE request"""
        return cls.handle_request("delete", cls._endpoint_name, cls.handle_delete, **kwargs)

    @classmethod
    def handle_delete(cls, **kwargs):  # pragma: no cover
        """To be implemented in child classes"""
        raise NotImplementedError


def parse_int_list(input_str):
    """Function to parse string with ints to list, e.g. "1,2,3" -> [1,2,3]"""
    return [int(part) for part in input_str.split(",")]


def parse_str_list(input_str):
    """
    Function to parse string with rules to list, e.g.
    "rule1|ERR_KEY,rule2|ERR_KEY2" -> [rule1|ERR_KEY, rule2|ERR_KEY2]
    """
    return input_str.split(",")


def bool_or_rules_list(arg: str):
    """Converts string to bool or parsed security rules list"""
    try:
        return bool(strtobool(arg))
    except ValueError:
        return parse_str_list(arg)


def remove_str_nulls(val):
    """Remove \\00 characters from string, DB driver does not like them in expressions"""
    if isinstance(val, str):
        return val.replace("\x00", "").strip()
    return val


def parse_str_or_list(str_list):
    """Parses a list of strings or single one, while removing invalid values"""
    retval = None
    if isinstance(str_list, str):
        retval = [remove_str_nulls(str_list)]
    if isinstance(str_list, list):
        retval = [s for s in [remove_str_nulls(item) for item in str_list] if s]
    if not retval or not any(retval):
        raise ValueError("Expected str or str list")
    return retval


def get_or_create_account():
    """In some cases rh_account might not have already been created by listener, create it for usage in manager"""
    rh_account = RHAccount.select(RHAccount.id).where(RHAccount.org_id == context.context["user"]["org_id"])
    if rh_account.count() == 0:
        rh_account = RHAccount.insert(account_number=context.context["user"]["account_number"],
                                      org_id=context.context["user"]["org_id"]).on_conflict(
            conflict_target=[RHAccount.account_number],
            update={RHAccount.account_number: context.context["user"]["account_number"],
                    RHAccount.org_id: context.context["user"]["org_id"]}).returning(RHAccount)
    return rh_account[0].id


def round_to_100_percent(number_set, digit_after_decimal=0):
    """
        This function take a list of number and return a list of percentage, which represents the portion of each number in sum of all numbers
        Moreover, those percentages are adding up to 100%!!!
    """
    divisor = float(sum(number_set))
    if not any(number_set):
        divisor = 100
    unround_numbers = [x / divisor * 100 * 10 ** digit_after_decimal for x in number_set]
    decimal_part_with_index = sorted([(index, unround_numbers[index] % 1) for index in range(len(unround_numbers))], key=lambda y: y[1], reverse=True)
    remainder = 100 * 10 ** digit_after_decimal - sum([int(x) for x in unround_numbers])
    index = 0
    while remainder > 0:
        unround_numbers[decimal_part_with_index[index][0]] += 1
        remainder -= 1
        index = (index + 1) % len(number_set)
    return [int(x) / float(10 ** digit_after_decimal) for x in unround_numbers]


def get_mapping(cves: List[int], subquery, rh_account_id):
    """Return select query from CveRuleMapping"""
    # pylint: disable=singleton-comparison
    selectables = [
        CveMetadata.cve,
        CveRuleMapping.cve_id,
        InsightsRule.name,
        InsightsRule.description_text,
        InsightsRule.summary_text,
        InsightsRule.reboot_required,
        InsightsRule.playbook_count,
        InsightsRule.change_risk,
        InsightsRule.kbase_node_id,
        InsightsRule.active,
        InsightsRule.rule_impact,
        InsightsRule.publish_date,
    ]

    if rh_account_id is None:
        return (CveRuleMapping.select(*selectables)
                              .join(InsightsRule, on=(CveRuleMapping.rule_id == InsightsRule.id))
                              .join(CveMetadata, on=(CveRuleMapping.cve_id == CveMetadata.id))
                              .where((InsightsRule.active == True) & (InsightsRule.rule_only == False))  # noqa: E712
                              .where(CveRuleMapping.rule_id.in_(CveRuleMapping.select(CveRuleMapping.rule_id).where(CveRuleMapping.cve_id.in_(cves))))
                              .dicts())

    return (CveRuleMapping.select(*selectables, fn.COUNT(subquery.c.id).alias("systems_affected"))
                          .join(InsightsRule, on=(CveRuleMapping.rule_id == InsightsRule.id))
                          .join(CveMetadata, on=(CveRuleMapping.cve_id == CveMetadata.id))
                          .join(subquery, JOIN.LEFT_OUTER,
                                on=((subquery.c.rule_id == InsightsRule.id) & (subquery.c.cve_id == CveRuleMapping.cve_id)))
                          .where((InsightsRule.active == True) & (InsightsRule.rule_only == False))  # noqa: E712
                          .where(CveRuleMapping.rule_id.in_(CveRuleMapping.select(CveRuleMapping.rule_id).where(CveRuleMapping.cve_id.in_(cves))))
                          .group_by(*selectables)
                          .dicts())


def get_subquery(cves: List[int], rh_account_id):
    """Return subquery, None if `rh_account_id` is None"""
    # pylint: disable=singleton-comparison
    if rh_account_id is None:
        return None

    subquery = (SystemVulnerabilities.select(SystemVulnerabilities.id, SystemVulnerabilities.rule_id, SystemVulnerabilities.cve_id)
                                     .join(SystemPlatform, on=((SystemVulnerabilities.system_id == SystemPlatform.id) &
                                                               system_is_active(rh_account_id=rh_account_id, edge=None)))
                                     .where(SystemVulnerabilities.cve_id.in_(cves))
                                     .where(SystemVulnerabilities.mitigation_reason.is_null(True))
                                     .where((SystemVulnerabilities.rh_account_id == rh_account_id)))
    return cyndi_join(subquery)


def get_rules_for_cves(cves: list, rh_account=None) -> dict:
    """Return associated rules for a CVE"""
    # pylint: disable=singleton-comparison, unsubscriptable-object
    rules_map = {}
    rule_cve_mapping = {}
    rh_account_id = None

    if rh_account is not None:
        try:
            rh_account_id = RHAccount.select(RHAccount.id).where(RHAccount.org_id == rh_account["org_id"])[0]
        except IndexError:
            pass

    subquery = get_subquery(cves, rh_account_id)
    mapping = get_mapping(cves, subquery, rh_account_id)

    for row in mapping:
        rule_cve_mapping.setdefault(row["name"], []).append(row["cve"])
    for row in mapping:
        rule_detail = {
            "rule_id": row["name"],
            "description": row["description_text"],
            "summary": row["summary_text"],
            "reboot_required": row["reboot_required"],
            "playbook_count": row["playbook_count"],
            "change_risk": row["change_risk"],
            "kbase_node_id": row["kbase_node_id"],
            "associated_cves": rule_cve_mapping[row["name"]],
            "rule_impact": row["rule_impact"],
            "publish_date": format_datetime(row["publish_date"])
        }
        if rh_account_id is not None:
            rule_detail["systems_affected"] = row["systems_affected"]
        rules_map.setdefault(row["cve_id"], []).append(rule_detail)
    return rules_map


def get_system_count(rh_account, include_cyndi=True, filters=None, filters_args=None):
    """Get count of nonstale, nonoptouted, evaluated user systems"""
    # pylint: disable=singleton-comparison
    query = SystemPlatform.select(fn.COUNT(SystemPlatform.id).alias("count"))\
        .where((SystemPlatform.rh_account_id == rh_account)
               & ((SystemPlatform.last_evaluation.is_null(False)) | (SystemPlatform.advisor_evaluated.is_null(False)))
               & system_is_active(rh_account_id=rh_account, edge=None))

    if include_cyndi:
        query = cyndi_join(query)

    if filters:
        query = apply_filters(query, filters_args, filters, {})

    return query.first().count


def get_system_count_by_type(rh_account_id) -> Dict[str, int]:
    """Get count of nonstale, nonoptouted, evaluated user systems, by their type"""
    selectables = [
        fn.COALESCE(fn.SUM(Case(None, ((SystemPlatform.host_type == "edge", 1),), 0)), 0).alias("edge"),
        fn.COALESCE(fn.SUM(Case(None, ((SystemPlatform.host_type.is_null(True), 1),), 0)), 0).alias("rpmdnf"),
    ]

    query = (SystemPlatform.select(*selectables)
                           .where((SystemPlatform.rh_account_id == rh_account_id) &
                                  ((SystemPlatform.last_evaluation.is_null(False)) | (SystemPlatform.advisor_evaluated.is_null(False))) &
                                  system_is_active(rh_account_id=rh_account_id, edge=None))
                           .dicts())
    query = cyndi_join(query)
    return query.first()


def get_account_data(account) -> AccountData:
    """Translates account name to RH account data"""
    result = RHAccount.select(
        RHAccount.id, RHAccount.cves_without_errata, RHAccount.cve_cache_from, RHAccount.cve_cache_keepalive,
        RHAccount.cve_cache_groups) \
        .where(RHAccount.org_id == account["org_id"]) \
        .tuples() \
        .first()
    if result:
        result = list(result)
        result[1] = show_cves_without_errata(result[1])
        return AccountData(result[0], result[1], result[2], result[3], result[4])
    return AccountData(None, None, None, None, None)


def _eq_sorted_groups(groupsA: List[List[Dict[str, str]]], groupsB: List[List[Dict[str, str]]]) -> bool:
    """Compares two lists of sorted groups and returns if they are equal"""
    if type(groupsA) is not type(groupsB):
        return False
    if len(groupsA) != len(groupsB):
        return False

    for (groupA, groupB) in zip(groupsA, groupsB):
        if groupA != groupB:
            return False
    return True


def is_valid_cache(account_data: AccountData, group_ids: List[List[Dict[str, str]]]) -> bool:
    """Validates if the CVE cache is valid according to timestamps and cached inventory groups
       and invalidates cache if the inventory groups changed"""
    to_update = {}
    correct_groups = True
    if not validate_cve_cache_keepalive(account_data.cve_cache_keepalive, 1):
        # update keepalive
        to_update["cve_cache_keepalive"] = datetime.now(timezone.utc)
    if not _eq_sorted_groups(account_data.cve_cache_groups, group_ids):
        # cached inventory groups are not valid for the current user
        to_update["cve_cache_groups"] = []  # WORKAROUND: cache only full access to all system groups
        correct_groups = False
    if to_update:
        RHAccount.update(**to_update).where(RHAccount.id == account_data.id).execute()
    return correct_groups and account_data.cve_cache_from is not None


def unique_bool_list(bool_list):
    """Makes from repeating multiple values only unique bool values"""
    return list(set(bool_list))


def parse_tags(tags_list):
    """
    Parses tags and initializes them.
    Tags are in form of <namespace>/<key>=<value> or <namespace>/<key> where value is null.
    Tags can contain characters like "/" or "=" but they need to be escaped by URL encoding,
    where here are decoded. The tag validation is done by regex in spec and connexion.
    Result is list of dictionaried tags.
    """
    tags = []
    for tag_raw in tags_list:
        tag = {}
        tag["namespace"], key_value = tag_raw.split("/")
        try:
            tag["key"], tag["value"] = key_value.split("=")
        except ValueError:
            tag["key"] = key_value
            tag["value"] = None

        for key, value in tag.items():
            tag[key] = unquote(value) if value is not None else value

        tags.append(tag)
    return tags


def inventory_groups_condition(group_ids) -> Tuple[str, bool]:
    """Prepares SQL condition (array of possible values) for filtering by inventory group IDs"""
    res = []
    include_ungrouped = False
    for elem in group_ids:
        if elem == []:
            include_ungrouped = True
        else:
            res.append(json.dumps(json.dumps(elem)))
    return "{" + ",".join(res) + "}", include_ungrouped


def transform_names(names: [str]) -> str:
    """Transforms comma-separated names to format suitable for SQL clause."""
    res, _ = inventory_groups_condition([[{"name": name}] for name in names])
    return res


def transform_ids(ids: [str]) -> str:
    """Transforms comma-separated ids to format suitable for SQL clause."""
    res, _ = inventory_groups_condition([[{"id": id}] for id in ids])
    return res


def cyndi_join(query):
    """Function adds join on cyndi table, based if cyndi is enabled."""
    query = query.join(
        InventoryHosts, JOIN.INNER, on=(SystemPlatform.inventory_id == InventoryHosts.id)
    )
    if context.context["user"]["group_ids"]:
        inventory_groups, include_ungrouped = inventory_groups_condition(context.context["user"]["group_ids"])
        expr = Expression(InventoryHosts.groups, "@>", fn.ANY(SQL(f"'{inventory_groups}'::jsonb[]")))
        if include_ungrouped:
            expr |= (InventoryHosts.groups == SQL("\'[]\'"))
        query = query.where(expr)
    return query


def is_not_cacheable_request(args):
    """Checks if request needs cyndi join"""
    return any(
        key in args and args[key] is not None
        for key in [
            "tags",
            "sap_system",
            "sap_sids",
            "rhel_version",
            "ansible",
            "mssql",
            "group_names",
            "group_ids",
            "ungrouped_hosts",
        ]
    )


def wait_on_cyndi():
    """Waits until inventory.hosts schema is initialized"""
    LOGGER.info("Waiting for cyndi...")
    db_instance = DB_READ_REPLICA if DB_READ_REPLICA else DB
    while True:
        try:
            InventoryHosts.select(InventoryHosts.id).limit(1).exists()
            LOGGER.info("Cyndi schema exists, OK")
            db_instance.close()
            break
        except PeeweeException as exc:
            db_instance.rollback()
            LOGGER.info("Cyndi not initialized: %s. Waiting: %ss", exc, WAIT_INTERVAL_SEC)
            sleep(WAIT_INTERVAL_SEC)


def get_remediation_filter(advisory_available: Optional[List[bool]]) -> Tuple[Optional[List[int]], bool]:
    if advisory_available is None or (False in advisory_available and True in advisory_available):
        remediation_filter = None  # Return all remediations from system_vulnerabilities
        return_only_first_subq = False
    elif False in advisory_available:
        remediation_filter = [remediation.NONE.value]  # Return only rule hits without remediation from system_vulnerabilities
        return_only_first_subq = False
    else:
        remediation_filter = DEFAULT_REMEDIATION_FILTER
        return_only_first_subq = True  # Return only hits with remediation from system_vulnerabilities
    return remediation_filter, return_only_first_subq


def init_status_cache():
    """Initializes status map on application start"""
    LOGGER.info("Initializing status cache...")
    db_instance = DB_READ_REPLICA if DB_READ_REPLICA else DB
    while True:
        try:
            query = (Status.select().order_by(Status.id.asc()).dicts())
            for status in query:
                STATUS_CACHE[status["id"]] = status["name"]
            LOGGER.info("Status cache initialized.")
            db_instance.close()
            break
        except PeeweeException as exc:
            db_instance.rollback()
            LOGGER.info("Status cache not initialized: %s. Waiting: %ss", exc, WAIT_INTERVAL_SEC)
            sleep(WAIT_INTERVAL_SEC)
