"""
Common and utility functions/classes for vulnerability-manager
"""
import csv
from datetime import datetime, timezone
from enum import Enum
from io import StringIO
import json
from math import floor
from urllib.parse import unquote
from time import sleep
from typing import List

import connexion
from flask import Response, g
from peewee import fn, DataError, JOIN, SQL, PeeweeException
from prometheus_client import Counter, Histogram

from common.config import Config
from common.identity import get_identity, is_entitled_insights
from common.logging import get_logger
from common.peewee_model import (CveMetadata, CveRuleMapping, InsightsRule, RHAccount, SystemPlatform, SystemVulnerabilities, InventoryHosts,
                                 DB, DB_READ_REPLICA)
from common.peewee_conditions import (system_is_active)
from common.strtobool import strtobool
from common.utils import EXCEPTION_COUNT, format_datetime, validate_cve_cache_keepalive
from .filters import apply_filters
from .rbac_manager import RbacManager

LOGGER = get_logger(__name__)
CFG = Config()

IDENTITY_HEADER = "x-rh-identity"
DEFAULT_PAGE_SIZE = 20
DEFAULT_BUSINESS_RISK = "Not Defined"
DEFAULT_STATUS = "Not Reviewed"
CVE_SYNOPSIS_SORT = [fn.SUBSTRING(CveMetadata.cve, r"-(\d+)-").cast("integer"),
                     fn.SUBSTRING(CveMetadata.cve, r"-(\d+)$").cast("integer")]
DISABLE_ACCOUNT_CACHE = CFG.disable_account_cache

UI_REFERER = "console.redhat.com"
API_SOURCE = "API"
UI_SOURCE = "UI"

LOGGER.info("Access URL: %s", CFG.default_route)

# Prometheus support
# Counter for all-the-get-calls, dealt with in BaseHandler
REQUEST_COUNTS = Counter("ve_manager_invocations", "Number of calls per handler", ["method", "endpoint"])
ACCOUNT_REQUESTS = Counter("ve_manager_account_invocations", "Number of calls per account", ["account", "source"])
ADMIN_REQUESTS = Counter("ve_manager_admin_invocations", "Number of calls on admin API")
REQUEST_DURATION = Histogram("ve_manager_durations", "Duration of requests", ["method", "endpoint"], buckets=[1, 1.5, 1.75, 2, 2.5, 3, 3.5, 4])

WORKER_THREADS = CFG.worker_threads or 8

OS_INFO_QUERY = SQL("""
    CASE WHEN system_profile->'operating_system'->'name' IS NULL
        THEN 'N/A'
    WHEN system_profile->'operating_system'->'major' IS NULL
        THEN (system_profile->'operating_system'->>'name')
    WHEN system_profile->'operating_system'->'minor' IS NULL
        THEN (system_profile->'operating_system'->>'name') || ' ' || (system_profile->'operating_system'->>'major')
    ELSE
        (system_profile->'operating_system'->>'name') || ' ' || (system_profile->'operating_system'->>'major') ||
            '.' || (system_profile->'operating_system'->>'minor')
    END
""")

OS_INFO_SORT = [
    SQL("system_profile->'operating_system'->>'name'"),
    SQL("system_profile->'operating_system'->'major'"),
    SQL("system_profile->'operating_system'->'minor'")
]


class reporter(Enum):  # pylint: disable=invalid-name
    """Sources of reported CVE"""
    NONE = 0
    VMAAS = 1
    RULE = 2
    BOTH = 3


class InvalidArgumentException(Exception):
    """Illegal arguments for pagination/filtering/sorting"""


class ApplicationException(Exception):
    """General exception in the application"""

    def __init__(self, message, status_code):
        self.message = message
        self.status_code = status_code
        super().__init__()

    def format_exception(self):
        """Formats error message to desired format"""
        if isinstance(self.message, dict):
            return self.message, self.status_code
        return Request.format_exception(self.message, self.status_code)


class MissingEntitlementException(Exception):
    """entitlement is missing"""


class ReadOnlyModeException(Exception):
    """manager is running in read-only mode"""


class ApiStatusTimeoutException(Exception):
    """represents threshold timeout for rh status"""


def basic_auth(username, password, required_scopes=None):  # pylint: disable=unused-argument
    """
    Basic auth is done on 3scale level.
    """
    raise MissingEntitlementException


def auth_common(identity, x_rh_identity):  # pylint: disable=unused-argument
    """
    Check account number and entitlements
    """
    if "identity" not in identity:
        return None
    id_details = identity["identity"]

    if "account_number" not in id_details and "org_id" not in id_details:
        return None
    account_number = id_details.get("account_number")
    org_id = id_details.get("org_id")

    if not is_entitled_insights(identity):
        raise MissingEntitlementException

    rbac_manager = RbacManager()
    g.rbac_perms = rbac_manager.fetch_permissions(x_rh_identity)  # pylint: disable=assigning-non-slot

    ACCOUNT_REQUESTS.labels(org_id, UI_SOURCE if UI_REFERER in connexion.request.headers.get("referer", "") else API_SOURCE).inc()
    return {"uid": {"account_number": account_number, "org_id": org_id}}


def auth(x_rh_identity, required_scopes=None):  # pylint: disable=unused-argument
    """
    Parses account number from the x-rh-identity header
    """
    identity = get_identity(x_rh_identity)
    return auth_common(identity, x_rh_identity) if identity is not None else None


def auth_admin(x_rh_identity, required_scopes=None):  # pylint: disable=unused-argument
    """
    Parses user name from the x-rh-identity header
    """
    identity = get_identity(x_rh_identity)
    user = identity.get("identity", {}).get("associate", {}).get("email")
    LOGGER.info("User '%s' accessed admin API.", user)
    ADMIN_REQUESTS.inc()
    return {"uid": user} if user else None


def forbidden_missing_entitlement(exception):  # pylint: disable=unused-argument
    """Override default connexion 401 coming from auth() with 403"""
    return Response(response=json.dumps({"errors": [{"detail": "insights entitlement is missing",
                                                     "status": "403"}]}),
                    status=403, mimetype="application/vnd.api+json")


def forbidden_rbac(exception):  # pylint: disable=unused-argument
    """Override default connexion 401 coming from auth() with 403"""
    return Response(response=json.dumps({"errors": [{"detail": exception.message,
                                                     "status": "403"}]}),
                    status=403, mimetype="application/vnd.api+json")


class Request:
    """general class for processing requests"""

    _endpoint_name: str

    @staticmethod
    def _check_int_arg(kwargs, key, dflt, zero_allowed=False):
        val = kwargs.get(key, dflt)
        if val < 0 or (val == 0 and not zero_allowed):
            raise ApplicationException("Requested %s out of range: %s" % (key, val), 400)
        return val

    @staticmethod
    def _check_read_only_mode():
        if CFG.read_only_mode:
            raise ReadOnlyModeException("Service is running in read-only mode. Please try again later.")

    @staticmethod
    def _format_data(output_data_format, data_list, ids_only=False):
        if output_data_format == "csv":
            output = StringIO()
            if data_list:
                fields = None
                if ids_only:
                    # if endpoint returns ids only - id, type, attributes does not exist
                    fields = []
                    fields.extend(data_list[0].keys())
                else:
                    # create list of columns - type, id and all keys from attributes
                    fields = ["type", "id"]
                    fields.extend(data_list[0]["attributes"].keys())
                writer = csv.DictWriter(output, fields)
                writer.writeheader()
                for item in data_list:
                    # create flat dictionary (type, id + values from attributes) and write it
                    writer.writerow({field: item.get(field) or (not ids_only and item["attributes"].get(field)) for field in fields})
            return output.getvalue()
        return data_list

    @classmethod
    def _parse_list_arguments(cls, kwargs):
        # We may get limit/offset, or page/page_size, or both
        # limit/offset 'wins', if it's set
        # page/page_size defaults to 0/DEFAULT_PAGE_SIZE and limit/offset to DEFAULT_PAGE_SIZE if *neither* are set
        # regardless, make sure limit/offset and page/page_size a) both exist, and b) are consistent, before we leave
        offset_set = kwargs.get("offset", "") or kwargs.get("limit", "")
        page_set = kwargs.get("page", "") or kwargs.get("page_size", "")

        if offset_set:
            limit = cls._check_int_arg(kwargs, "limit", DEFAULT_PAGE_SIZE)
            offset = cls._check_int_arg(kwargs, "offset", 0, True)
            page = floor(offset / limit) + 1
            page_size = limit
        elif page_set:
            page = cls._check_int_arg(kwargs, "page", 1)
            page_size = cls._check_int_arg(kwargs, "page_size", DEFAULT_PAGE_SIZE)
            limit = page_size
            offset = (page - 1) * page_size
        else:
            page = 1
            offset = 0
            page_size = DEFAULT_PAGE_SIZE
            limit = DEFAULT_PAGE_SIZE

        data_format = kwargs.get("data_format", "json")
        if data_format not in ["json", "csv"]:
            raise InvalidArgumentException("Invalid data format: %s" % kwargs.get("data_format", None))

        return {
            "filter": remove_str_nulls(kwargs.get("filter", None)),
            "sort": remove_str_nulls(kwargs.get("sort", None)),
            "page": page,
            "page_size": page_size,
            "limit": limit,
            "offset": offset,
            "data_format": data_format
        }

    @staticmethod
    def format_exception(text, status_code):
        """Formats error message to desired format"""
        return {"errors": [{"status": str(status_code), "detail": text}]}, status_code

    @staticmethod
    def _sanitize_argument(arg):
        """Sanitizes arguments in list or string, from null chars"""
        retval = arg
        if isinstance(arg, list):
            retval = [Request._sanitize_argument(part) for part in arg]
        if isinstance(arg, str):
            retval = arg.replace("\x00", "")
        return retval

    @staticmethod
    def _parse_arguments(kwargs, argv):
        """
        Utility method for getting parameters from request which come as string
        and their conversion to a object we'd like to have.
        Expects array of {"arg_name" : some_str, "convert_func" : e.g. float, int}
        Returns dict of values if succeeds, throws exception in case of fail
        """
        retval = {}
        errors = []
        for arg in argv:
            retval[arg["arg_name"]] = kwargs.get(arg["arg_name"], None)
            if retval[arg["arg_name"]] is not None:
                retval[arg["arg_name"]] = Request._sanitize_argument(retval[arg["arg_name"]])
                try:
                    if arg["convert_func"] is not None:
                        retval[arg["arg_name"]] = arg["convert_func"](retval[arg["arg_name"]])
                except (ValueError, OverflowError):
                    errors.append({"status": "400",
                                   "detail": "Error in argument %s: '%s'" % (arg["arg_name"], retval[arg["arg_name"]])})
        if errors:
            raise ApplicationException({"errors": errors}, 400)
        return retval

    @classmethod
    def handle_errors(cls, fun, **kwargs):
        """ Execute provided function, while handling all common errors, and returning a formatted response """
        # pylint: disable=too-many-return-statements
        try:
            return fun(**kwargs)
        except ApplicationException as exc:
            return exc.format_exception()
        # TODO: Can this disclose any information ? Should we provide generic response message ?
        except DataError as exc:
            return cls.format_exception(str(exc).split(":")[0], 400)
        except InvalidArgumentException as exc:
            return cls.format_exception(str(exc), 400)
        except ReadOnlyModeException as exc:
            return cls.format_exception(str(exc), 503)
        except ApiStatusTimeoutException as exc:
            return cls.format_exception(str(exc), 408)
        except Exception:  # pylint: disable=broad-except
            EXCEPTION_COUNT.inc()
            LOGGER.exception("Unhandled exception: ")
            return cls.format_exception("Internal server error", 500)


class GetRequest(Request):
    """general class for processing GET requests"""

    _endpoint_name: str

    @classmethod
    def get(cls, **kwargs):
        """Answer GET request"""
        REQUEST_COUNTS.labels("get", cls._endpoint_name).inc()

        with REQUEST_DURATION.labels("get", cls._endpoint_name).time():
            return cls.handle_errors(cls.handle_get, **kwargs)

    @classmethod
    def handle_get(cls, **kwargs):  # pragma: no cover
        """To be implemented in child classes"""
        raise NotImplementedError


class ReadWriteRequest(Request):
    """ Base class for request implementations which require database to be opened in write mode"""

    _endpoint_name: str

    @classmethod
    def handle_errors(cls, fun, **kwargs):
        """ Handle common errors, and check whether read_only mode is enabled or disabled"""

        def readonly_fun(**kwargs):
            cls._check_read_only_mode()
            return fun(**kwargs)

        return super().handle_errors(readonly_fun, **kwargs)


class PatchRequest(ReadWriteRequest):
    """general class for processing PATCH requests"""

    _endpoint_name: str

    @classmethod
    def patch(cls, **kwargs):
        """Answer PATCH request"""
        REQUEST_COUNTS.labels("patch", cls._endpoint_name).inc()

        with REQUEST_DURATION.labels("patch", cls._endpoint_name).time():
            return cls.handle_errors(cls.handle_patch, **kwargs)

    @classmethod
    def handle_patch(cls, **kwargs):  # pragma: no cover
        """To be implemented in child classes"""
        raise NotImplementedError


class PostRequest(ReadWriteRequest):
    """general class for processing POST requests"""

    _endpoint_name: str

    @classmethod
    def post(cls, **kwargs):
        """Answer POST request"""
        REQUEST_COUNTS.labels("post", cls._endpoint_name).inc()

        with REQUEST_DURATION.labels("post", cls._endpoint_name).time():
            return cls.handle_errors(cls.handle_post, **kwargs)

    @classmethod
    def handle_post(cls, **kwargs):  # pragma: no cover
        """To be implemented in child classes"""
        raise NotImplementedError


class PutRequest(ReadWriteRequest):
    """general class for processing PUT requests"""

    _endpoint_name: str

    @classmethod
    def put(cls, **kwargs):
        """Answer PUT request"""
        REQUEST_COUNTS.labels("put", cls._endpoint_name).inc()

        with REQUEST_DURATION.labels("put", cls._endpoint_name).time():
            return cls.handle_errors(cls.handle_put, **kwargs)

    @classmethod
    def handle_put(cls, **kwargs):  # pragma: no cover
        """To be implemented in child classes"""
        raise NotImplementedError


class DeleteRequest(ReadWriteRequest):
    """general class for processing DELETE requests"""

    _endpoint_name: str

    @classmethod
    def delete(cls, **kwargs):
        """Answer DELETE request"""
        REQUEST_COUNTS.labels("delete", cls._endpoint_name).inc()

        with REQUEST_DURATION.labels("delete", cls._endpoint_name).time():
            return cls.handle_errors(cls.handle_delete, **kwargs)

    @classmethod
    def handle_delete(cls, **kwargs):  # pragma: no cover
        """To be implemented in child classes"""
        raise NotImplementedError


def parse_int_list(input_str):
    """Function to parse string with ints to list, e.g. "1,2,3" -> [1,2,3]"""
    return [int(part) for part in input_str.split(",")]


def parse_str_list(input_str):
    """
    Function to parse string with rules to list, e.g.
    "rule1|ERR_KEY,rule2|ERR_KEY2" -> [rule1|ERR_KEY, rule2|ERR_KEY2]
    """
    return input_str.split(",")


def bool_or_rules_list(arg: str):
    """Converts string to bool or parsed security rules list"""
    try:
        return bool(strtobool(arg))
    except ValueError:
        return parse_str_list(arg)


def remove_str_nulls(val):
    """Remove \\00 characters from string, DB driver does not like them in expressions"""
    if isinstance(val, str):
        return val.replace("\x00", "").strip()
    return val


def parse_str_or_list(str_list):
    """Parses a list of strings or single one, while removing invalid values"""
    retval = None
    if isinstance(str_list, str):
        retval = [remove_str_nulls(str_list)]
    if isinstance(str_list, list):
        retval = [s for s in [remove_str_nulls(item) for item in str_list] if s]
    if not retval or not any(retval):
        raise ValueError("Expected str or str list")
    return retval


def get_or_create_account():
    """In some cases rh_account might not have already been created by listener, create it for usage in manager"""
    rh_account = RHAccount.select(RHAccount.id).where(RHAccount.org_id == connexion.context["user"]["org_id"])
    if rh_account.count() == 0:
        rh_account = RHAccount.insert(account_number=connexion.context["user"]["account_number"],
                                      org_id=connexion.context["user"]["org_id"]).on_conflict(
            conflict_target=[RHAccount.account_number],
            update={RHAccount.account_number: connexion.context["user"]["account_number"],
                    RHAccount.org_id: connexion.context["user"]["org_id"]}).returning(RHAccount)
    return rh_account[0].id


def round_to_100_percent(number_set, digit_after_decimal=0):
    """
        This function take a list of number and return a list of percentage, which represents the portion of each number in sum of all numbers
        Moreover, those percentages are adding up to 100%!!!
    """
    divisor = float(sum(number_set))
    if not any(number_set):
        divisor = 100
    unround_numbers = [x / divisor * 100 * 10 ** digit_after_decimal for x in number_set]
    decimal_part_with_index = sorted([(index, unround_numbers[index] % 1) for index in range(len(unround_numbers))], key=lambda y: y[1], reverse=True)
    remainder = 100 * 10 ** digit_after_decimal - sum([int(x) for x in unround_numbers])
    index = 0
    while remainder > 0:
        unround_numbers[decimal_part_with_index[index][0]] += 1
        remainder -= 1
        index = (index + 1) % len(number_set)
    return [int(x) / float(10 ** digit_after_decimal) for x in unround_numbers]


def get_mapping(cves: List[int], subquery, rh_account_id):
    """Return select query from CveRuleMapping"""
    # pylint: disable=singleton-comparison
    selectables = [
        CveMetadata.cve,
        CveRuleMapping.cve_id,
        InsightsRule.name,
        InsightsRule.description_text,
        InsightsRule.summary_text,
        InsightsRule.reboot_required,
        InsightsRule.playbook_count,
        InsightsRule.change_risk,
        InsightsRule.kbase_node_id,
        InsightsRule.active,
        InsightsRule.rule_impact,
        InsightsRule.publish_date,
    ]

    if rh_account_id is None:
        return (CveRuleMapping.select(*selectables)
                              .join(InsightsRule, on=(CveRuleMapping.rule_id == InsightsRule.id))
                              .join(CveMetadata, on=(CveRuleMapping.cve_id == CveMetadata.id))
                              .where((InsightsRule.active == True) & (InsightsRule.rule_only == False))  # noqa: E712
                              .where(CveRuleMapping.rule_id.in_(CveRuleMapping.select(CveRuleMapping.rule_id).where(CveRuleMapping.cve_id.in_(cves))))
                              .dicts())

    return (CveRuleMapping.select(*selectables, fn.COUNT(subquery.c.id).alias("systems_affected"))
                          .join(InsightsRule, on=(CveRuleMapping.rule_id == InsightsRule.id))
                          .join(CveMetadata, on=(CveRuleMapping.cve_id == CveMetadata.id))
                          .join(subquery, JOIN.LEFT_OUTER,
                                on=((subquery.c.rule_id == InsightsRule.id) & (subquery.c.cve_id == CveRuleMapping.cve_id)))
                          .where((InsightsRule.active == True) & (InsightsRule.rule_only == False))  # noqa: E712
                          .where(CveRuleMapping.rule_id.in_(CveRuleMapping.select(CveRuleMapping.rule_id).where(CveRuleMapping.cve_id.in_(cves))))
                          .group_by(*selectables)
                          .dicts())


def get_subquery(cves: List[int], rh_account_id):
    """Return subquery, None if `rh_account_id` is None"""
    # pylint: disable=singleton-comparison
    if rh_account_id is None:
        return None

    subquery = (SystemVulnerabilities.select(SystemVulnerabilities.id, SystemVulnerabilities.rule_id, SystemVulnerabilities.cve_id)
                                     .join(SystemPlatform, on=((SystemVulnerabilities.system_id == SystemPlatform.id) &
                                                               system_is_active(rh_account_id=rh_account_id)))
                                     .where(SystemVulnerabilities.cve_id.in_(cves))
                                     .where(SystemVulnerabilities.mitigation_reason.is_null(True))
                                     .where((SystemVulnerabilities.rh_account_id == rh_account_id)))
    return cyndi_join(subquery)


def get_rules_for_cves(cves: list, rh_account=None) -> dict:
    """Return associated rules for a CVE"""
    # pylint: disable=singleton-comparison, unsubscriptable-object
    rules_map = {}
    rule_cve_mapping = {}
    rh_account_id = None

    if rh_account is not None:
        try:
            rh_account_id = RHAccount.select(RHAccount.id).where(RHAccount.org_id == rh_account["org_id"])[0]
        except IndexError:
            pass

    subquery = get_subquery(cves, rh_account_id)
    mapping = get_mapping(cves, subquery, rh_account_id)

    for row in mapping:
        rule_cve_mapping.setdefault(row["name"], []).append(row["cve"])
    for row in mapping:
        rule_detail = {
            "rule_id": row["name"],
            "description": row["description_text"],
            "summary": row["summary_text"],
            "reboot_required": row["reboot_required"],
            "playbook_count": row["playbook_count"],
            "change_risk": row["change_risk"],
            "kbase_node_id": row["kbase_node_id"],
            "associated_cves": rule_cve_mapping[row["name"]],
            "rule_impact": row["rule_impact"],
            "publish_date": format_datetime(row["publish_date"])
        }
        if rh_account_id is not None:
            rule_detail["systems_affected"] = row["systems_affected"]
        rules_map.setdefault(row["cve_id"], []).append(rule_detail)
    return rules_map


def get_system_count(rh_account, include_cyndi=True, filters=None, filters_args=None):
    """Get count of nonstale, nonoptouted, evaluated user systems"""
    # pylint: disable=singleton-comparison
    query = SystemPlatform.select(fn.COUNT(SystemPlatform.id).alias("count"))\
        .where((SystemPlatform.rh_account_id == rh_account)
               & ((SystemPlatform.last_evaluation.is_null(False)) | (SystemPlatform.advisor_evaluated.is_null(False)))
               & system_is_active(rh_account_id=rh_account))

    if include_cyndi:
        query = query.join(InventoryHosts, JOIN.INNER, on=(SystemPlatform.inventory_id == InventoryHosts.id))

    if filters:
        query = apply_filters(query, filters_args, filters, {})

    return query.first().count


def get_account_data(account):
    """Translates account name to RH account data"""
    result = RHAccount.select(RHAccount.id, RHAccount.cve_cache_from, RHAccount.cve_cache_keepalive) \
        .where(RHAccount.org_id == account["org_id"]) \
        .tuples() \
        .first()
    if result:
        return result
    return None, None, None


def update_cve_cache_keepalive(account_id, last_timestamp):
    """Update keepalive timestamp for CVE cache in account. Used for maintaining cache only for active accounts."""
    if not validate_cve_cache_keepalive(last_timestamp, 1):
        RHAccount.update(cve_cache_keepalive=datetime.now(timezone.utc)).where(RHAccount.id == account_id).execute()


def unique_bool_list(bool_list):
    """Makes from repeating multiple values only unique bool values"""
    return list(set(bool_list))


def parse_tags(tags_list):
    """
    Parses tags and initializes them.
    Tags are in form of <namespace>/<key>=<value> or <namespace>/<key> where value is null.
    Tags can contain characters like "/" or "=" but they need to be escaped by URL encoding,
    where here are decoded. The tag validation is done by regex in spec and connexion.
    Result is list of dictionaried tags.
    """
    tags = []
    for tag_raw in tags_list:
        tag = {}
        tag["namespace"], key_value = tag_raw.split("/")
        try:
            tag["key"], tag["value"] = key_value.split("=")
        except ValueError:
            tag["key"] = key_value
            tag["value"] = None

        for key, value in tag.items():
            tag[key] = unquote(value) if value is not None else value

        tags.append(tag)
    return tags


def cyndi_join(query):
    """Function adds join on cyndi table, based if cyndi is enabled."""
    query = query.join(InventoryHosts, JOIN.INNER, on=(SystemPlatform.inventory_id == InventoryHosts.id))
    return query


def is_cyndi_request(args):
    """Checks if request needs cyndi join"""
    return any(key in args and args[key] is not None for key in ["tags", "sap_system", "sap_sids", "rhel_version", "ansible", "mssql"])


def wait_on_cyndi():
    """Waits until inventory.hosts schema is initialized"""
    wait_interval_sec = 2
    LOGGER.info("Waiting for cyndi...")
    db_instance = DB_READ_REPLICA if DB_READ_REPLICA else DB
    while True:
        try:
            InventoryHosts.select(InventoryHosts.id).limit(1).exists()
            LOGGER.info("Cyndi schema exists, OK")
            db_instance.close()
            break
        except PeeweeException as exc:
            db_instance.rollback()
            LOGGER.info("Cyndi not initialized: %s. Waiting: %ss", exc, wait_interval_sec)
            sleep(wait_interval_sec)
